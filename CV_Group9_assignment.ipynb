{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Group9_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gherbin/ComputerVisionKUL/blob/master/CV_Group9_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH_DPxxjTeoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import random\n",
        "import logging\n",
        "\n",
        "from urllib import request\n",
        "from socket import timeout\n",
        "from urllib.error import HTTPError, URLError\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGBkRUir9f7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = \"/content/sample_data/CV__Group_assignment\"\n",
        "\n",
        "if not os.path.isdir(base_path):\n",
        "  os.makedirs(base_path)\n",
        "\n",
        "vgg_face_dataset_url = \"http://www.robots.ox.ac.uk/~vgg/data/vgg_face/vgg_face_dataset.tar.gz\"\n",
        "\n",
        "with request.urlopen(vgg_face_dataset_url) as r, open(os.path.join(base_path, \"vgg_face_dataset.tar.gz\"), 'wb') as f:\n",
        "  f.write(r.read())\n",
        "\n",
        "with tarfile.open(os.path.join(base_path, \"vgg_face_dataset.tar.gz\")) as f:\n",
        "  f.extractall(os.path.join(base_path))\n",
        "\n",
        "trained_haarcascade_url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "\n",
        "with request.urlopen(trained_haarcascade_url) as r, open(os.path.join(base_path, \"haarcascade_frontalface_default.xml\"), 'wb') as f:\n",
        "    f.write(r.read())\n",
        "\n",
        "\n",
        "\n",
        "all_subjects = [subject for subject in sorted(os.listdir(os.path.join(base_path, \"vgg_face_dataset\", \"files\"))) if subject.startswith(\"B\") and subject.endswith(\".txt\")]\n",
        "\n",
        "nb_subjects = 0\n",
        "nb_images_per_subject = 5\n",
        "\n",
        "images = []\n",
        "for subject in all_subjects[:nb_subjects]:\n",
        "\n",
        "  with open(os.path.join(base_path, \"vgg_face_dataset\", \"files\", subject), 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "  images_ = []\n",
        "  for line in lines:\n",
        "    url = line[line.find(\"http://\"): line.find(\".jpg\") + 4]\n",
        "\n",
        "    try:\n",
        "      res = request.urlopen(url, timeout=1)\n",
        "      img = np.asarray(bytearray(res.read()), dtype=\"uint8\")\n",
        "      img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
        "      h, w = img.shape[:2]\n",
        "      images_.append(img)\n",
        "      cv2_imshow(cv2.resize(img, (w // 5, h // 5)))\n",
        "\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    if len(images_) == nb_images_per_subject:\n",
        "      images.append(images_)\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOH3DL2jKk3U",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQPukQmEpoRC",
        "colab_type": "text"
      },
      "source": [
        "How to generate datasets\n",
        "A = Emma Stone\n",
        "\n",
        "1.   A --> Emma Stone\n",
        "2.   B --> Bradley Cooper\n",
        "3.   C --> Jane Levy\n",
        "4.   D --> Marc Blucas\n",
        "\n",
        "\n",
        "#Idea to get the images dataset\n",
        "## For A and B\n",
        "1. define a seed for A, and a seed for B\n",
        "2. generate a number based on this seed\n",
        "3. using this number, select 50 images from the list of 1000 images provided in the database\n",
        "4. Select 30 out of the 50 images obtained. This constitutes the original dataset (Training and Test) for A and B.\n",
        "\n",
        "## For C and D\n",
        "1. define a seed for C, and a seed for D\n",
        "2. generator a number based on this seed\n",
        "3. using this number, select 20 images from the lsit of 1000 images provided in the database\n",
        "4. Select 10 out of the 20 images obtained. This constutes the original dataset for C and D.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsyV36nO-SxH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFh6oMU6phLs",
        "colab_type": "text"
      },
      "source": [
        "Start from clean sheet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAMpaW-Ym0oG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "path_datasets = r\"/content/datasets/\"\n",
        "path_discard = r\"/content/discard/\"\n",
        "path_database = r\"/content/database/\"\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(path_datasets)\n",
        "    shutil.rmtree(path_discard)\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvcthM1B-PFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Rj5OSS3fUx",
        "colab_type": "text"
      },
      "source": [
        "populate database if required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQw39iLK36m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_info = r\"/content/database/info_retrieved.txt\"\n",
        "path_datasets = r\"/content/datasets/\"\n",
        "path_discard = r\"/content/discard/\"\n",
        "path_database = r\"/content/database/\"\n",
        "try: \n",
        "    os.mkdir(path_datasets) \n",
        "    os.mkdir(path_discard)\n",
        "except OSError as error: \n",
        "    logging.error(error) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuEfFZE42YeO",
        "colab_type": "text"
      },
      "source": [
        "Instead of randomly download from web, take images from \"local\" repository containing the 160 images downloaded once and for all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgaFPa0C2YJH",
        "colab_type": "code",
        "outputId": "f28f7302-a7ef-4e0c-8530-3aa9cb1816c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "load_from_local_drive = True\n",
        "if load_from_local_drive:\n",
        "    try:\n",
        "        os.mkdir(path_database)\n",
        "    except OSError as error:\n",
        "        logging.warning(error)\n",
        "\n",
        "    fromDirectory = r\"/content/drive/My Drive/ComputerVision/DATABASE\"\n",
        "    toDirectory= path_database\n",
        "    copy_tree(fromDirectory, toDirectory)\n",
        "\n",
        "path_, dirs_, files = next(os.walk(path_database))\n",
        "if len(files) == 161:\n",
        "    logging.debug(\"Successful database retrieval\")\n",
        "else:\n",
        "    logging.error(\"Most Likely problem with database retrieval, number of files = \" + str(len(files)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DEBUG:root:Successful database retrieval\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M09QQcnf38xN",
        "colab_type": "text"
      },
      "source": [
        "XXXXXXXXXXXXXXXXXXXXX\n",
        "XXXXXXXXXXXXXXXXXXXXX\n",
        "XXXXXXXXXXXXXXXXXXXXX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEGMZ43b4iaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "personA = \"Emma_Stone.txt\"\n",
        "personC = \"Jane_Levy.txt\"\n",
        "personB = \"Bradley_Cooper.txt\"\n",
        "personD = \"Marc_Blucas.txt\"\n",
        "persons = [personA, personB, personC, personD]\n",
        "datasets_dict = {}\n",
        "images_size = {}\n",
        "images_size[personA] = 50\n",
        "images_size[personB] = 50\n",
        "images_size[personC] = 30\n",
        "images_size[personD] = 30\n",
        "\n",
        "\n",
        "\n",
        "# Dictionary containing the ids of the pictures downloaded from internet\n",
        "vgg_ids = {}\n",
        "for p in persons:\n",
        "    vgg_ids[p] = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vu_v8LFOCra",
        "colab_type": "code",
        "outputId": "ed40cb5e-06e6-4a0e-adb1-d6d89933038f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# for p in persons:\n",
        "#     print(\"---------------------------------------\")\n",
        "#     random.seed(p)\n",
        "#     f = random.randrange(0,1000) \n",
        "#     s = random.randrange(0,1000)\n",
        "#     t = random.randrange(0,1000)\n",
        "\n",
        "#     print(\"f     => \" + str(p) + \" => \" + str(f))\n",
        "#     print(\"s     => \" + str(p) + \" => \" + str(s))\n",
        "#     print(\"t     => \" + str(p) + \" => \" + str(t))\n",
        "\n",
        "# with open(os.path.join(base_path, \"vgg_face_dataset\", \"files\", personA), 'r') as f:\n",
        "#             lines = f.readlines() \n",
        "#             print(lines[78].split(\" \")[8])     \n",
        "#             print(int(lines[78].split(\" \")[8]) == 1)\n",
        "#             print(int(lines[78].split(\" \")[8]) == 0)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qdfeFWLAL6C",
        "colab_type": "text"
      },
      "source": [
        "Populating DB - Run only if database folder is empty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5VsGBAJ3inK",
        "colab_type": "code",
        "outputId": "1b5615f8-b734-4a60-a2d4-73b3e01ee5d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "confirmation = False\n",
        "if confirmation:\n",
        "    try:\n",
        "        shutil.rmtree(path_database)\n",
        "    except:\n",
        "        pass \n",
        "    try:\n",
        "        os.mkdir(path_database)\n",
        "    except:\n",
        "        pass \n",
        "\n",
        "    fo = open(file_info, \"w+\")\n",
        "\n",
        "    # images = {}\n",
        "    # images_nominal_indices = {}\n",
        "    for person in persons:\n",
        "        logging.debug(\"Taking care of: \" + str(person))\n",
        "        random.seed(person)\n",
        "        # print(hash(person))\n",
        "        images_ = []\n",
        "        # images_nominal_indices_ = []\n",
        "        prev_index = []\n",
        "\n",
        "\n",
        "        with open(os.path.join(base_path, \"vgg_face_dataset\", \"files\", person), 'r') as f:\n",
        "            lines = f.readlines()       \n",
        "        \n",
        "\n",
        "        while len(images_) < images_size[person]:\n",
        "            index = random.randrange(0, 1000)\n",
        "            logging.debug(\"Index = \" + str(index))\n",
        "            if index in prev_index:\n",
        "                logging.debug(\"Index = \" + str(index) + \" => already there\")\n",
        "                continue\n",
        "            else:\n",
        "                prev_index.append(index)\n",
        "                line = lines[index]\n",
        "                # only curated data\n",
        "                if int(line.split(\" \")[8]) == 1:\n",
        "                    url = line[line.find(\"http://\"): line.find(\".jpg\") + 4]\n",
        "                    logging.debug(\"URL > \\\"\" + str(url))\n",
        "                    try:\n",
        "                        res = request.urlopen(url, timeout = 1)\n",
        "                        img = np.asarray(bytearray(res.read()), dtype=\"uint8\")\n",
        "                        img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
        "\n",
        "                        h, w = img.shape[:2]\n",
        "                        cv2_imshow(cv2.resize(img, (w//4, h//4)))\n",
        "                        # images_nominal_indices_.append(index)\n",
        "\n",
        "                        filename = path_database +  str(index) + \"_\" + str(person.split(\".\")[0]) + \".jpg\"\n",
        "\n",
        "                        value = cv2.imwrite(filename, img) \n",
        "                        # logging.debug(\"saved in DB: \" + str(filename))\n",
        "                        images_.append(img)\n",
        "                        fo.write(line)\n",
        "                    except ValueError as e:\n",
        "                            logging.error(\"Value Error >\" + str(e))\n",
        "                    except (HTTPError, URLError) as e:\n",
        "                            logging.error('ERROR RETRIEVING URL >' + str(e))\n",
        "                    except timeout:\n",
        "                            logging.error('socket timed out - URL %s', str(url))\n",
        "                    except cv2.error as e: \n",
        "                            logging.error(\"ERROR WRITING FILE IN DB  >\" + str(e))\n",
        "                    except:\n",
        "                        logging.error(\"Weird exception : \" + str(line))\n",
        "                else:\n",
        "                    logging.debug(\"File not curated => rejected (id = \" + str(index) + \" )\")    \n",
        "                \n",
        "                # images[person] = images_\n",
        "                # images_nominal_indices[person] = images_nominal_indices_\n",
        "\n",
        "    fo.close()\n",
        "else:\n",
        "    logging.warning(\"If you really want to erase and renew the database, please change first the \\\"confirmation\\\" boolean variable, at the beginning of this cell\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:If you really want to erase and renew the database, please change first the \"confirmation\" boolean variable, at the beginning of this cell\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnOEcJNUGS3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3eNIMAdCLVu",
        "colab_type": "text"
      },
      "source": [
        "From local database (not the web, not the drive), building lists of images for all persons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdFihucjCO6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(file_info, 'r') as f: \n",
        "    lines = f.readlines()\n",
        "\n",
        "assert len(lines)==160, \"amount of lines in file incompatible\" \n",
        "\n",
        "images = {}\n",
        "\n",
        "for p in persons:\n",
        "    images[p] = []\n",
        "\n",
        "\n",
        "images_index = {}\n",
        "for running_index in range(len(lines)):\n",
        "    if running_index in range(0,50):\n",
        "        p = personA\n",
        "    elif running_index in range(50,100):\n",
        "        p = personB\n",
        "    elif running_index in range(100,130):\n",
        "        p = personC\n",
        "    elif running_index in range(130,160):\n",
        "        p = personD\n",
        "    ind = str(int(lines[running_index].split(\" \")[0])-1)\n",
        "    vgg_ids[p].append(ind)\n",
        "    filename = ind + \"_\" + str(p.split(\".\")[0]) + \".jpg\"\n",
        "    images[p].append(cv2.imread(path_database+filename, cv2.IMREAD_COLOR))\n",
        "    \n",
        "print(len(images.keys()))\n",
        "print(len(images[personA]))\n",
        "print(len(images[personB]))\n",
        "print(len(images[personC]))\n",
        "print(len(images[personD]))\n",
        "\n",
        "for person in persons:\n",
        "    counter = 0\n",
        "    for img in images[person]:\n",
        "        logging.debug(\"------------------------------------------------------\")\n",
        "        logging.debug(\"Photo ID = \" + str(counter))\n",
        "        # cv2_imshow(img)\n",
        "        counter += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d-u5s3sHWp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v4tuRVO67u1",
        "colab_type": "text"
      },
      "source": [
        "To remove:\n",
        "From DB loaded from the internet, several images are to be removed. The main reasons are:\n",
        "\n",
        "\n",
        "*   Too much make up\n",
        "*   too different hair with usual representation\n",
        "*   really poor image quality\n",
        "*   relevance and error in dataset\n",
        "*   same image as already in dataset\n",
        "*   cropped image\n",
        "\n",
        "considering the tight selection of images to train our model, and the relative global amount of image candidates, it is acceptable to first sort the images according to visual insights. \n",
        "\n",
        "From the initial retrieved images, we then remove the undesired images, that we copy in discard images folder, for tracking purposes. We may want to use them later on to assess the training, for an academical purpose.\n",
        "\n",
        "From the remaing imaging, we can apply the same strategy of selecting the required datasets, that we finally load in separate folders, and save in drive.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g23-S0R87o3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir(path_datasets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPKRTSB5r8pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionary of the size required (see section 3)\n",
        "datasets_size = {}\n",
        "datasets_size[personA] = 30\n",
        "datasets_size[personB] = 30\n",
        "datasets_size[personC] = 10\n",
        "datasets_size[personD] = 10\n",
        "\n",
        "\n",
        "# manually remove images that are not relevant or considered not good enough to be part of the dataset\n",
        "to_remove = {}\n",
        "to_remove[personA] = [0,1,8,12,13,23,28,34,36,42,44,47,48,49]\n",
        "to_remove[personB] = [4,7,11,12,13,16,21,22,23,25,26,27,32,36,39,46,49]\n",
        "to_remove[personC] = [0,1,4,6,7,11,14,16,17,19,20]\n",
        "to_remove[personD] = [0,3,5,7,8,9,14,15,16,23,28]\n",
        "\n",
        "# goal is to sort in descending to remove elements from lists without modifying the indexes\n",
        "for p in persons:\n",
        "    to_remove[p].sort(reverse = True)\n",
        "\n",
        "\n",
        "# retrieve images candidates\n",
        "# --------------------------\n",
        "if len(os.listdir(path_datasets) ) == 0:\n",
        "    logging.debug(\"datasets empty - need to retrieve all !\")\n",
        "    # removing images to discard\n",
        "    for person in persons:\n",
        "        for index in to_remove[person]:\n",
        "            img = images[person].pop(index)\n",
        "            logging.debug(\"Removing item \" + str(index) + \" from list \" + str(person))\n",
        "            try:\n",
        "                filename = path_discard +  str(index) +\"_discarded_\" + str(person.split(\".\")[0]) + \".jpg\"\n",
        "                cv2.imwrite(filename, img) \n",
        "            except:\n",
        "                logging.error(\"Error while writing discarded image \" + str(filename))\n",
        "\n",
        "    # randomly select among remaining images\n",
        "    for person in persons:\n",
        "        # build list of indices from remaining images\n",
        "        logging.debug(\"Phase 2 -> random selection for \" + str(person))\n",
        "\n",
        "        images_ = []\n",
        "        indices = []\n",
        "        new_ids = []\n",
        "        # prev_index = []\n",
        "        random.seed(person)\n",
        "\n",
        "        while len(indices) < datasets_size[person]:       \n",
        "            index = random.randrange(0, len(images[person]))\n",
        "            if index in indices:\n",
        "                logging.debug(\"Index among remaining = \" + str(index) + \" => already there\")\n",
        "                continue\n",
        "            else:\n",
        "                # prev_index.append(index)\n",
        "                indices.append(index)\n",
        "\n",
        "        logging.debug(\"Phase 2 -> random selection idx:  \" + str(indices))\n",
        "\n",
        "        for index in indices:\n",
        "            img = images[person][index]\n",
        "            images_.append(img)\n",
        "            filename = path_datasets +  str(vgg_ids[person][index]) + \"_\" + str(person.split(\".\")[0]) + \".jpg\"\n",
        "            logging.debug(\"saved: \" + str(filename))\n",
        "            cv2.imwrite(filename, img) \n",
        "            new_ids.append(vgg_ids[person][index])\n",
        "        images[person] = images_\n",
        "        vgg_ids[person] = new_ids\n",
        "else:\n",
        "    logging.debug(\"folders not empty => can build directly images dictionnary\")\n",
        "\n",
        "# logging.debug(\"Number of images keys=\" + len(images.keys))\n",
        "# logging.debug(\"Number of images values=\" + len(images.values))\n",
        "for i in images.keys():\n",
        "    logging.debug(\"Number of images for \" + str(i) + \" => \" + str(len(images[i])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwJjZ1oaHEV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save to drive folders\n",
        "to_db_confirmation = False\n",
        "\n",
        "path_drive_DB = r\"/content/drive/My Drive/ComputerVision/DATABASE\"\n",
        "path_drive_Datasets = r\"/content/drive/My Drive/ComputerVision/DATASETS\"\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# drive folders should be properly set up\n",
        "\n",
        "if to_db_confirmation:\n",
        "\n",
        "    try:\n",
        "        shutil.rmtree(path_drive_DB)\n",
        "        shutil.rmtree(path_drive_Datasets)\n",
        "    except:\n",
        "        logging.error(\"Error in rmtree\") \n",
        "\n",
        "\n",
        "    try: \n",
        "        os.mkdir(path_drive_DB) \n",
        "        os.mkdir(path_drive_Datasets)\n",
        "    except OSError as error: \n",
        "        logging.error(error) \n",
        "    \n",
        "    logging.debug(\"Saving database in drive : start\")\n",
        "\n",
        "    fromDirectory = path_database\n",
        "    toDirectory = path_drive_DB\n",
        "    copy_tree(fromDirectory, toDirectory)\n",
        "\n",
        "    logging.debug(\"Saving datasets in drive : start\")\n",
        "\n",
        "    fromDirectory = path_datasets\n",
        "    toDirectory = path_drive_Datasets\n",
        "    copy_tree(fromDirectory, toDirectory)\n",
        "\n",
        "    logging.debug(\"Saving: done !\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-yore7xCeiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAdqr8emBM0J",
        "colab_type": "text"
      },
      "source": [
        "<!-- ## New Section title\n",
        "New section texte.\n",
        "\n",
        "[square]\n",
        "- List item1\n",
        "** * * *   List item2\n",
        "*   List item3\n",
        "    * list item 31\n",
        "    ** list item 32 -->\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1519aDRzcef8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in images[persons[0]]:\n",
        "    cv2_imshow(i)\n",
        "for i in images[persons[1]]:\n",
        "    cv2_imshow(i)\n",
        "for i in images[persons[2]]:\n",
        "    cv2_imshow(i)\n",
        "for i in images[persons[3]]:\n",
        "    cv2_imshow(i)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AF-XMBgbGRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_box(information_file_lines, index, image):\n",
        "    \"\"\"\n",
        "    information_file_lines is a list of lines of all images in the database\n",
        "    index is the vgg_idx\n",
        "    image is the image of interest, as retrieved from website\n",
        "    \"\"\"\n",
        "    line = information_file_lines[index]\n",
        "    left = line.split(\" \")[2]\n",
        "    top = line.split(\" \")[3]\n",
        "    right = line.split(\" \")[4]\n",
        "    bottom = line.split(\" \")[5]\n",
        "    image = cv2.rectangle(image, (left,top), (right,bottom), [0,0,255], 10)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HilePrqbDWC",
        "colab_type": "text"
      },
      "source": [
        "recognize faces based on haarCascade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G582IgL-fvi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "faceCascade = cv2.CascadeClassifier(os.path.join(base_path, \"haarcascade_frontalface_default.xml\"))\n",
        "\n",
        "with open(file_info, 'r') as f: \n",
        "    lines = f.readlines()\n",
        "\n",
        "for person in persons:\n",
        "    # print(len(images[person]))    \n",
        "    # cv2_imshow(images[person][0])\n",
        "    # for images_ in images[person]:\n",
        "    running_index = 0\n",
        "    for img in images[person]:\n",
        "\n",
        "        img_ = img.copy()\n",
        "        # cv2_imshow(img)\n",
        "        img_gray = cv2.cvtColor(img_, cv2.COLOR_BGR2GRAY)\n",
        "        faces = faceCascade.detectMultiScale(\n",
        "            img_gray,\n",
        "            scaleFactor=1.2,\n",
        "            minNeighbors=5,\n",
        "            minSize=(30, 30),\n",
        "            flags=cv2.CASCADE_SCALE_IMAGE\n",
        "        )\n",
        "        print(\"Found {} face(s)!\".format(len(faces)))\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(img_, (x, y), (x+w, y+h), (0, 255, 0), 10)\n",
        "\n",
        "        h, w = img_.shape[:2]\n",
        "        \n",
        "        draw_box(lines, vgg_ids[person][running_index]+1, img_)\n",
        "        running_index +=1 \n",
        "        \n",
        "        cv2_imshow(cv2.resize(img_, (w // 5, h // 5)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVrtCWGgRFKX",
        "colab_type": "text"
      },
      "source": [
        "From Datasets of images to Trainng set and validation sets;\n",
        "\n",
        "```\n",
        "images[person]\n",
        "```\n",
        "is a dictionary of all the images in the database that are dedicated to a specific person. In order to obtain a :\n",
        "* training set\n",
        "* test set\n",
        "\n",
        "for the person A and B, one can randomly select 20 images for validation sets, and 10 images for test sets. \n",
        "\n",
        "For the sake of reproducibility, the details are logged"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylnkm0G5SCcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sets_size = {}\n",
        "training_sets_size[personA] = 20\n",
        "training_sets_size[personB] = 20\n",
        "training_sets_size[personC] = 0\n",
        "training_sets_size[personD] = 0\n",
        "\n",
        "test_sets_size = {}\n",
        "test_sets_size[personA] = 10\n",
        "test_sets_size[personB] = 10\n",
        "test_sets_size[personC] = 10\n",
        "test_sets_size[personD] = 10\n",
        "\n",
        "training_set = {}\n",
        "test_set = {}\n",
        "for person in persons:\n",
        "    image_ = images[person]\n",
        "    training_set_ = []\n",
        "    random.seed(person)\n",
        "    init_set = set(range(0, len(image_)))\n",
        "\n",
        "    indices_training = random.sample(init_set, training_sets_size[person])\n",
        "    indices_test = list(init_set - set(indices_training))\n",
        "\n",
        "    training_set[person] = [images[person][i] for i in indices_training] \n",
        "    test_set[person] = [images[person][i] for i in indices_test]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEo9lXETYXWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.debug(\"training_set\")\n",
        "for p in persons:\n",
        "    logging.debug(\"######################################################################\")\n",
        "    logging.debug(p)\n",
        "    for img in training_set[p]:\n",
        "        cv2_imshow(img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}