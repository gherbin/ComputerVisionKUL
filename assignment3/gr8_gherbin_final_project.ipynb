{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gr8_gherbin_final_project.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "8jPKxBLpKtmP"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh4PAn0yA6Wu",
        "colab_type": "text"
      },
      "source": [
        "# Computer vision Final project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meBXv3zUU6_4",
        "colab_type": "text"
      },
      "source": [
        "Import (most of) required package first. \n",
        "\n",
        "**it may be required to restart Runtime because of tensorflow addons**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjNP0XJDSq_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install megatools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIRGFqTFQvmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import tarfile\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import numpy as np\n",
        "# from numpy.testing import assert_array_almost_equal\n",
        "\n",
        "import random\n",
        "import logging\n",
        "\n",
        "from urllib import request\n",
        "from socket import timeout\n",
        "from urllib.error import HTTPError, URLError\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.interpolate import RectBivariateSpline\n",
        "from scipy.linalg import svd as scipy_linalg_svd\n",
        "from scipy import ndimage, misc\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "# from tensorflow.keras import tf.keras.layers, models\n",
        "# !pip install cloud-tpu-client\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "mpl_logger = logging.getLogger(\"matplotlib\")\n",
        "mpl_logger.setLevel(logging.WARNING)\n",
        "\n",
        "pil_logger = logging.getLogger(\"PIL.Image\")\n",
        "pil_logger.setLevel(logging.ERROR)\n",
        "# logging.basicConfig(level=logging.ERROR # show only error msgs,\n",
        "#                     format='%(asctime)s - %(message)s',\n",
        "#                     datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "\n",
        "# !pip install tfa-nightly\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaAvRPXHw0LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)\n",
        "print(tfa.__version__)\n",
        "!pip list | grep tensorflow\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQDDj9Ia7BBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkIoJeCmQH6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['LOAD_FROM_GITHUB'] = \"TRUE\"\n",
        "\n",
        "need_to_download = not os.path.isdir('/content/VOCdevkit') \n",
        "if need_to_download:\n",
        "    os.environ['NEED_TO_DOWNLOAD'] = \"TRUE\"\n",
        "else:\n",
        "    os.environ['NEED_TO_DOWNLOAD'] = \"FALSE\"\n",
        "print(need_to_download)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCp6335T1Znt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "if [ $NEED_TO_DOWNLOAD = \"TRUE\" ]\n",
        "then\n",
        "    if [ $LOAD_FROM_GITHUB = \"TRUE\" ]\n",
        "    then\n",
        "        echo \"github\"\n",
        "\n",
        "    else\n",
        "        echo \"oxford\"\n",
        "    fi\n",
        "else\n",
        "    echo \"no need to download\"\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sd76mCBy4lG",
        "colab_type": "text"
      },
      "source": [
        "####Parameters used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj_EY016CQ-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(426473)\n",
        "voc_root_folder = \"/content/VOCdevkit/VOC2009\"\n",
        "sq_size = 224 #\n",
        "n_samples = None\n",
        "num_classes = 20\n",
        "classification_type = \"multilabel\" # {\"single\", \"multilabel\"}\n",
        "\n",
        "BS = 32\n",
        "BATCH_SIZE = BS\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "path_image_folder = voc_root_folder + r'/JPEGImages/'\n",
        "classes_names = ('aeroplane','bicycle', 'bird','boat','bottle','bus','car',\n",
        "                'cat', 'chair','cow','diningtable','dog','horse','motorbike',\n",
        "                'person','pottedplant','sheep','sofa','train','tvmonitor')\n",
        "\n",
        "use_mean_subtraction = False\n",
        "enlarged_training_set = True\n",
        "\n",
        "# filenames\n",
        "# base_folder = r'/content/drive/My Drive/ComputerVision/models/'\n",
        "base_folder_class = r'/content/weights_class_224/'\n",
        "base_folder_seg = r'/content/'\n",
        "\n",
        "# Classification\n",
        "model_v1_save_filename                  = base_folder_class + r'model_v1_class_from_scratch_weights.h5'\n",
        "model_v1_hist_save_filename             = base_folder_class + r'model_v1_class_from_scratch_weights_hist.sav'\n",
        "\n",
        "model_v2_save_filename                  = base_folder_class + r'model_v2_class_from_scratch_weights.h5'\n",
        "model_v2_hist_save_filename             = base_folder_class + r'model_v2_class_from_scratch_weights_hist.sav'\n",
        "\n",
        "model_v3_save_filename                  = base_folder_class + r'model_v3_class_from_scratch_weights.h5'\n",
        "model_v3_hist_save_filename             = base_folder_class + r'model_v3_class_from_scratch_weights_hist.sav'\n",
        "\n",
        "class_tl_save_filename                  = base_folder_class + r'class_transfer_learning_model.h5'\n",
        "class_tl_hist_save_filename             = base_folder_class + r'class_transfer_learning_model_hist.sav'\n",
        "\n",
        "class_tl_finetuned_save_filename        = base_folder_class + r'class_transfer_learning_model_fine_tuned.h5'\n",
        "class_tl_finetuned_hist_save_filename   = base_folder_class + r'class_transfer_learning_model_fine_tuned_hist.h5'\n",
        "\n",
        "single_model_save_filename              = base_folder_class + r'single_model_save_filename.h5'\n",
        "single_model_hist_save_filename         = base_folder_class + r'single_model_save_filename_hist.sav'\n",
        "\n",
        "# Segmentation\n",
        "model_seg_tl_save_filename              = base_folder_seg + r'model_seg_tl_weights.h5'\n",
        "model_seg_tl_hist_save_filename         = base_folder_seg + r'model_seg_tl_hist.sav'\n",
        "\n",
        "model_seg_fs_save_filename              = base_folder_seg + r'model_seg_fs_weights.h5'\n",
        "model_seg_fs_hist_save_filename         = base_folder_seg + r'model_seg_fs_hist.sav'\n",
        "\n",
        "model_ah_save_filename                  = base_folder_seg + r'model_ah_weights.h5'\n",
        "model_ah_hist_save_filename             = base_folder_seg + r'model_ah_weights_hist.sav'\n",
        "\n",
        "model_seg_fs_ah_save_filename           = base_folder_seg + r'model_seg_fs_ah_weights.h5'\n",
        "model_seg_fs_ah_hist_save_filename      = base_folder_seg + r'model_seg_fs_ah_hist.sav'\n",
        "\n",
        "histories = {}\n",
        "\n",
        "train_class_model_v1        = False\n",
        "train_class_model_v2        = False\n",
        "train_class_model_v3        = False\n",
        "train_class_model_tl        = False\n",
        "train_class_model_tl_ft     = False and False # should be False, unless really sure conditions are met ! (note: another parameter block it at the appropriate cell)\n",
        "train_class_model_sp        = False\n",
        "\n",
        "train_seg_model_tl          = False\n",
        "train_seg_model_fs          = False\n",
        "train_class_ah              = False\n",
        "train_seg_fs_ah             = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9e0FMgbBBOC",
        "colab_type": "text"
      },
      "source": [
        "Fetch data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thIIdR6YMVTo",
        "colab_type": "text"
      },
      "source": [
        "Based on the `load_from_local_drive` parameter, the data are fetched either from the official website or from a *personal-controled* github drive. \n",
        "\n",
        "The goal of this manoeuvre is to gain speed every time the notebook is restarted from scratch and the session loss, where the data need to be downloaded anew:\n",
        "* official download and untar: ~3.05 minutes\n",
        "* github download and unzip: ~0.55 minutes\n",
        "\n",
        "Whatever the solution chosen, in the end, the data are the stored at the exact same position. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnGWJb_lQFlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "%%bash\n",
        "#!/bin/bash\n",
        "if [ $NEED_TO_DOWNLOAD = \"TRUE\" ]\n",
        "then\n",
        "    if [ $LOAD_FROM_GITHUB = \"TRUE\" ]\n",
        "    then\n",
        "        for i in {001..044};\n",
        "            do\n",
        "            wget -nc -nv https://raw.githubusercontent.com/gherbin/cv_gr8_finalProject/master/final_project_db.zip.$i \n",
        "            done \n",
        "        7z x final_project_db.zip.001 \n",
        "        mv /content/final_project_db/* /content/\n",
        "\n",
        "    else\n",
        "        wget -nc http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar\n",
        "        tar -xf VOCtrainval_11-May-2009.tar --totals\n",
        "        # wget -nc http://host.robots.ox.ac.uk:8080/eval/downloads/VOC2009test.tar\n",
        "        # tar -xf VOC2009test.tar --totals\n",
        "    fi\n",
        "else\n",
        "    echo \"No need to download\"\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6LBtVhBF_bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "if [ $NEED_TO_DOWNLOAD = \"TRUE\" ]\n",
        "then\n",
        "    if [ $LOAD_FROM_GITHUB = \"TRUE\" ]\n",
        "    then\n",
        "        rm -rf final_project_db*\n",
        "    else\n",
        "        rm -rf VOCtrainval_11-May-2009.tar*\n",
        "    fi\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLEAp1ukVtXp",
        "colab_type": "text"
      },
      "source": [
        "###Download weights and histories\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd8g32nrV4nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "need_to_download_weights = not os.path.isdir('/content/weights_class_224') \n",
        "if need_to_download_weights:\n",
        "    try:\n",
        "        print(\"Trying to download weights and histories\")\n",
        "        !megadl 'https://mega.nz/#!gZh2SIgQ!2DfCFh_W2js8QbXKnCU015ZreGgilkb85AURuBkM1G0'\n",
        "        !megadl 'https://mega.nz/#!0dA3WICS!rzGUdyHE5-liTE4M-gPjuxMJUaIU9vqQGug9WHt64aU'\n",
        "        !7z x weights_class_224-20200531T094420Z-001.zip \n",
        "        !7z x weights_seg_224-20200601T110727Z-001.zip\n",
        "    except:\n",
        "        print(\"Error while Downloading and extracting weights. \\n Please make sure that all files mentioned in the first snippet are located in /content/\")\n",
        "else:\n",
        "    print(\"Weights already downloaded\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wMCLbo8BzhY",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "In this very first part, I build some tools and knowledge on the VOC dataset. \n",
        "The details of the code is in the comments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEq1VjkRNk-6",
        "colab_type": "text"
      },
      "source": [
        "## Split the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mx_efOMTiLR",
        "colab_type": "text"
      },
      "source": [
        "<!--In ImageSets\n",
        "- layout -> person layout taster task\n",
        "- main -> {class}_trainval.txt; {class}_train.txt; {class}_val.txt ==> in trainval.txt: 7054 images\n",
        "- segmentation -> trainval.txt: 1499 images\n",
        "\n",
        "=> idea: from the 7054 images in \"ImageSets/main/trainval.txt\" => x % -> train, y% val, z% test; \n",
        "and from the 1499 images for \"ImageSets/segmentation/trainval.txt\" => x% for train, y% for validation, z% for test sets.\n",
        "\n",
        "In total, 6 tests, produced using a seed so that it's repeatable (pseudo-random)\n",
        "-->\n",
        "[COMMENTS]\n",
        "In order to split the data, different ways are possible. In this work, I simply use the VOC2009 suggested training and validation set. \n",
        "\n",
        "- classification:\n",
        "    - training: 3473\n",
        "    - validation: 3581\n",
        "- segmentation:\n",
        "    - training: 749\n",
        "    - validation: 750\n",
        "\n",
        "[VOC DB stats](http://host.robots.ox.ac.uk/pascal/VOC/voc2009/dbstats.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ML68TeI3S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaRw92UYfJWK",
        "colab_type": "text"
      },
      "source": [
        "## Get to know the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6qoJN3v9Opc",
        "colab_type": "text"
      },
      "source": [
        "#### get the ids of the images\n",
        "The following cell create the identifiers list that are used for the training and validation sets. The identifiers are string names, usually of the form \"year_xxxxxxx\". An extract is printed (first two elements of the sets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuqxsjjUBwxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ids(dataset_type, task_type):\n",
        "    '''\n",
        "    Based on dataset_type {training, validation} and task_type{classification}, parse the corresponding txt file {train.txt, val.txt} in \n",
        "    order to get the identifiers of the images of the requested set.\n",
        "    '''\n",
        "\n",
        "    if dataset_type == \"training\":\n",
        "        stem = \"train\"\n",
        "    elif dataset_type == \"validation\":\n",
        "        stem = \"val\"\n",
        "    else:\n",
        "        raise ValueError(\"dataset_type unknown\")\n",
        "    \n",
        "    if task_type == \"classification\":\n",
        "        stem_folder = r'/ImageSets/Main/'\n",
        "    else:\n",
        "        stem_folder = r'/ImageSets/Segmentation/'\n",
        "\n",
        "    file_path = voc_root_folder + stem_folder + stem + r'.txt'\n",
        "    with open(file_path, \"r\") as f:\n",
        "        content = f.readlines()\n",
        "    ids = [x.strip() for x in content] \n",
        "\n",
        "    # shuffle list of ids\n",
        "    random.seed(str(426473) + dataset_type + task_type )\n",
        "    random.shuffle(ids)\n",
        "    # random.seed()\n",
        "\n",
        "    return ids \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sx7eJBJkUkN",
        "colab_type": "text"
      },
      "source": [
        "A parameter `enlarged_training_set` can set up experiment with an enlarged training set. To enlarge, 2000 out of the ~3500 items from the validation set are transfered to the training ids set. This eventually gives:\n",
        "- training set: ~77 %\n",
        "- validation set: ~23 %\n",
        "\n",
        "The goal is to observe the change in behavior when enlarging the dataset. The remaining validation set should be enough to reach ot to conclusion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ0O0kFOjhRr",
        "colab_type": "text"
      },
      "source": [
        "We can use the ids using the function just defined. A summary of this loading is printed "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20-CryItJ8gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_ids = get_ids(\"training\", \"classification\")\n",
        "val_ids = get_ids(\"validation\", \"classification\")\n",
        "\n",
        "if enlarged_training_set:\n",
        "    training_ids = training_ids + val_ids[0:2000]\n",
        "    val_ids = val_ids[2001:]\n",
        "\n",
        "print(\"Classification task:\")\n",
        "print(\"training set,   #elements = \", len(training_ids))\n",
        "print(\"validation set, #elements = \", len(val_ids))\n",
        "\n",
        "print(training_ids[0:2])\n",
        "print(val_ids[0:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HcKfE_-mTIv",
        "colab_type": "text"
      },
      "source": [
        "#### Helper functions\n",
        "\n",
        "Helper functions:\n",
        "- `my_reshape`\n",
        "- `plot_matrix`\n",
        "- `get_images`\n",
        "- `get_class_labels_str`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW-YV72g8lp3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRB51UMiNC9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# # Load in the images\n",
        "# for filepath in os.listdir(path_image_folder):\n",
        "def my_reshape(image_vector, sq_size, color):\n",
        "    '''\n",
        "    returns a reshape version of an image represented as an image array, depending of the color parameter.\n",
        "    If color is True, it returns a colored RGB format image of size (sq_size x sq_size) (useable as is by matplotlib)\n",
        "    If color is False, it returns a grayscale image (sq_size x sq_size)\n",
        "    '''\n",
        "    flattened = image_vector.ndim == 1\n",
        "    if flattened:\n",
        "        if color:\n",
        "            img_reshaped = (np.reshape(image_vector, (sq_size, sq_size, 3))).astype('uint8')\n",
        "            return img_reshaped # cv2.cvtColor(img_reshaped, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            return np.reshape(image_vector, (sq_size, sq_size))\n",
        "    else:\n",
        "        if color:\n",
        "            # img_reshaped = (np.reshape(image_vector, (sq_size, sq_size, 3))).astype('uint8')\n",
        "            if \"Tensor\" in image_vector.__class__.__name__ :\n",
        "                return image_vector\n",
        "            else:\n",
        "                # print(image_vector.__class__.__name__ + \" => not a Tensor\")\n",
        "                return image_vector#.astype('float32') # cv2.cvtColor(img_reshaped, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            return image_vector\n",
        "\n",
        "def plot_matrix(images_matrix, labels = None, sq_size = 32, color=True, my_color_map=\"viridis\", h=8, w=5, transpose = False, return_figure = False, scale = 1):\n",
        "    '''\n",
        "    plots the images contained in a matrix of data, reshaping and coloring them\n",
        "    ''' \n",
        "    if h == 8 and w == 5:\n",
        "        h = np.ceil(np.sqrt(images_matrix.shape[0]))\n",
        "        w = np.ceil(np.sqrt(images_matrix.shape[0]))\n",
        "\n",
        "    fig = plt.figure(figsize=(w*scale,h*scale)) \n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.25, wspace=0.05) \n",
        "    # plot the images, each image is 64 by 64 pixels \n",
        "\n",
        "    if transpose:\n",
        "        images_matrix_used = images_matrix.T # .copy()\n",
        "    else:\n",
        "        images_matrix_used = images_matrix # .copy()\n",
        "\n",
        "    i=0\n",
        "    for img_vector in images_matrix_used: \n",
        "        ax = fig.add_subplot(h, w, i+1, xticks=[], yticks=[]) \n",
        "        ax.imshow(my_reshape(img_vector, sq_size, color), cmap = my_color_map, interpolation='nearest') \n",
        "        if labels is None:\n",
        "            ax.set_xlabel('label =' + str(i), color = 'r')\n",
        "        else:\n",
        "            # ax.set_xlabel('label =' + str(i), color = 'g')\n",
        "            ax.set_xlabel(labels[i], color = 'w', backgroundcolor = \"k\")\n",
        "        i+=1\n",
        "    plt.show()\n",
        "\n",
        "    if return_figure:\n",
        "        return fig\n",
        "\n",
        "def get_images(ids, path_image_folder, width=5, height=5, channel=3, n_samples = None):\n",
        "    if n_samples == None:\n",
        "        n_samples = len(ids)\n",
        "    \n",
        "    print_once = False\n",
        "    images = np.empty((n_samples, height, width, channel), dtype=np.uint8)\n",
        "    for i in range(0, n_samples):\n",
        "        name = ids[i]\n",
        "        # images are loaded in uint8\n",
        "        src_img = cv2.imread(path_image_folder+name+r'.jpg', )\n",
        "        if print_once:\n",
        "            print(src_img.dtype)\n",
        "        src_img_resized = cv2.resize(src_img, (height, width))\n",
        "        if print_once:\n",
        "            print(src_img_resized.dtype)\n",
        "        src_img_resized_rgb = cv2.cvtColor(src_img_resized, cv2.COLOR_BGR2RGB, )   # BGR -> RGB\n",
        "        if print_once:\n",
        "            print(src_img_resized_rgb.dtype)        # cv2_imshow(src_img)\n",
        "        # cv2_imshow(src_img_resized_rgb)\n",
        "        \n",
        "        images[i,:,:,:] = src_img_resized_rgb # flatten returns a copy - may be not efficient\n",
        "        if print_once:\n",
        "            print(images[0].dtype)\n",
        "            print_once = False\n",
        "\n",
        "    return images\n",
        "\n",
        "def get_class_labels_str(ids, unique=True, remove_difficult=True, classification_type=\"multilabel\", n_samples = None):\n",
        "    '''\n",
        "    Based on the Annotation, parse the xml, and build a tuple of the classes\n",
        "    return a tuple ordered as ids containing all the tuples of the \n",
        "    \"Unique\": if unique is True, returns only one element of the class (ex : 2 bikes => returns only once)\n",
        "    '''\n",
        "    ids_labels = []\n",
        "    if n_samples == None:\n",
        "        n_samples = len(ids)\n",
        "    \n",
        "    for i in range(0, n_samples):\n",
        "        class_labels = []\n",
        "        tree = ET.parse( voc_root_folder+r'/Annotations/' + ids[i] + r'.xml')\n",
        "        root = tree.getroot()\n",
        "        for object_ in root.findall('object'):\n",
        "            class_name = object_.find('name').text\n",
        "\n",
        "            is_difficult = object_.find('difficult').text == \"1\"\n",
        "            if not remove_difficult:\n",
        "                # raise NotImplementedError(\"remove_difficult needs to be True\")\n",
        "                if unique:\n",
        "                    if class_name not in class_labels:\n",
        "                        class_labels.append(class_name)\n",
        "                    else:\n",
        "                        continue\n",
        "                elif not unique:\n",
        "                    class_labels.append(class_name)\n",
        "            else:\n",
        "                if unique and (not is_difficult):\n",
        "                    if class_name not in class_labels:\n",
        "                        class_labels.append(class_name)\n",
        "                    else:\n",
        "                        continue\n",
        "                elif (not unique) and (not is_difficult):\n",
        "                    class_labels.append(class_name)\n",
        "                else:\n",
        "                    ##\n",
        "                    # print(\"Difficult for label \" + str(ids[i]) + ', object of class : ' + str(class_name))\n",
        "                    continue\n",
        "\n",
        "        if classification_type == \"single\":\n",
        "            ids_labels.append(tuple([class_labels[0]]))\n",
        "        elif classification_type == \"multilabel\":\n",
        "            ids_labels.append(tuple(class_labels))\n",
        "        else:\n",
        "            raise ValueError('classification_type unknown value => ' + str(classification_type))     \n",
        "\n",
        "        \n",
        "    return tuple(ids_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6SWlBin8-03",
        "colab_type": "text"
      },
      "source": [
        "The following code cell sets up appropriately the training and validation sets, based on the identifiers. \n",
        "\n",
        "At this point, the images returned are not !! flattened, but are resized.\n",
        "\n",
        "The labels (multiple labels per image) are stored in a tuple of tuples; the order is the one defined by ids.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7MoThZSbys9",
        "colab_type": "text"
      },
      "source": [
        "#### One hot encoding\n",
        "multilabels : \n",
        "[sklearn multilabel binarization](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x6sxgmiz0Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Get the labels (string) for the training and validation sets, baes on the ids obtained from get_ids\n",
        "'''\n",
        "training_labels_str = get_class_labels_str(training_ids, classification_type=classification_type, remove_difficult = False, n_samples = None)\n",
        "val_labels_str = get_class_labels_str(val_ids, classification_type=classification_type, remove_difficult = False, n_samples = None)\n",
        "\n",
        "'''\n",
        "Create a Binarizer object, and fit it to the classes names of the problem\n",
        "'''\n",
        "# use to encore the labels as one hot encoding\n",
        "multiLabelBinarizer = preprocessing.MultiLabelBinarizer(classes=classes_names)\n",
        "multiLabelBinarizer.fit(classes_names)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGsRSQm9ew9u",
        "colab_type": "text"
      },
      "source": [
        "Based on the training_ids, load all images in memory. \n",
        "Note: this is not used by the tf_generator principle !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ixRuH3Mmw-H",
        "colab_type": "text"
      },
      "source": [
        "####Load all images in memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtLFds3G88Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        "Get the images based on the ids\n",
        "'''\n",
        "training_images = get_images(training_ids, path_image_folder, width=sq_size, height=sq_size, n_samples=None)\n",
        "val_images = get_images(val_ids, path_image_folder, width=sq_size, height=sq_size, n_samples=None)\n",
        "\n",
        "'''\n",
        "convert the labels using the binarize\n",
        "'''\n",
        "\n",
        "training_labels_binarized =  multiLabelBinarizer.fit_transform(training_labels_str)\n",
        "val_labels_binarized =  multiLabelBinarizer.fit_transform(val_labels_str)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56YL5qt0xZX4",
        "colab_type": "text"
      },
      "source": [
        "At this point, images are loaded in ram, and corresponding labels are available (both in string and one hot encoded format). We verify the images/labels in the next snippet. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LtTzpI7xYA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Training\")\n",
        "print(\"Type = \" + str(training_images[0].dtype))\n",
        "print(\"min = \" + str(np.min(training_images[0:1,:])))\n",
        "print(\"max = \" + str(np.max(training_images[0:1,:])))\n",
        "\n",
        "# The images loaded are in float64 format\n",
        "# To plot them, I first need to cast them to acceptable format\n",
        "plot_matrix(training_images[0:16,:], labels = training_labels_str[0:16], sq_size=sq_size, scale = 2)\n",
        "\n",
        "print(\"Validation\")\n",
        "plot_matrix(val_images[0:16,:], labels = val_labels_str[0:16], sq_size=sq_size, scale = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f9HhxY7m5zQ",
        "colab_type": "text"
      },
      "source": [
        "we check also the matching of the labels in string and binary formats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEqbBSWhpkho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_training = 14\n",
        "index_val = 12\n",
        "\n",
        "print(training_ids[index_training])\n",
        "print(training_labels_str[index_training])\n",
        "print(training_labels_binarized[index_training])\n",
        "print(\"- \"*20)\n",
        "print(val_ids[index_training])\n",
        "print(val_labels_str[index_val])\n",
        "print(val_labels_binarized[index_val])\n",
        "\n",
        "print(\"--\"*20)\n",
        "print(\"Are all Training Labels well binarized: \", np.all(np.any(training_labels_binarized == 1, axis=1)))\n",
        "print(\"Are all Validation Labels well Binarized: \" , np.all(np.any(val_labels_binarized == 1, axis=1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5A-DxLa91VX",
        "colab_type": "text"
      },
      "source": [
        "We can confirm the shapes of the different datastructures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q902T6C2At4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Data Structures shapes:\")\n",
        "print(\"--\"*13 + \"\\n\")\n",
        "print(\"Training images shape         : \", training_images.shape)\n",
        "print(\"Training images type         : \", training_images[0].dtype)\n",
        "print(\"Training class labels length  :\" , len(training_labels_str))\n",
        "print(\"--\"*40)\n",
        "print(\"Validation images shape       : \", val_images.shape)\n",
        "print(\"Validation images type         : \", val_images[0].dtype)\n",
        "print(\"Validation class labels length:\" , len(val_labels_str))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6A0zr-lJ5J6",
        "colab_type": "text"
      },
      "source": [
        "Have the color values between 0 and 1 (or -1 -> 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiX3RfKEJ46a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Training images are \n",
        "\n",
        "'''\n",
        "if np.max(np.max(training_images)) > 1:\n",
        "    training_images = np.divide(training_images, 255.0, dtype = np.float32)\n",
        "    val_images = np.divide(val_images,255.0, dtype = np.float32)\n",
        " \n",
        "MEAN_TRAIN_IMAGE = np.mean(training_images, axis = 0, dtype = np.float32)\n",
        "MEAN_TRAIN_IMAGE = np.expand_dims(MEAN_TRAIN_IMAGE,0)\n",
        "STD_TRAIN_IMAGE  = np.std(training_images, dtype=np.float32)\n",
        "\n",
        "\n",
        "\n",
        "print(\"shape MEAN TRAIN IMG = \", MEAN_TRAIN_IMAGE.shape)\n",
        "print(\"Type MEAN TRAIN IMG = \", MEAN_TRAIN_IMAGE.dtype)\n",
        "print(\"max MEAN TRAIN IMG = \", np.max(MEAN_TRAIN_IMAGE))\n",
        "print(\"min MEAN TRAIN IMG = \", np.min(MEAN_TRAIN_IMAGE))\n",
        "\n",
        "print(\"Type STD TRAIN IMG = \", STD_TRAIN_IMAGE.dtype)\n",
        "print(\"STD_TRAIN_IMAGE  = \", STD_TRAIN_IMAGE)\n",
        "plot_matrix(MEAN_TRAIN_IMAGE, [\"mean\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLAmo6A4s5U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_remove_mean(dataset, mean = MEAN_TRAIN_IMAGE):\n",
        "    '''\n",
        "    remove the mean image of the training set to all image from dataset\n",
        "    type : np.float32\n",
        "    '''\n",
        "    return (dataset - mean).astype(np.float32)   #np.apply_along_axis(_normalize, 0, dataset, mean, std)\n",
        "def dataset_normalize(dataset, mean = MEAN_TRAIN_IMAGE):\n",
        "    '''\n",
        "    @param dataset: should be np.float32 type, limited in [0, 1]\n",
        "    @return a dataset between [0,1], for which the mean image was substracted to all images\n",
        "    '''\n",
        "    return ((dataset_remove_mean(dataset, mean) + 1) / 2.0).astype(np.float32)\n",
        "\n",
        "def dataset_add_mean(dataset,mean = MEAN_TRAIN_IMAGE):\n",
        "    '''\n",
        "    add the mean image of the training set to all image from dataset\n",
        "    type : np.float32\n",
        "    '''\n",
        "    return (dataset + mean).astype(np.float32)\n",
        "\n",
        "def dataset_denormalize(dataset, mean = MEAN_TRAIN_IMAGE):\n",
        "    '''\n",
        "    @param dataset: should be np.float32 type, limited in [0, 1]\n",
        "    @return a dataset between [0,1], for which the mean image was added to all images\n",
        "    typ. usage : plot_matrix(dataset_denormalize(dataset), labels, sq_size, scale = 1)\n",
        "    '''\n",
        "    return np.clip(dataset_add_mean(dataset*2.0 - 1, mean).astype(np.float32),0,1.0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "backup_train = training_images.copy()\n",
        "backup_val = val_images.copy()\n",
        "\n",
        "\n",
        "if use_mean_subtraction:\n",
        "    print(\"Training before normalization\")\n",
        "    print(\"Type = \" + str(training_images[0].dtype))\n",
        "    print(\"min = \" + str(np.min(training_images[0:1,:])))\n",
        "    print(\"max = \" + str(np.max(training_images[0:1,:])))\n",
        "\n",
        "\n",
        "    training_images = dataset_normalize(training_images, MEAN_TRAIN_IMAGE)\n",
        "    val_images = dataset_normalize(val_images, MEAN_TRAIN_IMAGE)\n",
        "\n",
        "    print(\"Training after normalization\")\n",
        "    print(\"Type = \" + str(training_images[0].dtype))\n",
        "    print(\"min = \" + str(np.min(training_images[0:1,:])))\n",
        "    print(\"max = \" + str(np.max(training_images[0:1,:])))\n",
        "\n",
        "\n",
        "    print(\"Training after denormalization\")\n",
        "    print(\"Type = \" + str(dataset_denormalize(training_images[0]).dtype))\n",
        "    print(\"min = \" + str(np.min(dataset_denormalize(training_images[0:1,:]))))\n",
        "    print(\"max = \" + str(np.max(dataset_denormalize(training_images[0:1,:]))))\n",
        "\n",
        "\n",
        "    plot_matrix(dataset_denormalize(training_images[0:12,:]), labels = training_labels_str[0:12], sq_size=sq_size, scale = 1)\n",
        "    plot_matrix(dataset_denormalize(val_images[0:12,:]), labels = val_labels_str[0:12], sq_size=sq_size, scale = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NX4nrOicvOD",
        "colab_type": "text"
      },
      "source": [
        "### Data distribution analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocq5Riw1dxvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "plot dataset distribution\n",
        "'''\n",
        "local_training_ids = get_ids('training', 'classification')\n",
        "local_validation_ids = get_ids('validation', 'classification')\n",
        "\n",
        "local_training_labels = get_class_labels_str(local_training_ids,remove_difficult = False,)\n",
        "local_training_labels =  multiLabelBinarizer.fit_transform(local_training_labels)\n",
        "local_val_labels = get_class_labels_str(local_validation_ids,remove_difficult = False,)\n",
        "local_val_labels =  multiLabelBinarizer.fit_transform(local_val_labels)\n",
        "\n",
        "print(\"VOC training ids (not enlarged) = \", len(local_training_ids))\n",
        "print(\"VOC validation ids (not enlarged) = \", len(local_validation_ids))\n",
        "\n",
        "local_hist_train = np.sum(local_training_labels, axis=0)\n",
        "local_hist_val = np.sum(local_val_labels, axis=0)\n",
        "\n",
        "# fig, axes = plt.subplots(2,2,sharex = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfSsdulEVDak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local_df = pd.DataFrame({ \"class\" : classes_names, \\\n",
        "                         \"training_original\" : 100*local_hist_train/np.sum(local_hist_train), \\\n",
        "                         \"training_used\": 100*np.sum(training_labels_binarized, axis=0) / np.sum(np.sum(training_labels_binarized, axis=0)), \\\n",
        "                         \"validation_original\" : 100*local_hist_val/np.sum(local_hist_val), \\\n",
        "                         \"validation_used\": 100*np.sum(val_labels_binarized, axis=0) / np.sum(np.sum(val_labels_binarized, axis=0))})\n",
        "print(local_df.to_string())\n",
        "fig, ax = plt.subplots(1,1, figsize = (12,6))\n",
        "local_df.set_index( local_df[\"class\"] ).plot.bar(ax = ax);\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXrRaeitlzWf",
        "colab_type": "text"
      },
      "source": [
        "> How many are multilabels ?\n",
        "> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NG_enBnlyr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(training_labels_binarized.shape)\n",
        "sum_training_labels_binarized = np.sum(training_labels_binarized, axis=-1)\n",
        "# print(sum_training_labels_binarized.shape)\n",
        "sum_training_labels_binarized_count=np.bincount(sum_training_labels_binarized)\n",
        "# print(sum_training_labels_binarized_count)\n",
        "\n",
        "# print(val_labels_binarized.shape)\n",
        "sum_val_labels_binarized = np.sum(val_labels_binarized, axis=-1)\n",
        "# print(sum_val_labels_binarized.shape)\n",
        "sum_val_labels_binarized_count=np.bincount(sum_val_labels_binarized)\n",
        "# print(sum_val_labels_binarized_count)\n",
        "\n",
        "print(\"Proportion of multilabeled images in Classification training:\\n\" + str( 1- sum_training_labels_binarized_count[1] / np.sum(sum_training_labels_binarized_count) ))\n",
        "print(\"Proportion of multilabeled images in Classification validation:\\n\" + str( 1- sum_val_labels_binarized_count[1] / np.sum(sum_val_labels_binarized_count) ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH7K1sBKGgx2",
        "colab_type": "text"
      },
      "source": [
        "Classes balance discussion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBi5hRDRGm_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "From the number of samples, we known also the original classes weights in the training (and val)\n",
        "distribution\n",
        "'''\n",
        "classes_weights = np.sum(training_labels_binarized == 1, axis = 0) / training_labels_binarized.shape[0]\n",
        "print(classes_weights)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vciu8Lxre1Bx",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation - tensorflow & Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmyxj9YEfPIf",
        "colab_type": "text"
      },
      "source": [
        "In order to ease the manipulation of the data, it appears important to be able to:\n",
        "- easily get the images from particular classes only\n",
        "- generate batches of images in an efficient way, because running from images can take a lot of time, and as training requires several tens (hundreds) of epoch runs, one may want to efficiently load the data. It has been a key exercice to try and optimize, without completely refactoring the structure, to load the data in an efficient and convenient way.\n",
        "    * including data augmentation\n",
        "    * including caching if possible\n",
        "    * including pre-fetching\n",
        "\n",
        "To build the input pipeline, I choose first to gather all the relevant information that have been extracted so far into a dataframe (from Pandas). A df can be later used by different generators according to the needs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CChuJuVMe6HY",
        "colab_type": "text"
      },
      "source": [
        "#### Selecting subset of classes\n",
        "\n",
        "If the problem appears unbalanced, it may be good to analyze the behavior for only a subset of classes. The few code snippets below give that opportunity. \n",
        "\n",
        "$\\Rightarrow$ It results in a dataframe containing only (identifiers of) images from subset of classes, with the labels modified accordingly\n",
        "\n",
        "In short we:\n",
        "* need to remove from the labels the classes not used (so that binarization can happen well)\n",
        "* need functions to properly select images based on the selected classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zap6Ku7n9NQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        "returns the tuple given as input cleared out from undesired classes. \n",
        "'''\n",
        "def _keep_classes_only(tuple_of_classes, tuple_of_classes_to_keep):\n",
        "    return tuple([ x for x in tuple_of_classes if x in tuple_of_classes_to_keep])\n",
        "\n",
        "'''\n",
        "example of used\n",
        "'''\n",
        "print(_keep_classes_only(('bicycle', 'car', 'cat', 'dog'), ('cat', 'dog')))\n",
        "print(_keep_classes_only(('bicycle', 'horse', 'cat', 'boat', 'aeroplane'), ('cat', 'dog')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REldihh_whda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "gets a dataframe containing only filepath and classes for given tuple of classes\n",
        "'''\n",
        "def get_dataframe_from_classes(my_df, tuple_of_classes):\n",
        "    '''\n",
        "    tuple_of_classes = tuple of string classes \n",
        "    returns a sliced dataframe containing rows of desired classes. \n",
        "\n",
        "    '''\n",
        "    classes_of_interest_binarized =  multiLabelBinarizer.transform(( tuple_of_classes ,))[0]    \n",
        "    bits_of_interest = np.where(classes_of_interest_binarized == 1)[0]\n",
        "    indexes_to_retain = [index_row for index_row in range(0, len(my_df[\"class\"])) if sum( multiLabelBinarizer.transform(( my_df[\"class\"][index_row] ,))[0][bits_of_interest]) > 0]\n",
        "    df_sliced = my_df.loc[indexes_to_retain,:].copy()\n",
        "    df_sliced[\"class\"] = [ _keep_classes_only(x, tuple_of_classes) for x in df_sliced['class']]    \n",
        "    return df_sliced\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZKUiM4aiEKl",
        "colab_type": "text"
      },
      "source": [
        "Toy example of use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBHwfRUNwj3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dico = {\"filename\":[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\"], \n",
        "        \"class\": [('aeroplane',), ('bicycle',), ('aeroplane', 'bicycle'), ('bird',), ('aeroplane', 'bird'), ('bicycle', 'bird'), ('aeroplane', 'bicycle', 'bird'), ('boat',)]}\n",
        "df_dico = pd.DataFrame(data = dico)\n",
        "print(\"Original dataframe:\\n\")\n",
        "print(df_dico)\n",
        "\n",
        "print(\"\\n\\nOutput dataframe:\\n\")\n",
        "df_sliced = get_dataframe_from_classes(df_dico, ('aeroplane','bicycle'))\n",
        "print(df_sliced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTpgSSbrixeg",
        "colab_type": "text"
      },
      "source": [
        "####Create base dictionary\n",
        "\n",
        "At this point, we have the tools to build the dataframe. The next code snippets:  \n",
        "1. Build a dictionary\n",
        "2. Build a pandas Dataframe from this dictionary\n",
        "3. Build the tensorflow efficient data pipeline\n",
        "\n",
        "\n",
        "The name of the variable is kept as explicit as possible\n",
        "\n",
        ">`name` | type | description\n",
        ">---|---|---\n",
        ">`d_class_train` | dictionary | training dictionary for classification\n",
        ">`d_class_val` | dictionary | validation dictionary for classification\n",
        ">`df_class_train` | dataframe | training dataframe for classification\n",
        ">`df_class_val` | dataframe | validation dataframe for classification\n",
        "\n",
        "\n",
        "The two datagrames are the reference and the very input of the data pipeline preparation. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNz19f69e4Iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "classification\n",
        "'''\n",
        "d_class_train = {'filename': [sub + '.jpg' for sub in training_ids] , 'class': training_labels_str}\n",
        "d_class_val   = {'filename': [sub + '.jpg' for sub in val_ids] , 'class': val_labels_str}\n",
        "\n",
        "df_class_train = pd.DataFrame(data=d_class_train)\n",
        "df_class_val   = pd.DataFrame(data=d_class_val)\n",
        "\n",
        "df_class_train_cat_dog= get_dataframe_from_classes(df_class_train, ('cat','dog'))\n",
        "df_class_val_cat_dog = get_dataframe_from_classes(df_class_val, ('cat','dog'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# df_class_train\n",
        "# df_class_val\n",
        "# df_class_train_cat_dog\n",
        "# df_class_val_cat_dog\n",
        "\n",
        "'''\n",
        "Dataframe for segmentation isn't exactly the same format\n",
        "suggestion TODO => change : one dictionary for all...\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJX9eUFB8oyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20-GClOBnafp",
        "colab_type": "text"
      },
      "source": [
        "Final step: definition of the dataframe that are used in the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAI5Gr5qniYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "classification part\n",
        "'''\n",
        "df_class_train_to_generate = df_class_train #df_class_train_cat_dog\n",
        "df_class_val_to_generate = df_class_val # df_class_val_cat_dog\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lto-JyfxjEkb",
        "colab_type": "text"
      },
      "source": [
        "#### Input pipeline\n",
        "\n",
        "So far, we have loaded images in RAM, and we have structures containing information about where is what. \n",
        "\n",
        "Considering the resources available, we want an input pipeline as efficient as possible. We need:\n",
        "- to provide to training (later) the images and the labels\n",
        "- to augment the data, as preliminary tests indicated huge overfitting, very fast. the database being rather small after all, we need to make it larger\n",
        "- to do it FAST! considering the resources available (human and machine)\n",
        "\n",
        "Two alternatives are built and benchmarked (the benchmark tests are skipped in the nominal version, results are in the presentation)\n",
        "\n",
        "1. tf.keras.ImageDataGenerator API\n",
        "2. tf.Data API\n",
        "\n",
        "This last is the fastest, by far, and is selected (although harder to get acquainted with...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeeqAVm22xud",
        "colab_type": "text"
      },
      "source": [
        "##### From tf.Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEORTEU_o1Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.tensorflow.org/tutorials/load_data/images\n",
        "\n",
        "def parse_function(filename, label):\n",
        "    '''\n",
        "    based on the filename and label, returns a resized float32, \"normalized\" images from JPEGImages folder\n",
        "    '''\n",
        "    filename = voc_root_folder+r'/JPEGImages/'+filename\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "\n",
        "    #This will convert to float values in [0, 1]\n",
        "    #  get the input_image in float32, between 0 and 1\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.image.resize(image, [sq_size, sq_size])\n",
        "    # image, label = classification_normalize(image, label)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def classification_normalize(input_image, input_label):\n",
        "    '''\n",
        "    SKIPPED - does not seem to help!\n",
        "\n",
        "    pre: the MEAN_TRAIN_IMAGE shall be available in the environmnet\n",
        "\n",
        "    input: an input_image, tensor image,  dtype = tf.float32, values between 0.0 and 1.0; \n",
        "           an input_label,\n",
        "    returns: - the image input_image with the mean of the training set substracted, \n",
        "            with px values still within 0.0 and 1.0;\n",
        "             - the input_label (wo transformation)\n",
        "    '''\n",
        "    # substract the mean\n",
        "    input_image = ((input_image - MEAN_TRAIN_IMAGE) + 1) / 2.0\n",
        "\n",
        "    return input_image[0], input_label\n",
        "\n",
        "\n",
        "\n",
        "def classification_denormalize(input_image, input_label):\n",
        "    '''\n",
        "    pre: the MEAN_TRAIN_IMAGE shall be available in the environmnet\n",
        "\n",
        "    input: an input_image, tensor image,  dtype = tf.float32, values between 0.0 and 1.0; \n",
        "           an input_label,\n",
        "    returns: - the image input_image with the mean of the training set added, \n",
        "            with px values still within 0.0 and 1.0;\n",
        "             - the input_label (wo transformation)\n",
        "    '''\n",
        "    input_image = (( (input_image*2.0) -1) + MEAN_TRAIN_IMAGE)\n",
        "    input_image = tf.clip_by_value(input_image, 0.0, 1.0)\n",
        "    return input_image[0], input_label\n",
        "\n",
        "\n",
        "\n",
        "def train_classification_preprocess(image, label):\n",
        "    '''\n",
        "    input:  - a tensor image, dtype float32, values between 0.0 and 1.0\n",
        "            - the corresponding label\n",
        "    returns a preprocessed image (values clipped between 0.0 and 1.0) and corresponding label.\n",
        "    The preprocessing steps are:\n",
        "    - random horizontal flip\n",
        "    - random brightness change\n",
        "    - random saturation change\n",
        "    - random contrast change\n",
        "    - random cropping \n",
        "    - random rotation\n",
        "    \n",
        "    '''\n",
        "\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    \n",
        "    \n",
        "    image = tf.image.random_brightness(image, max_delta=0.3)\n",
        "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
        "    image = tf.image.random_contrast(image, 0.85, 1.15)\n",
        "\n",
        "    \n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.resize_with_crop_or_pad(image, sq_size+25, sq_size+25) # Add 6 pixels of padding\n",
        "        image = tf.image.random_crop(image, size=[sq_size, sq_size, 3])\n",
        "       \n",
        "    # randomly rotate image\n",
        "    # Requires tfa nightly built\n",
        "    if int(tfa.__version__.split('.')[1]) > 8:\n",
        "        angle=tf.random.uniform(shape=[], minval=-np.pi/7, maxval=np.pi/7)\n",
        "        image = tfa.image.rotate(image, angle)\n",
        "        image = tf.image.central_crop(image, 0.70)\n",
        "        image = tf.image.resize(image,  size = [sq_size, sq_size])\n",
        "\n",
        "\n",
        "    #Make sure the image is still in [0, 1]\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "\n",
        "def get_classification_generator(dataframe, multiLabelBinarizer, to_augment = True, cache=True, model = None):\n",
        "    '''\n",
        "    input:  - a dataframe containing a column \"filename\" and a column \"class\" (see above)\n",
        "            - a multiLabelBinarizer to convert the label into one hot encoding\n",
        "            - a boolean \"to_augment\" indicating if the pre-processing steps needs to be applied (training: True, validation: False)\n",
        "            - cache: if string, indicates where to cache. Else, cache in RAM\n",
        "            - model: Not used   \n",
        "\n",
        "    returns a tensorflow efficient and cached classification generator\n",
        "    '''\n",
        "    _filenames = list(dataframe[\"filename\"])\n",
        "    _labels = multiLabelBinarizer.fit_transform(tuple(dataframe[\"class\"]))\n",
        "\n",
        "    tf_generator = tf.data.Dataset.from_tensor_slices(( _filenames, _labels))\n",
        "    tf_generator = tf_generator.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "\n",
        "    if isinstance(cache, str):\n",
        "        tf_generator = tf_generator.cache(cache)\n",
        "    else:\n",
        "        tf_generator = tf_generator.cache()\n",
        "    \n",
        "\n",
        "    if to_augment:\n",
        "        tf_generator = tf_generator.map(train_classification_preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    \n",
        "    tf_generator = tf_generator.shuffle(len(_filenames), seed = 426473 )\n",
        "    tf_generator = tf_generator.repeat()\n",
        "    tf_generator = tf_generator.batch(BATCH_SIZE)\n",
        "    tf_generator = tf_generator.prefetch(buffer_size = AUTOTUNE)\n",
        "    return tf_generator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Td9c_Mgn1No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Effectively build the generators\n",
        "'''\n",
        "training_set_class_tf_generator = get_classification_generator(df_class_train_to_generate, multiLabelBinarizer, to_augment = True)\n",
        "val_set_class_tf_generator      = get_classification_generator(df_class_val_to_generate, multiLabelBinarizer, to_augment = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDJ9gYhEoYup",
        "colab_type": "text"
      },
      "source": [
        "Toy test of the pipeline to make sure steps are well respected. This is purely local and is skipped in the nominal run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PklOxFzJGir9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "test the classification pipeline (specifically normalization and denormalization)\n",
        "'''\n",
        "test_the_classification_pipeline = False\n",
        "if test_the_classification_pipeline:\n",
        "    _filenames = list(df_class_train_to_generate[\"filename\"])\n",
        "    _labels = multiLabelBinarizer.fit_transform(tuple(df_class_train_to_generate[\"class\"]))\n",
        "    filename = _filenames[0]\n",
        "    filename = voc_root_folder+r'/JPEGImages/'+filename\n",
        "    label = _labels[0]\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    tf.print(\"original\")\n",
        "    tf.print(\"min = \" + str(np.min(image.numpy())))\n",
        "    tf.print(\"max = \" + str(np.max(image.numpy())))\n",
        "    #This will convert to float values in [0, 1]\n",
        "    print(image.shape)\n",
        "\n",
        "    image = tf.cast(image, tf.float32)/255.0\n",
        "    tf.print(\"after convert to float32\")\n",
        "    tf.print(\"min = \" + str(np.min(image.numpy())))\n",
        "    tf.print(\"max = \" + str(np.max(image.numpy())))\n",
        "\n",
        "    image = tf.image.resize(image, [sq_size, sq_size])\n",
        "    image, label = classification_normalize(image, label) #    input_image  = (input_image - MEAN_TRAIN_IMAGE) / tf.cast(tf.sqrt(STD_TRAIN_IMAGE + 1e-8), dtype = 'float32') return ...[0]\n",
        "    tf.print(\"after normalization\")\n",
        "    tf.print(\"min = \" + str(np.min(image.numpy())))\n",
        "    tf.print(\"max = \" + str(np.max(image.numpy())))\n",
        "\n",
        "    image, label = classification_denormalize(image, label) #    input_image  = (input_image - MEAN_TRAIN_IMAGE) / tf.cast(tf.sqrt(STD_TRAIN_IMAGE + 1e-8), dtype = 'float32') return ...[0]\n",
        "    tf.print(\"after denormalization\")\n",
        "    tf.print(\"min = \" + str(np.min(image.numpy())))\n",
        "    tf.print(\"max = \" + str(np.max(image.numpy())))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDZyx2rcoMMw",
        "colab_type": "text"
      },
      "source": [
        "##### From Keras API\n",
        "Simpler but slower method to build a generator a data, using augmentation\n",
        "This is not used anymore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW9DPoouoEsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Alternative using simpler but slower ImageDataGenerator\n",
        "'''\n",
        "images_generator_training = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255, \n",
        "                    \n",
        "                                                                            featurewise_center=False,\n",
        "                                                                            featurewise_std_normalization=False,\n",
        "\n",
        "                                                                            rotation_range = 20,\n",
        "                                                                            width_shift_range = .2,\n",
        "                                                                            height_shift_range = .2,\n",
        "                                                                            horizontal_flip = True,\n",
        "                                                                            zoom_range = 0.2,\n",
        "                                                                            )\n",
        "\n",
        "images_generator_validation = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255, \n",
        "                                                                              featurewise_center=False,\n",
        "                                                                              featurewise_std_normalization=False)\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "# images_generator_training.fit(training_images)\n",
        "# images_generator_validation.fit(training_images)\n",
        "\n",
        "def get_classification_keras_generator(dataframe, mode, seed = 426473, BS = BS, sq_size = sq_size):\n",
        "    if mode == 'training':\n",
        "        return images_generator_training.flow_from_dataframe(dataframe, \n",
        "                                              directory = voc_root_folder+r'/JPEGImages/', \n",
        "                                              x_col='filename', \n",
        "                                              y_col='class', \n",
        "                                              class_mode='categorical',\n",
        "                                              target_size = (sq_size, sq_size), \n",
        "                                              batch_size = BS,\n",
        "                                              shuffle = True, \n",
        "                                              seed = seed,\n",
        "                                              )\n",
        "    elif mode == 'validation':\n",
        "        return images_generator_validation.flow_from_dataframe(dataframe, \n",
        "                                              directory = voc_root_folder+r'/JPEGImages/', \n",
        "                                              x_col='filename', \n",
        "                                              y_col='class', \n",
        "                                              class_mode='categorical',\n",
        "                                              target_size = (sq_size, sq_size), \n",
        "                                              batch_size = BS,\n",
        "                                              shuffle = True, \n",
        "                                              seed = seed,\n",
        "                                              )\n",
        "    else:\n",
        "        raise ValueError('mode unknown')\n",
        "\n",
        "train_img_gen = get_classification_keras_generator(df_class_train_to_generate, mode = 'training')\n",
        "val_img_gen = get_classification_keras_generator(df_class_val_to_generate, mode = 'validation')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs8cZPy3pWwz",
        "colab_type": "text"
      },
      "source": [
        "####Benchmarking the two API's \n",
        "Benchmark of `tf.Data` and `tf.keras.preprocessing.image.ImageDataGenerator`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLW1dsbjpy8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perform_benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmxs9D_dx0NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "default_timeit_steps = 1000\n",
        "\n",
        "def timeit(ds, steps=default_timeit_steps):\n",
        "    '''\n",
        "    Credit: https://www.tensorflow.org/tutorials/load_data/images\n",
        "    '''\n",
        "    start = time.time()\n",
        "    it = iter(ds)\n",
        "    for i in range(steps):\n",
        "        batch = next(it)\n",
        "        if i%10 == 0:\n",
        "            print('.',end='')\n",
        "    print()\n",
        "    end = time.time()\n",
        "\n",
        "    duration = end-start\n",
        "    print(\"{} batches: {} s\".format(steps, duration))\n",
        "    print(\"{:0.5f} Images/s\".format(BATCH_SIZE*steps/duration))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q75zO_O_blc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if perform_benchmark:\n",
        "    timeit(training_set_class_tf_generator)\n",
        "    timeit(val_set_class_tf_generator)\n",
        "    print(\"===\"*25)\n",
        "    timeit(train_img_gen)\n",
        "    timeit(val_img_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW1bOhJmBzwn",
        "colab_type": "text"
      },
      "source": [
        "# Classification Tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6fE2gGofgza",
        "colab_type": "text"
      },
      "source": [
        "### Data checkup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whs57rLCs_fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "For each classification sets (training and validation), show one batch\n",
        "'''\n",
        "\n",
        "print(\"Training Set\")\n",
        "for image_train_batch, label_train_batch in training_set_class_tf_generator.take(1):\n",
        "    pass\n",
        "\n",
        "label_train_batch_str = multiLabelBinarizer.inverse_transform(np.array(label_train_batch))\n",
        "\n",
        "plot_matrix(image_train_batch, label_train_batch_str, scale = 2)\n",
        "# plot_matrix(dataset_denormalize(image_train_batch.numpy()), label_train_batch_str, scale = 2)\n",
        "\n",
        "print(\"==\"*30)\n",
        "\n",
        "print(\"Validaton Set\")\n",
        "for image_val_batch, label_val_batch in val_set_class_tf_generator.take(1):\n",
        "    pass\n",
        "\n",
        "label_val_batch_str = multiLabelBinarizer.inverse_transform(np.array(label_val_batch))\n",
        "\n",
        "plot_matrix(image_val_batch, label_val_batch_str, scale = 2)\n",
        "# plot_matrix(dataset_denormalize(image_val_batch.numpy()), label_val_batch_str, scale = 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctxu7rmhnbk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height = sq_size\n",
        "width = sq_size\n",
        "channel = 3\n",
        "print(height)\n",
        "print(width)\n",
        "print(channel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGLA6ATmYZfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "This cell is a sandbox\n",
        "'''\n",
        "print(\"sandbox\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFMCq1gZxHfs",
        "colab_type": "text"
      },
      "source": [
        "Based on the probabilities of each class (training set), we should define an initializer for the bias of the last layer. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1-ow8dAOCKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyBiasInitializer(tf.keras.initializers.Initializer):\n",
        "\n",
        "    #- np.log( (np.ones(classes_weights.shape) - classes_weights) / classes_weights)\n",
        "    def __call__(self, shape, dtype=None):\n",
        "        return tf.convert_to_tensor( - np.log( (np.ones(classes_weights.shape) - classes_weights) / classes_weights) , dtype='float32')\n",
        "\n",
        "    def get_config(self):  # To support serialization\n",
        "        return {'init_weights' : classes_weights}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQkJwgSa4amm",
        "colab_type": "text"
      },
      "source": [
        "### Model Class\n",
        "To ease the model retrieval, we encapsulate the building of the network in a class, using static method. \n",
        " (note: this would need to be refactored as a class inheriting from Model to improve clarity and modularity, and ease further development)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYqWSr8lhym7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Gr8ClassNet:\n",
        "\n",
        "    @staticmethod\n",
        "    def build(width, height, channel, \n",
        "              dropout = False, \n",
        "              batch_normalization = False, \n",
        "              extra_dense = False, \n",
        "              extra_convolution_batch = False, \n",
        "              l2_reg = (0,0), classification_type=classification_type, num_classes = 20):\n",
        "        tf.print(classification_type)\n",
        "        inputShape = (height, width, channel)\n",
        "\n",
        "        lambda_fc = l2_reg[0]\n",
        "        lambda_conv = l2_reg[1]\n",
        "\n",
        "        '''\n",
        "        Classification type used\n",
        "        '''\n",
        "        output_activation_function = \"unknown\"\n",
        "        if classification_type == \"single\":\n",
        "            output_activation_function = \"softmax\"\n",
        "        elif classification_type == \"multilabel\":\n",
        "            output_activation_function = \"sigmoid\"\n",
        "        else:\n",
        "            raise ValueError(\"classification_type value unknown\")\n",
        "\n",
        "\n",
        "        model = tf.keras.models.Sequential()\n",
        "\n",
        "\n",
        "        # CONV => RELU => POOL\n",
        "        model.add(tf.keras.layers.Conv2D(32, \n",
        "                                         (3, 3), \n",
        "                                         padding=\"same\", \n",
        "                                         strides = (1,1),\n",
        "                                         input_shape=inputShape,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(lambda_conv),\n",
        "                                         name = 'conv1',\n",
        "                                         ))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "        \n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))  \n",
        "\n",
        "        if dropout:\n",
        "            model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        ######################################################################\n",
        "        model.add(tf.keras.layers.Conv2D(64, \n",
        "                                        (3, 3), \n",
        "                                        padding=\"same\",\n",
        "                                        kernel_regularizer=tf.keras.regularizers.l2(lambda_conv),\n",
        "                                        name = 'conv2',) )\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        if dropout:\n",
        "            model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        if dropout:\n",
        "            model.add(tf.keras.layers.Dropout(0.3))\n",
        "  \n",
        "        if extra_convolution_batch:\n",
        "                    # (CONV => RELU) * 2 => POOL\n",
        "            ######################################################################\n",
        "            model.add(tf.keras.layers.Conv2D(192, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "            model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "            model.add(tf.keras.layers.Conv2D(192, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "            model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "            model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "            if dropout:\n",
        "                model.add(tf.keras.layers.Dropout(0.3))\n",
        "            \n",
        "            \n",
        "            model.add(tf.keras.layers.Conv2D(192, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "            model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "            model.add(tf.keras.layers.Conv2D(192, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "            model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "            model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "            if dropout:\n",
        "                model.add(tf.keras.layers.Dropout(0.3))\n",
        "            \n",
        "\n",
        "        # first (and only) set of FC => RELU tf.keras.layers\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(lambda_fc)))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "        if extra_dense:\n",
        "            model.add(tf.keras.layers.Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(lambda_fc)))\n",
        "            if batch_normalization:\n",
        "                model.add(tf.keras.layers.BatchNormalization())\n",
        "            model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "        if dropout:\n",
        "            model.add(tf.keras.layers.Dropout(0.3))\n",
        "        \n",
        "        # use a *softmax* activation for single-label classification\n",
        "        # and *sigmoid* activation for multi-label classification\n",
        "        model.add(tf.keras.layers.Dense(num_classes,  kernel_regularizer=tf.keras.regularizers.l2(lambda_fc))) #bias_initializer = MyBiasInitializer(),\n",
        "        model.add(tf.keras.layers.Activation(output_activation_function))\n",
        "        return model\n",
        "    \n",
        "    @staticmethod\n",
        "    def build_second(width, height, channel, \n",
        "                    dropout = False, \n",
        "                    batch_normalization = False, \n",
        "                    extra_dense = False, \n",
        "                    extra_convolution_batch = False, \n",
        "                    l2_reg = (0,0), classification_type=classification_type, num_classes = 20):\n",
        "\n",
        "        inputShape = (height, width, channel)\n",
        "\n",
        "        lambda_fc = l2_reg[0]\n",
        "        lambda_conv = l2_reg[1]\n",
        "        classification_type = \"multilabel\"\n",
        "        output_activation_function = \"sigmoid\"\n",
        "        model = tf.keras.models.Sequential()\n",
        "        \n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization( input_shape=inputShape,))\n",
        "\n",
        "        # CONV => RELU => POOL\n",
        "        model.add(tf.keras.layers.Conv2D(64, \n",
        "                                         (5, 5), \n",
        "                                         padding=\"same\", \n",
        "                                         strides = (2,2),\n",
        "                                         input_shape=inputShape,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(lambda_conv),\n",
        "                                         name = 'conv1'))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization(input_shape=inputShape,))\n",
        "\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "        model.add(tf.keras.layers.Conv2D(64, \n",
        "                                         (3, 3), \n",
        "                                         padding=\"same\", \n",
        "                                         strides = (1,1),\n",
        "                                        #  input_shape=inputShape,\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(lambda_conv),\n",
        "                                         name = 'conv1bis'))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization(input_shape=inputShape,))\n",
        "\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))  \n",
        "\n",
        "        if dropout:\n",
        "            model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        ######################################################################\n",
        "        model.add(tf.keras.layers.Conv2D(128, \n",
        "                                        (3, 3),\n",
        "                                        strides = (1,1), \n",
        "                                        padding=\"same\",\n",
        "                                        kernel_regularizer=tf.keras.regularizers.l2(lambda_conv),\n",
        "                                        name = 'conv2') )\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "        if dropout:\n",
        "            model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "        # (CONV => RELU) * 2 => POOL\n",
        "        model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "        model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "        if batch_normalization:\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "        if dropout:\n",
        "            model.add(tf.keras.layers.Dropout(0.3))\n",
        "  \n",
        "        if extra_convolution_batch:\n",
        "                    # (CONV => RELU) * 2 => POOL\n",
        "            ######################################################################\n",
        "            model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "            model.add(tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "            model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "            model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "            model.add(tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "            model.add(tf.keras.layers.BatchNormalization())\n",
        "            model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "            # model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\n",
        "            # model.add(tf.keras.layers.Conv2D(512, (3, 3), padding=\"valid\",kernel_regularizer=tf.keras.regularizers.l2(lambda_conv)))\n",
        "            # model.add(tf.keras.layers.BatchNormalization())\n",
        "            # model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "            \n",
        "            if dropout:\n",
        "                model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "        # first (and only) set of FC => RELU tf.keras.layers\n",
        "        model.add(tf.keras.layers.GlobalMaxPooling2D())\n",
        "        # model.add(tf.keras.layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(lambda_fc)))\n",
        "        # model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "        \n",
        "        if extra_dense:\n",
        "            model.add(tf.keras.layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(lambda_fc)))\n",
        "            if batch_normalization:\n",
        "                model.add(tf.keras.layers.BatchNormalization())\n",
        "            model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "            # model.add(tf.keras.layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(lambda_fc)))\n",
        "            # if batch_normalization:\n",
        "            #     model.add(tf.keras.layers.BatchNormalization())\n",
        "            # model.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\n",
        "        \n",
        "        # use a *softmax* activation for single-label classification\n",
        "        # and *sigmoid* activation for multi-label classification\n",
        "        model.add(tf.keras.layers.Dense(num_classes, kernel_regularizer=tf.keras.regularizers.l2(lambda_fc))) #bias_initializer = MyBiasInitializer,\n",
        "        model.add(tf.keras.layers.Activation(output_activation_function))\n",
        "        return model\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu0dUQIgpWcJ",
        "colab_type": "text"
      },
      "source": [
        "Definition of a dictionnary to contain all the models histories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euhqxwp4pcNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try:\n",
        "#     histories = pickle.load(open(histories_filename, \"rb\")\n",
        "# except: \n",
        "#     print(\"No histories path found, creating a new one instead\")\n",
        "#     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9wMkCXAC1ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INIT_LR = 1e-4\n",
        "BS = 32\n",
        "STEPS_PER_EPOCH = 100\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(INIT_LR,  \n",
        "                                                             decay_steps=STEPS_PER_EPOCH*100,  \n",
        "                                                             decay_rate=1,  \n",
        "                                                             staircase=True)\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zopnIum5HMeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "step = np.linspace(0,100000)\n",
        "lr = lr_schedule(step)\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(step/STEPS_PER_EPOCH, lr)\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.xlabel('Epoch')\n",
        "_ = plt.ylabel('Learning Rate')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13cjlriKmg4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save_weights(filename)\n",
        "# model.load_weights(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8h-VW225HJ_",
        "colab_type": "text"
      },
      "source": [
        "### Callbacks \n",
        " Here, I create a custom callback class (following [Callbacks](https://www.tensorflow.org/guide/keras/custom_callback#introduction_to_keras_callbacks)) in order to retrieve information during training, and implement early stopping. \n",
        "=> not needed; it exists natively in tensorflow : [Early Stopping] (https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/EarlyStopping)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5zt7_SrEj24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "!mkdir logs\n",
        "logdir = r'logs/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RkavN-h7FWW",
        "colab_type": "text"
      },
      "source": [
        "Early Stopping callbacks, on the two losses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF3SfQXL5hcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_earlyStopping_val = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "callback_earlyStopping_train = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "my_callbacks = [callback_earlyStopping_train, callback_earlyStopping_val, ] #tensorboard_callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MydSO377NK2",
        "colab_type": "text"
      },
      "source": [
        "### Metrics\n",
        "\n",
        "In the multilabel case, binary accuracy may be used as a metric to monitor the training. Another interesting value is also the jaccard index. Snippet code below computes the Jaccard index, and shows in a toy example the interest\n",
        "\n",
        "Interestingly, it is usually used in the context of semantic segmentation (see next task) but we may as well use it for multilabel classification, see [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vx6TdGgmbUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard_index(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    >CREDIT : https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/jaccard.py\n",
        "    > \n",
        "    \n",
        "    Modified original description below ==> see source\n",
        "    Also known as the intersection-over-union loss.\n",
        "    [...]\n",
        "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
        "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
        "    # Arguments\n",
        "        y_true: The ground truth tensor.\n",
        "        y_pred: The predicted tensor\n",
        "    # Returns\n",
        "        The Jaccard index between the two tensors.\n",
        "    # References\n",
        "        - [What is a good evaluation measure for semantic segmentation?](\n",
        "           http://www.bmva.org/bmvc/2013/Papers/paper0032/paper0032.pdf)\n",
        "    \"\"\"\n",
        "    # y_pred = tf.round(y_pred)\n",
        "    intersection = tf.math.reduce_sum(tf.math.abs(y_true * y_pred), axis=-1)\n",
        "    sum_ = tf.math.reduce_sum(tf.math.abs(y_true) + tf.math.abs(y_pred), axis=-1)\n",
        "    jac = intersection / (sum_ - intersection + 1e-8)\n",
        "    return jac\n",
        "\n",
        "def jaccard_loss(y_true, y_pred):\n",
        "    return 1 - jaccard_index(y_true, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGd7Hu7cnS_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Comparison between three metrics for a toy problem, with 4 possible classes (multilabel)\")\n",
        "# y0_true = np.array([ [1,1,0,1], [0,0,1,0], [0,1,1,0]])\n",
        "# y0_pred = np.array([ [1,0,0,1], [0,1,0,0], [0,1,1,0]])\n",
        "\n",
        "# y0_true_tf = tf.convert_to_tensor(y0_true, dtype=tf.float32)\n",
        "# y0_pred_tf = tf.convert_to_tensor(y0_pred, dtype=tf.float32)\n",
        "\n",
        "y0_true = np.array([ [  1, 0,   0,]])\n",
        "# y0_pred = np.array([ [.54, 0.4, .12,.51,]]) #, [0,0.6,0.1,0], [0.2,0.7,0.2,0.2]\n",
        "y0_pred = np.array([ [1, 0, 0.4,]]) #, [0,0.6,0.1,0], [0.2,0.7,0.2,0.2]\n",
        "\n",
        "y0_true_tf = tf.convert_to_tensor(y0_true, dtype=tf.float32)\n",
        "y0_pred_tf = tf.convert_to_tensor(y0_pred, dtype=tf.float32)\n",
        "\n",
        "print(\"True labels: \")\n",
        "tf.print(y0_true_tf)\n",
        "print(\"\\nPredictions:\")\n",
        "tf.print(y0_pred_tf)\n",
        "tf.print(\"==\"*30)\n",
        "\n",
        "v = np.linspace(0,1,20)\n",
        "print(v)\n",
        "y0_pred_v = np.tile(y0_pred, (20,1))\n",
        "y0_pred_v[:,2] = v\n",
        "y0_pred_tf_v = tf.convert_to_tensor(y0_pred_v, dtype=tf.float32)\n",
        "\n",
        "res = np.zeros((20,6))\n",
        "print(res.shape)\n",
        "res[:,0] = jaccard_index(y0_true_tf, y0_pred_tf_v)\n",
        "\n",
        "res[:,1] = 1- tfa.metrics.hamming.hamming_loss_fn(y0_true_tf, y0_pred_tf_v, threshold = 0.25, mode = 'multilabel')\n",
        "res[:,2] = 1- tfa.metrics.hamming.hamming_loss_fn(y0_true_tf, y0_pred_tf_v, threshold = 0.50, mode = 'multilabel')\n",
        "res[:,3] = 1- tfa.metrics.hamming.hamming_loss_fn(y0_true_tf, y0_pred_tf_v, threshold = 0.75, mode = 'multilabel')\n",
        "res[:,4] = tf.keras.metrics.binary_accuracy(y0_true_tf, y0_pred_tf_v)\n",
        "res[:,5] = tf.keras.metrics.categorical_accuracy(y0_true_tf,y0_pred_tf_v)\n",
        "fig, ax = plt.subplots(1,1,figsize = (6,6))\n",
        "for i in np.arange(res.shape[1]):\n",
        "    ax.plot(v, res[:,i], '.-')\n",
        "\n",
        "ax.legend([\"Jaccard index\",  \"hamming loss (th=0.25)\", \"hamming loss (th=0.50)\", \"hamming loss (th=0.75)\",\"Binary accuracy\", \"Categorical accuracy\",],\n",
        "          loc = \"lower left\")\n",
        "ax.set_title(\"Variation of metrics with the variation of one prediction output\")\n",
        "ax.set_xlabel(\" value of \\'k\\' prediction\")\n",
        "ax.set_ylabel(\" metric score\")\n",
        "ax.set_ylim(0.45, 1.05)\n",
        "ax.annotate(\"pred = [1,0, k ]\\ntrue = [1, 0, 0]\", (0,0.9))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "tf.keras.metrics.categorical_accuracy(tf.convert_to_tensor(np.array(np.array([1,1,0,1]))), tf.convert_to_tensor(np.array(np.array([1,0,0,1]))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUC7HewMbYTG",
        "colab_type": "text"
      },
      "source": [
        "###Model_v1\n",
        "\"simple\" as only convolution and pooling layers\n",
        "- CONVOLUTION: it learns \"K\" spatial filters, of a size F defined (2 parameters, usually square), applied spatially with a defined strides. The filters apply on the whole volume. As one filter is applied (= convolved) on the input volume, it builds a 2 dimensional activation map, as the response of the convolution applied on the input volume. \n",
        "In [CS231n](https://cs231n.github.io/convolutional-networks/),  several animation shows exactly how the computation are done.\n",
        "The more conv layers, the more complicated features can be learned, but the more complicaed the training is. \n",
        "\n",
        "\n",
        "- POOLING: Usually max pooling or average pooling. Their goal is to decrease dimension, by keeping only the max (or average, typ.) of a spatial area. \n",
        "It is often not popular, because it induces a loss of information. Typically, certain architecture either remove those, using other mechanism to decrease dimensions, or implement some \"skip\" connections, as we'll see in the segmentation task.\n",
        "\n",
        "- FC layers: Fully Connected layer, similarly to \"regular\" shallow feedforward networks, the FC layers are the head of the network, performing the classification based on the features learned already by the convolution part. \n",
        "There also, some research are in favor of going fully convolutional and remove the FC part, as these layers contains the majority of the weights. (the connection matrices are huge compared to CONV layers). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGfNEq4sWf4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [DOES NOT WORK] opt =  tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# [DOES NOT WORK] opt =  tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "my_loss= tf.keras.losses.binary_crossentropy\n",
        "# # Compile the model\n",
        "\n",
        "model_v1 = Gr8ClassNet.build(width, height, channel, \n",
        "                            l2_reg = (0,0),\n",
        "                            num_classes = 20)\n",
        "model_v1.summary()\n",
        "\n",
        "model_v1.compile( optimizer= tf.keras.optimizers.Adam(lr = 0.001), # get_optimizer(), #\n",
        "                        loss= my_loss, # to explain my_loss\n",
        "                        metrics=[jaccard_index, 'accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sew_50TqFIEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo8ka2n4qj2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simple\n",
        "# train_model = True\n",
        "if train_class_model_v1 == True:\n",
        "    history_model_v1= model_v1.fit(   train_img_gen, #training_set_class_tf_generator,\n",
        "                                                        steps_per_epoch= len(training_ids) // BS,\n",
        "                                                        epochs=EPOCHS, \n",
        "                                                        callbacks = my_callbacks,\n",
        "                                                        validation_data=val_set_class_tf_generator,\n",
        "                                                        validation_steps = len(val_ids) // BS)\n",
        "    model_v1.save_weights(model_v1_save_filename)\n",
        "    histories[\"model_v1\"] = history_model_v1.history\n",
        "    pickle.dump(histories[\"model_v1\"], open(model_v1_hist_save_filename, 'wb'))\n",
        "else:\n",
        "    model_v1.load_weights(model_v1_save_filename)\n",
        "    histories['model_v1'] = pickle.load(open(model_v1_hist_save_filename, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6un6K8UTZUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    fig, axes = plt.subplots(2,1,figsize=(8,8))\n",
        "    axes[0].plot(histories[\"model_v1\"]['jaccard_index'], label='jaccard_index')\n",
        "    axes[0].plot(histories[\"model_v1\"]['val_jaccard_index'], label = 'val_jaccard_index')\n",
        "    axes[0].plot(histories[\"model_v1\"]['accuracy'], label='accuracy')\n",
        "    axes[0].plot(histories[\"model_v1\"]['val_accuracy'], label = 'val_accuracy')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Metric')\n",
        "    axes[0].set_ylim([0.0, 1])\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[1].plot(histories[\"model_v1\"]['loss'], label='loss')\n",
        "    axes[1].plot(histories[\"model_v1\"]['val_loss'], label = 'val_loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Binary Cross-entropy')\n",
        "    axes[1].set_ylim([0.0, 1])\n",
        "    axes[1].legend(loc='upper right')\n",
        "    fig.suptitle('Model From Scratch - First architecture')\n",
        "\n",
        "except:\n",
        "    print(\"There was a problem when attempting to plot the curve.\")\n",
        "finally:\n",
        "    print(len(val_images))\n",
        "    scores = model_v1.evaluate(val_images,  val_labels_binarized, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr6GrlF_32rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Get first layer filters\n",
        "'''\n",
        "random_model = Gr8ClassNet.build(width, height, channel)\n",
        "first_layer = random_model.get_layer(name = 'conv1')\n",
        "filters = random_model.get_weights()\n",
        "filters = filters[0]\n",
        "filters_matrix = np.zeros((filters.shape[3],filters.shape[0],filters.shape[1],filters.shape[2]), dtype=np.float32)\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "for i in range(filters.shape[3]):\n",
        "    filters_matrix[i,:,:,:] = filters[:,:,:,i]\n",
        "# plot results\n",
        "plot_matrix(filters_matrix[:,:,:,:], sq_size=filters.shape[0], h = 2, w = 16)\n",
        "# plot_matrix(filters_matrix[:,:,:,1], sq_size=filters.shape[0], h = 2, w = 16)\n",
        "# plot_matrix(filters_matrix[:,:,:,2], sq_size=filters.shape[0], h = 2, w = 16)\n",
        "\n",
        "''' \n",
        "after training\n",
        "'''\n",
        "print(\"==\"*50)\n",
        "# model_v1.load_weights(model_v1_save_filename)\n",
        "first_layer = model_v1.get_layer(name = 'conv1')\n",
        "filters, biases = first_layer.get_weights()\n",
        "\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "filters_matrix = np.zeros((filters.shape[3],filters.shape[0],filters.shape[1],filters.shape[2]), dtype =np.float32)\n",
        "for i in range(filters.shape[3]):\n",
        "    filters_matrix[i,:,:,:] = filters[:,:,:,i]\n",
        "# plot results\n",
        "plot_matrix(filters_matrix[:,:,:,:], sq_size=filters.shape[0], h = 2, w = 16)\n",
        "# plot_matrix(filters_matrix[:,:,:,1], sq_size=filters.shape[0], h = 2, w = 16)\n",
        "# plot_matrix(filters_matrix[:,:,:,2], sq_size=filters.shape[0], h = 2, w = 16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx0hN4_3JOAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = model_v1.predict(val_images)\n",
        "y_hat_round = np.round(y_hat)\n",
        "print(\"Are all the classes at least predicted once ?\")\n",
        "print(y_hat_round.any(axis=0))\n",
        "# with np.printoptions(threshold=np.inf, ):\n",
        "#     print(np.count_nonzero(y_hat_round, axis = 1))\n",
        "print(\"All classes: \")\n",
        "print(classes_names)\n",
        "\n",
        "\n",
        "with np.printoptions(precision=1,linewidth=100): # np.set_printoptions(precision=1,linewidth=100)\n",
        "    print(np.round(y_hat[1:2,:],1))\n",
        "    print(np.round(val_labels_binarized[1:2,:],1))\n",
        "    # print(val_labels_str[1:2])\n",
        "    plot_matrix(val_images[1:2, :, :, :], val_labels_str[1:2], scale = 3)\n",
        "\n",
        "\n",
        "    print(np.round(y_hat[4:5,:],1))\n",
        "    print(np.round(val_labels_binarized[4:5,:],1))\n",
        "    # print(val_labels_str[4:5])\n",
        "    plot_matrix(val_images[4:5, :, :, :], val_labels_str[4:5], scale = 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HWwBJCg2qaT",
        "colab_type": "text"
      },
      "source": [
        "It shows that, considering this (complicated) sigmoid multilabel problem:\n",
        "- it does not always predict the same result (it's good)\n",
        "- it indeed is able to predict two labels for a single sample, hence the multilabel (it's good)\n",
        "- sometimes, it does not predict anything, for instance on sample 0 (it's bad)\n",
        "This charactics is intrisically linked to the multilabeling problem: using the sigmoid output activation function, the labels are independant, and the network is not forced to output one of the classes - it can output none. This is not desirable, but it can happen in this case. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAv27IxRvJwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_batch, label_val_batch = next(iter(val_set_class_tf_generator))\n",
        "\n",
        "y_pred = model_v1.predict(val_batch[4:10])\n",
        "print(multiLabelBinarizer.inverse_transform(np.array(label_val_batch[4:10])))\n",
        "print(multiLabelBinarizer.inverse_transform(np.array(np.round(y_pred))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIwE4mj-HAI6",
        "colab_type": "text"
      },
      "source": [
        "<!-- Score above isn't great, and moreover, it indicates a large gap between training and validation scores. Let's tackle this issue - overfitting - by two differents means:\n",
        "1- data augmentation \n",
        "2- dropout -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iAwnsLHbJwy",
        "colab_type": "text"
      },
      "source": [
        "#### local sandbox \n",
        "*Test* on augmentation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjR-mPWDHP26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the image training data are already rescaled 1/255\n",
        "# to confirm by plotting\n",
        "test_generators = False\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if test_generators:\n",
        "    image_generator_horflip = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./1, horizontal_flip = True)\n",
        "    image_generator_rot     = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./1, rotation_range=45)\n",
        "    image_generator_zoom    = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./1, zoom_range=0.5) # zoom_range from 0 - 1 where 1 = 100%.\n",
        "\n",
        "\n",
        "    train_data_gen_horflip  = image_generator_horflip.flow( training_images, \n",
        "                                                            training_labels_binarized,\n",
        "                                                            seed = 426473)\n",
        "    train_data_gen_rot  = image_generator_rot.flow( training_images, \n",
        "                                                    training_labels_binarized,\n",
        "                                                    seed = 374624)\n",
        "\n",
        "    train_data_gen_zoom = image_generator_zoom.flow( training_images, \n",
        "                                                    training_labels_binarized, \n",
        "                                                    seed = 0)\n",
        "\n",
        "\n",
        "    augmented_images_horflip = [train_data_gen_horflip[0][0][0] for i in range(5)]\n",
        "    augmented_images_rot     = [train_data_gen_rot[0][0][0] for i in range(5)]\n",
        "    augmented_images_zoom    = [train_data_gen_zoom[0][0][0] for i in range(5)]\n",
        "\n",
        "    # This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "\n",
        "    plotImages(augmented_images_horflip)\n",
        "    plotImages(augmented_images_rot)\n",
        "    plotImages(augmented_images_zoom)\n",
        "# plot_matrix(np.array(augmented_images_zoom)*255.0, sq_size = sq_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1egQ_HgCw1W",
        "colab_type": "text"
      },
      "source": [
        "Before setting up the training: time decay learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwB3hBAKNGmp",
        "colab_type": "text"
      },
      "source": [
        "### Model v2\n",
        "**Add** drop out, batch normalization and weight regularization\n",
        "\n",
        "Although drop out and batch normalization don't (always) get along:\n",
        "see [Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift](https://arxiv.org/abs/1801.05134)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEGIKI_v8lyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v2 = Gr8ClassNet.build(width, height, channel, \n",
        "                             dropout = True, \n",
        "                             batch_normalization = True, \n",
        "                             extra_convolution_batch=False, \n",
        "                             extra_dense = False, \n",
        "                             l2_reg=(1e-3,1e-3))\n",
        "model_v2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGyrtO9QNDav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGqsu2ZGNlIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opt =  tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# opt =  tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "# opt = tf.keras.optimizers.RMSprop()\n",
        "\n",
        "if classification_type == \"multilabel\":\n",
        "    my_loss=tf.keras.losses.binary_crossentropy\n",
        "elif classification_type == \"single\":\n",
        "    my_loss=tf.keras.losses.categorical_crossentropy\n",
        "    # my_loss=tf.keras.losses.kullback_leibler_divergence\n",
        "\n",
        "model_v2.compile(optimizer= tf.keras.optimizers.Adam(0.0001), #,\n",
        "                loss=my_loss, # to explain\n",
        "                metrics=[jaccard_index, 'accuracy'])\n",
        "\n",
        "\n",
        "# EPOCHS = 200\n",
        "\n",
        "if train_class_model_v2 == True:\n",
        "    history_model_v2 = model_v2.fit(   train_img_gen, #training_set_class_tf_generator, \n",
        "                                            steps_per_epoch= len(df_class_train_to_generate[\"filename\"]) // BS,\n",
        "                                            epochs=EPOCHS, \n",
        "                                            callbacks=[my_callbacks],\n",
        "                                            validation_data= val_set_class_tf_generator, #val_img_gen, #\n",
        "                                            validation_steps = len(df_class_val_to_generate[\"filename\"]) // BS,\n",
        "    )\n",
        "    model_v2.save_weights(model_v2_save_filename)\n",
        "    histories[\"model_v2\"] = history_model_v2.history\n",
        "    pickle.dump(histories[\"model_v2\"], open(model_v2_hist_save_filename, 'wb'))\n",
        "\n",
        "else:\n",
        "    model_v2.load_weights(model_v2_save_filename)\n",
        "    histories['model_v2'] = pickle.load(open(model_v2_hist_save_filename, 'rb'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA_Cw3B2vDxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    fig, axes = plt.subplots(2,1,figsize=(8,8))\n",
        "    axes[0].plot(histories[\"model_v2\"]['jaccard_index'], label='jaccard_index')\n",
        "    axes[0].plot(histories[\"model_v2\"]['val_jaccard_index'], label = 'val_jaccard_index')\n",
        "    axes[0].plot(histories[\"model_v2\"]['accuracy'], label='accuracy')\n",
        "    axes[0].plot(histories[\"model_v2\"]['val_accuracy'], label = 'val_accuracy')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Metric')\n",
        "    axes[0].set_ylim([0.0, 1])\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[1].plot(histories[\"model_v2\"]['loss'], label='loss')\n",
        "    axes[1].plot(histories[\"model_v2\"]['val_loss'], label = 'val_loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Binary Cross-entropy')\n",
        "    axes[1].set_ylim([0.0, 1])\n",
        "    axes[1].legend(loc='upper right')\n",
        "    fig.suptitle('Model v2')\n",
        "\n",
        "except:\n",
        "    print(\"There was an error during the plot\")\n",
        "finally:\n",
        "    scores = model_v2.evaluate(val_images,  val_labels_binarized, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FHxyvEuLNO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_layer = model_v2.get_layer(name = 'conv1')\n",
        "filters = first_layer.get_weights()\n",
        "filters = filters[0]\n",
        "print(\" Shape of filters - conv1\" + str(filters.shape))\n",
        "\n",
        "# normalizing before showing\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "filters_matrix = np.zeros((filters.shape[3],filters.shape[0],filters.shape[1],filters.shape[2]), dtype =np.float32)\n",
        "for i in range(filters.shape[3]):\n",
        "    filters_matrix[i,:,:,:] = filters[:,:,:,i]\n",
        "# plot results\n",
        "plot_matrix(filters_matrix[0:20,:,:,:], sq_size=filters.shape[0], h=2, w=10)\n",
        "# plot_matrix(filters_matrix[0:9,:,:,1], sq_size=filters.shape[0])\n",
        "# plot_matrix(filters_matrix[0:9,:,:,2], sq_size=filters.shape[0])\n",
        "print(\"===\" * 30)\n",
        "\n",
        "\n",
        "second_layer = model_v2.get_layer(name = 'conv2')\n",
        "filters = second_layer.get_weights()\n",
        "filters = filters[0]\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "print(\" Shape of filters - conv2\" + str(filters.shape))\n",
        "filters_matrix = np.zeros((filters.shape[2]*filters.shape[3],filters.shape[0],filters.shape[1]), dtype =np.float32)\n",
        "for j in range(filters.shape[3]):\n",
        "    for i in range(filters.shape[2]):\n",
        "        filters_matrix[j*i,:,:] = filters[:,:,i,j]\n",
        "print(filters_matrix.shape)\n",
        "plot_matrix(filters_matrix[0:20,:], sq_size=filters.shape[0], h = 2, w = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpxELHW0lj-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = model_v2.predict(val_images)\n",
        "\n",
        "print(\"Are all the classes at least predicted once ?\")\n",
        "print(y_hat_round.any(axis=0))\n",
        "# with np.printoptions(threshold=np.inf, ):\n",
        "#     print(np.count_nonzero(y_hat_round, axis = 1))\n",
        "print(\"All classes: \")\n",
        "print(classes_names)\n",
        "\n",
        "\n",
        "with np.printoptions(precision=1,linewidth=100): # np.set_printoptions(precision=1,linewidth=100)\n",
        "    print(np.round(y_hat[1:2,:],1))\n",
        "    print(np.round(val_labels_binarized[1:2,:],1))\n",
        "    # print(val_labels_str[1:2])\n",
        "    plot_matrix(val_images[1:2, :, :, :], val_labels_str[1:2], scale = 3)\n",
        "\n",
        "\n",
        "    print(np.round(y_hat[4:5,:],1))\n",
        "    print(np.round(val_labels_binarized[4:5,:],1))\n",
        "    # print(val_labels_str[4:5])\n",
        "    plot_matrix(val_images[4:5, :, :, :], val_labels_str[4:5], scale = 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68e5VbD6a-cn",
        "colab_type": "text"
      },
      "source": [
        "### Model v3\n",
        "Add extra convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7J3olUlRWbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_v3 = tf.keras.Sequential()\n",
        "\n",
        "# model_v3.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(5, 5),  input_shape=(width,height,3)))\n",
        "# model_v3.add(tf.keras.layers.Activation('relu'))\n",
        "# model_v3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# model_v3.add(tf.keras.layers.Dropout(0.25))\n",
        "# model_v3.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3),))\n",
        "# # model_v3.add(tf.keras.layers.BatchNormalization())\n",
        "# model_v3.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "\n",
        "# model_v3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# model_v3.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "\n",
        "# model_v3.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), ))\n",
        "# # model_v3.add(tf.keras.layers.BatchNormalization())\n",
        "# model_v3.add(tf.keras.layers.Activation('relu'))\n",
        "# model_v3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# model_v3.add(tf.keras.layers.Dropout(0.25))\n",
        "# model_v3.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3),))\n",
        "# # model_v3.add(tf.keras.layers.BatchNormalization())\n",
        "# model_v3.add(tf.keras.layers.Activation('relu'))\n",
        "# model_v3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# # model_v3.add(tf.keras.layers.GlobalMaxPool2D())\n",
        "# model_v3.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "\n",
        "# model_v3.add(tf.keras.layers.Flatten())\n",
        "# model_v3.add(tf.keras.layers.Dense(512))\n",
        "# model_v3.add(tf.keras.layers.Activation('relu'))\n",
        "\n",
        "# model_v3.add(tf.keras.layers.Dropout(0.5))\n",
        "# # model_v3.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "# # model_v3.add(tf.keras.layers.Dropout(0.5))\n",
        "# model_v3.add(tf.keras.layers.Dense(20, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IWybIB9cj4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v3 = Gr8ClassNet.build_second(width, height, channel, \n",
        "                             dropout = False, \n",
        "                             batch_normalization = True, \n",
        "                             extra_convolution_batch=True, \n",
        "                             extra_dense = False, \n",
        "                             l2_reg=(0.0001,0.00005))\n",
        "model_v3.summary()\n",
        "# train_model = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGBNhnyqeOl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if classification_type == \"multilabel\":\n",
        "    my_loss=tf.keras.losses.binary_crossentropy\n",
        "elif classification_type == \"single\":\n",
        "    my_loss=tf.keras.losses.categorical_crossentropy\n",
        "    # my_loss=tf.keras.losses.kullback_leibler_divergence\n",
        "\n",
        "model_v3.compile(optimizer=  tf.keras.optimizers.Adam(0.0001), #get_optimizer(), #\n",
        "                                    loss=my_loss, # to explain\n",
        "                                    metrics=[jaccard_index, 'accuracy'])\n",
        "\n",
        "# EPOCHS = 200\n",
        "\n",
        "if train_class_model_v3 == True:\n",
        "    history_model_v3 = model_v3.fit(   train_img_gen,  #, # training_set_class_tf_generator\n",
        "                                            steps_per_epoch= len(df_class_train_to_generate[\"filename\"]) // BS,\n",
        "                                            epochs=EPOCHS, \n",
        "                                            callbacks=[my_callbacks],\n",
        "                                            validation_data= val_set_class_tf_generator, #val_img_gen, #\n",
        "                                            validation_steps = len(df_class_val_to_generate[\"filename\"]) // BS,\n",
        "    )\n",
        "    model_v3.save_weights(model_v3_save_filename)\n",
        "    histories[\"model_v3\"] = history_model_v3.history\n",
        "    pickle.dump(histories[\"model_v3\"], open(model_v3_hist_save_filename, 'wb'))\n",
        "\n",
        "else:\n",
        "    model_v3.load_weights(model_v3_save_filename)\n",
        "    histories['model_v3'] = pickle.load(open(model_v3_hist_save_filename, 'rb'))\n",
        "\n",
        "\n",
        "layers_model_v3 = [(layer, layer.name, layer.output_shape) for layer in model_v3.layers]\n",
        "pd.DataFrame(layers_model_v3, columns=['Layer Type', 'Layer Name', 'Layer output shape'])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BckqcHeJin04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    fig, axes = plt.subplots(2,1,figsize=(8,8))\n",
        "    axes[0].plot(histories[\"model_v3\"]['jaccard_index'], label='jaccard_index')\n",
        "    axes[0].plot(histories[\"model_v3\"]['val_jaccard_index'], label = 'val_jaccard_index')\n",
        "    axes[0].plot(histories[\"model_v3\"]['accuracy'], label='accuracy')\n",
        "    axes[0].plot(histories[\"model_v3\"]['val_accuracy'], label = 'val_accuracy')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Metric')\n",
        "    axes[0].set_ylim([0.0, 1])\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[1].plot(histories[\"model_v3\"]['loss'], label='loss')\n",
        "    axes[1].plot(histories[\"model_v3\"]['val_loss'], label = 'val_loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Binary Cross-entropy')\n",
        "    axes[1].set_ylim([0.0, 1])\n",
        "    axes[1].legend(loc='upper right')\n",
        "    fig.suptitle('Model v3')\n",
        "except:\n",
        "    print(\"There was an error during the plot\")\n",
        "finally:\n",
        "    scores = model_v3.evaluate(val_images,  val_labels_binarized, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmiDv9T8U5uF",
        "colab_type": "text"
      },
      "source": [
        "As previously, we plot filters of first and second layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7z6VYymB9xo",
        "colab_type": "text"
      },
      "source": [
        "With this (slightly) deeper network, the same kind of results are reached - maybe a bit better.  \n",
        "\n",
        "Clearly, there is overfitting. After several trial/errors, it seems complicated, considering the limited amount of original data, to learn enough to train as many classifiers - as multilabeling essentially is as many classifier as there are different classes to predict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSEsaZrIWIGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_v3.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg3OlfQQU47p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\n================================First Layer================================\\n\")\n",
        "\n",
        "first_layer = model_v3.get_layer(name = 'conv1')\n",
        "filters = first_layer.get_weights()\n",
        "filters = filters[0]\n",
        "\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "filters_matrix = np.zeros((filters.shape[3],filters.shape[0],filters.shape[1],filters.shape[2]))\n",
        "for i in range(filters.shape[3]):\n",
        "    filters_matrix[i,:,:,:] = filters[:,:,:,i]\n",
        "# plot results\n",
        "plot_matrix(filters_matrix[0:32,:,:,0], sq_size=filters.shape[0], h=2, w=16)\n",
        "plot_matrix(filters_matrix[0:32,:,:,1], sq_size=filters.shape[0], h=2, w=16)\n",
        "plot_matrix(filters_matrix[0:32,:,:,2], sq_size=filters.shape[0], h=2, w=16)\n",
        "plot_matrix(filters_matrix[0:32,:,:,:], sq_size=filters.shape[0], h=2, w=16)\n",
        "\n",
        "print(\"\\n===============================Second Layer================================\\n\")\n",
        "second_layer = model_v3.get_layer(name = 'conv2')\n",
        "filters, biases = second_layer.get_weights()\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "print(filters.shape)\n",
        "filters_matrix = np.zeros((filters.shape[2]*filters.shape[3],filters.shape[0],filters.shape[1]), np.float32)\n",
        "for j in range(filters.shape[3]):\n",
        "    for i in range(filters.shape[2]):\n",
        "        filters_matrix[j*i,:,:] = filters[:,:,i,j]\n",
        "print(filters_matrix.shape)\n",
        "plot_matrix(filters_matrix[0:32,:], sq_size=filters.shape[0], h=2, w=16)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE25Ld3PNYKJ",
        "colab_type": "text"
      },
      "source": [
        "#### Analysis using confusion matrix \n",
        "Multilabel, Multiclass => consider the labels independently - and simple confusion matrix per label\n",
        "\n",
        "``` \n",
        "           |   Predictions |\n",
        "           |___-___|___+___|\n",
        "   T | Neg |  TN   |   FP  |\n",
        "   R |_____|_ _ _ _|_ _ _ _|\n",
        "   U | Pos |  FN   |   TP  |\n",
        "   E |_____|_______|_______|\n",
        " ```\n",
        "A confusion matrix is a nice tool in order to observe the behaviour of the classifier on the validation set, and in particular the behavior between classes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHHn5iFHNXu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Dictionary containing the Conf matrix for all labels\n",
        "credit: https://stackoverflow.com/questions/53886370/multi-class-multi-label-confusion-matrix-with-sklearn\n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "create the dictionnaries that will contain the confusion matrix\n",
        "'''\n",
        "conf_mat_dict={}\n",
        "conf_mat_dict_norm = {}\n",
        "conf_mat_dict_prefect_norm = {}\n",
        "\n",
        "'''\n",
        "For clarity, rename classes_names => labels\n",
        "'''\n",
        "labels = classes_names\n",
        "\n",
        "''' \n",
        "Predict the labels for images on the validation set\n",
        "'''\n",
        "y_pred = model_v3.predict(val_images)\n",
        "y_pred = np.round(y_pred)\n",
        "\n",
        "'''\n",
        "Gather true values\n",
        "'''\n",
        "y_true = val_labels_binarized\n",
        "\n",
        "\n",
        "'''\n",
        "Check consistency of shapes\n",
        "'''\n",
        "print(\"y_true shape =\" + str(y_true.shape))\n",
        "print(\"y_pred shape = \" + str(y_pred.shape))\n",
        "\n",
        "\n",
        "'''\n",
        "Compute all the confusion matrices, one per class\n",
        "'''\n",
        "for label_col in range(len(labels)):\n",
        "    y_true_label = y_true[:, label_col]\n",
        "    y_pred_label = y_pred[:, label_col]\n",
        "    conf_mat_dict[labels[label_col]] = sklearn.metrics.confusion_matrix(y_true=y_true_label, y_pred=y_pred_label)\n",
        "    conf_mat_dict_norm[labels[label_col]] = sklearn.metrics.confusion_matrix(y_true=y_true_label, y_pred=y_pred_label,  normalize = 'true')\n",
        "\n",
        "'''\n",
        "Nicely plot the results to ease interpretation\n",
        "'''\n",
        "fig, axes = plt.subplots(4,5, figsize = (15,12))\n",
        "counter = 0\n",
        "for i in range(4):\n",
        "    for j in range(5):\n",
        "        label = labels[counter]\n",
        "        cf_matrix = conf_mat_dict_norm[label] #_norm\n",
        "        group_names = ['TN','FP','FN','TP']\n",
        "        group_counts = [\"{0:0.3f}\".format(value) for value in cf_matrix.flatten()]\n",
        "        # group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "        local_labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\n",
        "        local_labels = np.asarray(local_labels).reshape(2,2)\n",
        "        sns.heatmap(cf_matrix, annot=local_labels, fmt='', ax=axes[i,j])\n",
        "        # axes[i,j].matshow(conf_mat_dict_norm[label])    \n",
        "        axes[i,j].set_ylabel(\"True\")\n",
        "        axes[i,j].set_xlabel(\"Predicted\")\n",
        "        axes[i,j].set_title(str(label), fontsize = 14)\n",
        "        counter +=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_XQDCOyreUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZpIgSbkXItK",
        "colab_type": "text"
      },
      "source": [
        "## Classification using Transfer Learning\n",
        "\n",
        "the approach followed relies on [tensorflow documentation](https://www.tensorflow.org/tutorials/images/transfer_learning)\n",
        "\n",
        "For this part, I reuse the input data pipelines already built. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hp55utOfAiR",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained CNN model as Feature Extractor\n",
        "- load a model (MobileNetV2). Attempts were made with Restnet (much slower) and VGG16 (worst results)\n",
        "- freeze convolution blocks\n",
        "\n",
        "We can add a flattening layer in order to feed the head part. The bottom part is therefore already trained, and is the feature extraction part. The second (last) part, the head, is the classifier that we can train based on our dataset.\n",
        "\n",
        "The plan is:\n",
        "1. Get the base_model, already trained\n",
        "2. Complete the base with the classifier, the head\n",
        "3. With the base_model set as non trainable (!!), train the complete model based on our data. The goal is to find a set of weights that achieve a good accuracy\n",
        "4. IF there is no overfitting, we can relax the non-trainability of the base_model, lower the learning speed, and fine-tune the weigts to try and find a better optimum. This is risky as we might as well \"unlearn\". This is therefore important that there is no overfitting at that point, and that the learning rate is kept small.\n",
        "\n",
        "\n",
        "The main interest of Transfer Learning is that the re-use of an already trained feature extractor. It is interesting to observe the behavior of such a network, beforehand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZtL_LwPlKsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Ensure the parameters\n",
        "'''\n",
        "num_classes = 20;\n",
        "if classification_type == \"single\":\n",
        "    output_activation ='softmax' #softmax if \"single\"\n",
        "elif classification_type == \"multilabel\":\n",
        "    output_activation = 'sigmoid' # if multilabel <<<<<<<<<\n",
        "else:\n",
        "    raise ValueError(classification_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKSUXoGnf8Zq",
        "colab_type": "text"
      },
      "source": [
        "####Get the base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng_sVzLhdrTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "'''\n",
        "print('('+str(height) + \",\" + str(width) +', ' + str(channel) + \")\")\n",
        "\n",
        "'''\n",
        "Creation of the Pre-trained model => MobileNet\n",
        "'''\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(height, width, channel),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "# base_model = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', \n",
        "#                                      input_shape=(height, width, channel))\n",
        "\n",
        "# base_model = tf.keras.applications.ResNet152V2(include_top=False, weights='imagenet', \n",
        "#                                      input_shape=(height, width, channel))\n",
        "\n",
        "'''\n",
        "Make the model not trainable (first)\n",
        "'''\n",
        "base_model.trainable = False\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "layers_mobile_net = [(layer, layer.name, layer.trainable, layer.output_shape) for layer in base_model.layers]\n",
        "df_tmp = pd.DataFrame(layers_mobile_net, columns=['Layer Type', 'Layer Name', 'Layer Trainable', 'Layer output shape'])   \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_WylErR3isi",
        "colab_type": "text"
      },
      "source": [
        "As an example, we take two images from the (augmented) training set, and we show the bottleneck features: the features at the output of the pre-trained model. \n",
        "\n",
        "- First, we show the corresponding training image\n",
        "- Second, we show the dimension of the layer, \n",
        "- Third we show the 25th first features. \n",
        "\n",
        "We repeat that for two images, to observe the difference. \n",
        "\n",
        "Those bottleneck features constitute what goes in the head, the classifier. This is an \"automatically learnt\" feature, in contrast with HOG or PCA, from previous assignment, that were handcrafted. In the \"From scratch\" problem, the goal was to obtain also this feature extraction part: here, we reuse a base network already trained on a gigantic set of images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTiKP9jD7bUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_, label_ = next(train_img_gen)\n",
        "\n",
        "print(\"First image of the bacth, than we give as input to the MobileNet model\")\n",
        "plot_matrix(img_[0:1], multiLabelBinarizer.inverse_transform(np.array( label_[0:1])), scale = 4)\n",
        "\n",
        "# plot_matrix(dataset_denormalize(img_[0:1].numpy()), multiLabelBinarizer.inverse_transform(np.array( label_[0:1])), scale = 4)\n",
        "\n",
        "print(\"The Model computes the features. The output is of size: (before Fully connected layer)\")\n",
        "bottleneck_feature_example = base_model.predict(img_[0:1])\n",
        "print(bottleneck_feature_example.shape)\n",
        "# print(bottleneck_feature_example[0].shape)\n",
        "print(\"\\nFinally, we can observe some of the filters as the output of the MobileNet feature extraction part\")\n",
        "plot_matrix(bottleneck_feature_example[0][:,:,0:25].T, h=2, w=13)\n",
        "\n",
        "print(\"For another image: (before Fully connected layer)\")\n",
        "plot_matrix(img_[4:5], multiLabelBinarizer.inverse_transform(np.array( label_[4:5])), scale = 4)\n",
        "bottleneck_feature_example = base_model.predict(img_[4:5])\n",
        "print(bottleneck_feature_example.shape)\n",
        "# print(bottleneck_feature_example[0].shape)\n",
        "print(\"\\nFinally, we can observe some of the filters as the output of the MobileNet feature extraction part\")\n",
        "plot_matrix(bottleneck_feature_example[0][:,:,0:25].T, h=2, w=13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhvstxiSsvzi",
        "colab_type": "text"
      },
      "source": [
        "####Filters of first Convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHd-xcvnbpRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_layer = base_model.get_layer(name = 'Conv1')\n",
        "\n",
        "filters = first_layer.get_weights()\n",
        "filters = filters[0]\n",
        "filters_matrix = np.zeros((filters.shape[3],filters.shape[0],filters.shape[1],filters.shape[2]), np.float32)\n",
        "\n",
        "# plot results\n",
        "# filters_matrix -= np.mean(filters_matrix)\n",
        "\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# filters-=np.mean(filters)\n",
        "for i in range(filters.shape[3]):\n",
        "    filters_matrix[i,:,:,:] = filters[:,:,:,i]\n",
        "\n",
        "\n",
        "print(\"CHANNEL 0\\n\")\n",
        "plot_matrix(filters_matrix[:,:,:,0], sq_size=filters.shape[0], h = 2, w = 16)\n",
        "\n",
        "print(\"\\n\" + \"==\"*30 + \"\\nCHANNEL 1\\n\")\n",
        "plot_matrix(filters_matrix[:,:,:,1], sq_size=filters.shape[0], h = 2, w = 16)\n",
        "print(\"\\n\" + \"==\"*30 + \"\\nCHANNEL 2\\n\")\n",
        "plot_matrix(filters_matrix[:,:,:,2], sq_size=filters.shape[0], h = 2, w = 16)\n",
        "\n",
        "print(\"\\n\" + \"==\"*30 + \"\\nALL channels composed:\\n\")\n",
        "plot_matrix(filters_matrix[:,:,:,], sq_size=filters.shape[0], h = 2, w = 16)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BefRxR1fPEN",
        "colab_type": "text"
      },
      "source": [
        "####Addition of the head of the model (classifier)\n",
        "Traditionnaly, this is a (stack of) fully connected layer(s). Here, we use another (functional) API rather than `Sequential` in order to build up the model. There is no difference in the end-result. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnRp2Dj7uKKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Head of the classifier\n",
        "'''\n",
        "\n",
        "output_base_model = base_model.layers[-1].output\n",
        "# output_base_model = tf.keras.layers.Flatten()(output_base_model)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name = \"gap\")(output_base_model)\n",
        "# x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(1024,activation = 'relu',)(x)\n",
        "                        #   kernel_regularizer = tf.keras.regularizers.l2(1e-4),\n",
        "                        #   bias_regularizer = tf.keras.regularizers.l2(1e-4)\n",
        "x = tf.keras.layers.Dropout(0.35)(x)\n",
        "\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "# x = tf.keras.layers.Dense(1024, activation = 'relu',\n",
        "#                           kernel_regularizer = tf.keras.regularizers.l2(1e-3),\n",
        "#                           bias_regularizer = tf.keras.regularizers.l2(1e-3))(x)\n",
        "\n",
        "# x = tf.keras.layers.Dropout(0.35)(x)\n",
        "# x = tf.keras.layers.BatchNormalization()(x)\n",
        "output = tf.keras.layers.Dense(num_classes,activation='sigmoid')(x)\n",
        "\n",
        "class_transfer_learning_model = tf.keras.Model(base_model.input, output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1aYA0qyugoA",
        "colab_type": "text"
      },
      "source": [
        "Summary of the complete model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ci0gAKQukUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_transfer_learning_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz-eEKAJulww",
        "colab_type": "text"
      },
      "source": [
        "####Compilation\n",
        "- use of ADAM optimizer\n",
        "- binary cross entropy, as we are still in the multilabel problem\n",
        "- we record the jaccard_index, and the binary accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ytRxtG-rAxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INIT_LR = 0.00005\n",
        "# EPOCHS = 100\n",
        "# opt =  tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# opt =  tf.keras.optimizers.SGD(lr=INIT_LR, momentum=0.9)\n",
        "opt =  tf.keras.optimizers.Adam(lr = INIT_LR)\n",
        "class_transfer_learning_model.compile(loss= 'binary_crossentropy', \n",
        "                                optimizer=opt,\n",
        "                                metrics=[jaccard_index, 'accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dssL9YHRw7Kc",
        "colab_type": "text"
      },
      "source": [
        "####Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ6782m7C9CD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_model = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsAZKHdXr6Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if train_class_model_tl == True:\n",
        "    history_model_tl = class_transfer_learning_model.fit( \n",
        "                                                \n",
        "                                                train_img_gen, # training_set_class_tf_generator, \n",
        "                                                batch_size = BS,\n",
        "                                                steps_per_epoch= len(df_class_train_to_generate[\"filename\"]) // BS,\n",
        "                                                callbacks=[my_callbacks],\n",
        "                                                epochs=EPOCHS, \n",
        "                                                validation_data = val_set_class_tf_generator,\n",
        "                                                validation_steps = len(df_class_val_to_generate[\"filename\"]) // BS,\n",
        "                                            )\n",
        "    class_transfer_learning_model.save_weights(class_tl_save_filename)\n",
        "    histories[\"class_tansfer_learning_model\"] = history_model_tl.history\n",
        "    pickle.dump(histories[\"class_tansfer_learning_model\"], open(class_tl_hist_save_filename, 'wb'))\n",
        "\n",
        "else:\n",
        "    class_transfer_learning_model.load_weights(class_tl_save_filename)\n",
        "    histories['class_tansfer_learning_model'] = pickle.load(open(class_tl_hist_save_filename, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkmKXbWhd0qQ",
        "colab_type": "text"
      },
      "source": [
        "- MobileNetv2, ~70 % on validation set (overfitting)\n",
        "- VGG16, ~25% max apres 50 EPOCH, that does not really go up\n",
        "- RestNet -> quite slower than MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo4WeAa199UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for im, lab in training_set_class_tf_generator.take(1):\n",
        "    pass\n",
        "\n",
        "tf.print(np.max(im))\n",
        "tf.print(np.min(im))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnMry3AF90mJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = class_transfer_learning_model.evaluate(val_images, val_labels_binarized)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzph9P4A4vnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key_ in [\"class_tansfer_learning_model\",]: #histories.keys():\n",
        "    print(\"key = \" + str(key_))\n",
        "    try:\n",
        "        jacc = histories[key_]['jaccard_index']\n",
        "        val_jacc = histories[key_]['val_jaccard_index']\n",
        "\n",
        "        acc = histories[key_]['accuracy']\n",
        "        val_acc = histories[key_]['val_accuracy']\n",
        "\n",
        "        loss = histories[key_]['loss']\n",
        "        val_loss = histories[key_]['val_loss']\n",
        "\n",
        "        fig, axes = plt.subplots(3,1, figsize=(8, 12), sharex=True)\n",
        "        axes[0].plot(jacc, label='Training jaccard_index')\n",
        "        axes[0].plot(val_jacc, label='Validation jaccard_index')\n",
        "        axes[0].legend(loc='lower right')\n",
        "        axes[0].set_ylabel('Jaccard Index')\n",
        "        axes[0].set_ylim([0,1])\n",
        "\n",
        "\n",
        "        axes[1].plot(acc, label='Accuracy')\n",
        "        axes[1].plot(val_acc, label='Validation accuracy')\n",
        "        axes[1].legend(loc='lower right')\n",
        "        axes[1].set_ylabel('Accuracy')\n",
        "        axes[1].set_ylim([0,1])\n",
        "        # plt.title('Training and Validation jaccard_index')\n",
        "\n",
        "        axes[2].plot(loss, label='Training Loss')\n",
        "        axes[2].plot(val_loss, label='Validation Loss')\n",
        "        axes[2].set_ylabel('Cross Entropy')\n",
        "        axes[2].legend(loc='upper right')\n",
        "\n",
        "        # plt.ylim([0,1.0])\n",
        "        # plt.title('Training and Validation Loss')\n",
        "        axes[2].set_xlim([0,100])\n",
        "        axes[2].set_xlabel('epoch')\n",
        "        plt.show()\n",
        "    except KeyError:\n",
        "        print(\"Key error -> pass\")\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvqodtAw0VCV",
        "colab_type": "text"
      },
      "source": [
        "At some point, after several tests and trials of Hyperparameters, it seems a kind of ~60% to 65% max on the validation set is reachable. Most likely, to improve the score considering the same problem:\n",
        "- there is a need for more data, or/and better data augmentation\n",
        "- the parameters should be carefully assessed\n",
        "- the optimzer and objective function could be revised. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmNcPgM1wi7R",
        "colab_type": "text"
      },
      "source": [
        "###Fine Tuning\n",
        "\n",
        "The following part is coded (and works ;-)) but is skipped: there is overfitting in the model, and before this is settled, unlocking the training of the base_model may only 'untrain' it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa6KBDjde0WY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Define parameters\n",
        "'''\n",
        "\n",
        "fine_tune_class_transfer_learning_model = False\n",
        "epoch_restart = 0 # this shall be the number of epochs realized during previous training\n",
        "if fine_tune_class_transfer_learning_model:\n",
        "    assert epoch_restart > 0, \"The epoch_restart number must be larger than 0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dAYdVHNkCDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        "We can unfreeze several layers, to try and fine tune\n",
        "'''\n",
        "if fine_tune_class_transfer_learning_model:\n",
        "    base_model.trainable = True\n",
        "    # refreeze some, in order to not forget everything\n",
        "    for layer in base_model.layers[:100]:\n",
        "        layer.trainable = False\n",
        "    lr = 1e-6\n",
        "    opt =  tf.keras.optimizers.Adam(lr)\n",
        "    class_transfer_learning_model.compile(loss='binary_crossentropy',\n",
        "                                    optimizer=opt,\n",
        "                                    metrics=[jaccard_index, 'accuracy'])\n",
        "\n",
        "\n",
        "    # Increase training epochs for fine-tuning\n",
        "    fine_tune_epochs = EPOCHS\n",
        "    total_epochs =  EPOCHS + fine_tune_epochs\n",
        "    # Fine-tune model\n",
        "    # Note: Set initial_epoch to begin training after epoch 100 since we\n",
        "    # previously trained for 100 epochs.\n",
        "    if train_class_model_tl_ft:\n",
        "        history_model_tl_ft= class_transfer_learning_model.fit( \n",
        "                                                    training_set_class_tf_generator, \n",
        "                                                    batch_size = BS,\n",
        "                                                    steps_per_epoch= len(df_class_train_to_generate[\"filename\"]) // BS,\n",
        "                                                    callbacks=[my_callbacks],\n",
        "                                                    epochs=total_epochs, \n",
        "                                                    initial_epoch = EPOCHS,\n",
        "                                                    validation_data = val_set_class_tf_generator,\n",
        "                                                    validation_steps = len(df_class_val_to_generate[\"filename\"]) // BS,\n",
        "                                                )\n",
        "        class_transfer_learning_model.save_weights(class_tl_finetuned_save_filename)\n",
        "        histories[\"tansfer_learning_model_fine_tuning\"] = history_model_tl_ft.history\n",
        "        pickle.dump(histories[\"tansfer_learning_model_fine_tuning\"], open(class_tl_finetuned_hist_save_filename, 'wb'))\n",
        "\n",
        "    else:\n",
        "        class_transfer_learning_model.load_weights(class_tl_finetuned_save_filename)\n",
        "        histories['tansfer_learning_model_fine_tuning'] = pickle.load(open(class_tl_finetuned_hist_save_filename, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95AxG2n_xNgG",
        "colab_type": "text"
      },
      "source": [
        "As before, we can show the training curves, for the training still registered. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azEZaRa4sdk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key_ in [\"class_tansfer_learning_model\",\"tansfer_learning_model_fine_tuning\",]: #histories.keys():\n",
        "    print(\"key = \" + str(key_))\n",
        "    try:\n",
        "        jacc = histories[key_]['jaccard_index']\n",
        "        val_jacc = histories[key_]['val_jaccard_index']\n",
        "\n",
        "        acc = histories[key_]['accuracy']\n",
        "        val_acc = histories[key_]['val_accuracy']\n",
        "\n",
        "        loss = histories[key_]['loss']\n",
        "        val_loss = histories[key_]['val_loss']\n",
        "\n",
        "        fig, axes = plt.subplots(3,1, figsize=(8, 12), sharex=True)\n",
        "        axes[0].plot(jacc, label='Training jaccard_index')\n",
        "        axes[0].plot(val_jacc, label='Validation jaccard_index')\n",
        "        axes[0].legend(loc='lower right')\n",
        "        axes[0].set_ylabel('Jaccard Index')\n",
        "        axes[0].set_ylim([0,1])\n",
        "\n",
        "\n",
        "        axes[1].plot(acc, label='Accuracy')\n",
        "        axes[1].plot(val_acc, label='Validation accuracy')\n",
        "        axes[1].legend(loc='lower right')\n",
        "        axes[1].set_ylabel('Accuracy')\n",
        "        axes[1].set_ylim([0,1])\n",
        "        # plt.title('Training and Validation jaccard_index')\n",
        "\n",
        "        axes[2].plot(loss, label='Training Loss')\n",
        "        axes[2].plot(val_loss, label='Validation Loss')\n",
        "        axes[2].set_ylabel('Cross Entropy')\n",
        "        axes[2].legend(loc='upper right')\n",
        "\n",
        "        # plt.ylim([0,1.0])\n",
        "        # plt.title('Training and Validation Loss')\n",
        "        axes[2].set_xlim([0,100])\n",
        "        axes[2].set_xlabel('epoch')\n",
        "        plt.show()\n",
        "    except KeyError:\n",
        "        print(\"Key error -> pass\")\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKrZPv1J52qM",
        "colab_type": "text"
      },
      "source": [
        "Yet another transer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t4FcNEV02Fu",
        "colab_type": "text"
      },
      "source": [
        "Compute the predictions for the full validation set (~3500) items, and compute the jaccard index. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TODx0UFiwzA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(val_images[0,:][0:5, 0:5, 0])\n",
        "# file_of_weights = 'class_transfer_learning_model.h5'\n",
        "# class_transfer_learning_model.load_weights(file_of_weights)\n",
        "# y_hat_tl = class_transfer_learning_model.predict(val_images)\n",
        "# y_hat_tl_round = tf.round(y_hat_tl)\n",
        "# y_true_tl = tf.convert_to_tensor(val_labels_binarized, dtype='float32')\n",
        "\n",
        "# jac_index = jaccard_index(y_true_tl, y_hat_tl)\n",
        "\n",
        "# print(\"jac index: \" + str(jac_index))\n",
        "# esults = class_transfer_learning_model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQQKJCQr1F99",
        "colab_type": "text"
      },
      "source": [
        "### Analysis using confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9e_0pja01JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "create the dictionnaries that will contain the confusion matrix\n",
        "'''\n",
        "conf_mat_dict={}\n",
        "conf_mat_dict_norm = {}\n",
        "conf_mat_dict_prefect_norm = {}\n",
        "\n",
        "'''\n",
        "For clarity, rename classes_names => labels\n",
        "'''\n",
        "labels = classes_names\n",
        "\n",
        "''' \n",
        "Predict the labels for images on the validation set\n",
        "'''\n",
        "y_pred = class_transfer_learning_model.predict(val_images)\n",
        "y_pred = np.round(y_pred)\n",
        "\n",
        "'''\n",
        "Gather true values\n",
        "'''\n",
        "y_true = val_labels_binarized\n",
        "\n",
        "\n",
        "'''\n",
        "Check consistency of shapes\n",
        "'''\n",
        "print(\"y_true shape =\" + str(y_true.shape))\n",
        "print(\"y_pred shape = \" + str(y_pred.shape))\n",
        "\n",
        "\n",
        "'''\n",
        "Compute all the confusion matrices, one per class\n",
        "'''\n",
        "for label_col in range(len(labels)):\n",
        "    y_true_label = y_true[:, label_col]\n",
        "    y_pred_label = y_pred[:, label_col]\n",
        "    conf_mat_dict[labels[label_col]] = sklearn.metrics.confusion_matrix( y_true=y_true_label,y_pred=y_pred_label,)\n",
        "    conf_mat_dict_norm[labels[label_col]] = sklearn.metrics.confusion_matrix(y_true=y_true_label, y_pred=y_pred_label,  normalize = 'true')\n",
        "\n",
        "'''\n",
        "Nicely plot the results to ease interpretation\n",
        "'''\n",
        "fig, axes = plt.subplots(4,5, figsize = (15,12))\n",
        "counter = 0\n",
        "for i in range(4):\n",
        "    for j in range(5):\n",
        "        label = labels[counter]\n",
        "        cf_matrix = conf_mat_dict_norm[label] #_norm\n",
        "        group_names = ['TN','FP','FN','TP']\n",
        "        group_counts = [\"{0:0.3f}\".format(value) for value in cf_matrix.flatten()]\n",
        "        # group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "        local_labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\n",
        "        local_labels = np.asarray(local_labels).reshape(2,2)\n",
        "        sns.heatmap(cf_matrix, annot=local_labels, fmt='', ax=axes[i,j])\n",
        "        # axes[i,j].matshow(conf_mat_dict_norm[label])    \n",
        "        axes[i,j].set_ylabel(\"True\")\n",
        "        axes[i,j].set_xlabel(\"Predicted\")\n",
        "        axes[i,j].set_title(str(label), fontsize = 14)\n",
        "        counter +=1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWDnE4HsWLXs",
        "colab_type": "text"
      },
      "source": [
        "From the confusion map, we can see the variety of behavior considering the input. Recognizing a sheep seems dramatically more complicated than a horse. Similarly, recognizing a train seems easier than a potted plant. \n",
        "\n",
        "From the matrices (normalized per True value), our classifier behaved differently according to the class. \n",
        "\n",
        "Another complementary view is to show the precision-recall curve, that is shown below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaDW03JfzpqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "precision = {}\n",
        "recall = {}\n",
        "average_precision = {}\n",
        "\n",
        "print(y_pred.shape)\n",
        "print(y_true.shape)\n",
        "\n",
        "for i in range(num_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(y_true[:,i], y_pred[:,i])\n",
        "\n",
        "    average_precision[i] = average_precision_score(y_true[:,i], y_pred[:,i])\n",
        "\n",
        "# A \"micro-average\": quantifying score on all classes jointly\n",
        "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true.ravel(), y_pred.ravel())\n",
        "average_precision[\"micro\"] = average_precision_score(y_true, y_pred, average=\"micro\")\n",
        "print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
        "      .format(average_precision[\"micro\"]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfkiYT5T3ie1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "f_scores = np.linspace(0.2, 0.8, num=4)\n",
        "lines = []\n",
        "labels = []\n",
        "for f_score in f_scores:\n",
        "    x = np.linspace(0.01, 1)\n",
        "    y = f_score * x / (2 * x - f_score)\n",
        "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
        "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
        "\n",
        "lines.append(l)\n",
        "labels.append('iso-f1 curves')\n",
        "l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n",
        "lines.append(l)\n",
        "labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
        "              ''.format(average_precision[\"micro\"]))\n",
        "\n",
        "for i in range(num_classes):\n",
        "    l, = plt.plot(recall[i], precision[i], lw=2)\n",
        "    lines.append(l)\n",
        "    labels.append('P-R {0} (area = {1:0.2f})'\n",
        "                  ''.format(classes_names[i], average_precision[i]))\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.subplots_adjust(bottom=0.25)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Extension of Precision-Recall curve to multi-class')\n",
        "plt.legend(lines, labels, bbox_to_anchor=(1.04,1), loc=\"upper left\", prop=dict(size=14))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T079Ot7XXMAA",
        "colab_type": "text"
      },
      "source": [
        "From the class to recognize, there seem to be two groups, of around 10 classes each:\n",
        "- aeroplane, bicycle, bird, boat, bus, cat, dog, horse, motorbike, person and train, which are not that badly recognized yet, \n",
        "- bottle, car, chair, cow, diningtable, pottedplant, sheep, sofa and tvmonitor which are not properly recognized at all\n",
        "\n",
        "We can analyze that result in more details, by taking 2 samples of an aeroplane, and 2 samples of a cow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK08NE7nYRWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_aeroplane = [ '2007_000256', '2007_000738' ]\n",
        "ids_cow = ['2007_000464', '2007_000491']\n",
        "\n",
        "images_test_aeroplane = get_images(ids_aeroplane, path_image_folder,width=sq_size, height=sq_size,)\n",
        "images_test_cow = get_images(ids_cow, path_image_folder,width=sq_size, height=sq_size,)\n",
        "\n",
        "\n",
        "label_test_aeroplane = get_class_labels_str(ids_aeroplane)\n",
        "label_test_cow = get_class_labels_str(ids_cow)\n",
        "label_test_aeroplane_binarized =  multiLabelBinarizer.fit_transform(label_test_aeroplane)\n",
        "label_test_cow_binarized =  multiLabelBinarizer.fit_transform(label_test_cow)\n",
        "\n",
        "\n",
        "plot_matrix(images_test_aeroplane, label_test_aeroplane, scale = 3)\n",
        "plot_matrix(images_test_cow, label_test_cow,  scale = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcEnnLTua5of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_aeroplane_pred = class_transfer_learning_model.predict(images_test_aeroplane/255.0)\n",
        "y_cow_pred = class_transfer_learning_model.predict(images_test_cow/255.0)\n",
        "\n",
        "with np.printoptions(linewidth=500): # np.set_printoptions(precision=1,linewidth=100)\n",
        "    print(\"Y Prediction aeroplane (should be [1, 0, ...., 0])\\n\" + str(np.round(y_aeroplane_pred,2)))\n",
        "    print(\"Y Prediction cow (should be [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0])\\n\" + str(np.round(y_cow_pred,2)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTWxvmgViV5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(0, 160):\n",
        "#     print(class_transfer_learning_model.layers[i].__class__.__name__)\n",
        "print(classes_names[9])\n",
        "print(classes_names[12])\n",
        "print(classes_names[14])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93FqS2OCn_Db",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "*The results are based on a training with sq_size = 128! other sq_size may induce different results, of course*\n",
        "___\n",
        "\n",
        "Digging the cow situation, we analyze the results of those two class predictions:\n",
        "\n",
        "\n",
        "* the first one has only 0.44 coef of being a cow, but 0.45 of being a person and 0.12 of being a horse,\n",
        "* the second one has 0.26 coef of being a cow, but even higher chance of being a person\n",
        "\n",
        "Of course, as currently trained as a multilabel problem: for the classifier, there *could* be a cow and a person on this image. Using sigmoid activation, the sum of the 20 classifier's outputs isn't one. However, those results show that in those two cases, an image of a cow alone has activated features of horse, and human (mostly).\n",
        "\n",
        "It's interesting as\n",
        "- a horse is visually close to a cow, even for a human (mammal of comparable size, comparable colors, comparable shape, ...)\n",
        "- \"person\" is the class that is much more represented in the dataset. It does sound right that the system has learned more features about a person, than others, features that are yet activated by a cow. \n",
        "\n",
        "As confirmed by those two samples, the aeroplanes are well recognized, but not the cows. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-nOJu0YcW_G",
        "colab_type": "text"
      },
      "source": [
        "### Digging in the network\n",
        "\n",
        "\n",
        "The following part was possible thanks to https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0\n",
        "\n",
        "Similarly to what was done with the bottleneck features before, it's possible - and interesting ! - to look at how the network was activated  by the image input. we can visualize the different (convolution) layers and their filters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CbiD6HJQwxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        "we create a model that makes available the outputs at each layer\n",
        "'''\n",
        "layer_outputs = [layer.output for layer in class_transfer_learning_model.layers] # Extracts the outputs of the top 12 layers\n",
        "activation_model = tf.keras.models.Model(inputs=class_transfer_learning_model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input\n",
        "\n",
        "activations = activation_model.predict(images_test_cow[1:2]/255)\n",
        "print(activations[0].shape)\n",
        "\n",
        "layer_names = []\n",
        "layers_to_plot = [ l for l in class_transfer_learning_model.layers if ( (l.__class__.__name__ == 'Conv2D') or(l.name == 'gap'))] #(l.__class__.__name__ == 'Conv2D') or\n",
        "for layer in layers_to_plot:\n",
        "    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
        "\n",
        "\n",
        "print(layer_names)\n",
        "images_per_row = 10\n",
        "\n",
        "for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
        "    n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
        "    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
        "    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
        "    display_grid = np.ones((size * n_cols+1, images_per_row * size+1))\n",
        "    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # if layer_name == 'block_1_expand':\n",
        "            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
        "            if channel_image.std() > 0:\n",
        "                channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size, # Displays the grid\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    if layer_name in ['Conv1', 'expanded_conv_project']:\n",
        "        continue\n",
        "    else:\n",
        "        scale = 1. / size\n",
        "        plt.figure(figsize=(int(scale * display_grid.shape[1])+1,\n",
        "                        int(scale * display_grid.shape[0])+1))\n",
        "        plt.title(layer_name)\n",
        "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "        plt.grid(False)\n",
        "        plt.show()\n",
        "\n",
        "    # "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsUIZGLUwWeC",
        "colab_type": "text"
      },
      "source": [
        "The deeper we go into the network, the less visual clue remains, and more abstract features are developped. \n",
        "In the end, we show the activation of the global max pooling layer, before the activation. It is remarkable to observe how, after the MobileNet v2, the features from the aeroplane can look similar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG2ZePDgQzIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for z in [0, 1]:\n",
        "#     activations = activation_model.predict(images_test_aeroplane[z:z+1]/255)\n",
        "#     layer_names = []\n",
        "#     layers_to_plot = [ l for l in class_transfer_learning_model.layers if (l.__class__.__name__ == 'GlobalAveragePooling2D')]\n",
        "#     for layer in layers_to_plot:\n",
        "#         layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
        "#     images_per_row = 10\n",
        "\n",
        "#     layer_name = layers_to_plot[0].name\n",
        "#     layer_activation = activations[155]\n",
        "\n",
        "#     # for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
        "#     n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
        "#     size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
        "#     n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
        "#     display_grid = np.ones((size * n_cols, images_per_row * size))\n",
        "#     for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
        "#         for row in range(images_per_row):\n",
        "#             channel_image = layer_activation[0,\n",
        "#                                             :, :,\n",
        "#                                             col * images_per_row + row]\n",
        "#             channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
        "#             if channel_image.std() > 0:\n",
        "#                 channel_image /= channel_image.std()\n",
        "#             channel_image *= 64\n",
        "#             channel_image += 128\n",
        "#             channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "#             display_grid[col * size : (col + 1) * size, # Displays the grid\n",
        "#                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "#     scale = 1. / size\n",
        "#     # plt.figure(figsize=(int(scale * display_grid.shape[1])+1,\n",
        "#     #                 int(scale * display_grid.shape[0])+1))\n",
        "#     plt.figure()\n",
        "#     plt.title(layer_name)\n",
        "#     plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "#     plt.grid(False)\n",
        "#     plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzX48a24ghcW",
        "colab_type": "text"
      },
      "source": [
        "## Classification - single label\n",
        "\n",
        "So far, I tried to tackle the complete problem of multilabel, multiclass.\n",
        "\n",
        "At the beginning of this notebook, we computed the proportion of such multilabel cases : about 40 % cases.\n",
        "- Around 60% of samples (both in training and validation) are single label instance, \n",
        "- The Multilabels are often limited to a few\n",
        "\n",
        "Following those observations on the data, we may want to change the problem, and tackle a single label / multi-class classification. \n",
        "\n",
        "<u>Consequences: </u>\n",
        "\n",
        "- as shown before, the ratio between each class is not constant, and may vary a lot between some classes (e.g. human and sheep): I want to avoid that, and therefore change the distribution of the training input. \n",
        "\n",
        "This is disputable, but my goal is to train an \"as general\" as possible classifier.\n",
        "\n",
        "- The loss function and activation function used insofar are not adapted anymore, and need to change:\n",
        "    * Loss function: Categorical Cross Entropy\n",
        "    * Activation: 'softmax', as the sum of all output probability should equal to 1\n",
        "    * Metric: accuracy\n",
        "\n",
        "- A new model is built based on those new settings, using Transfer Learning.\n",
        "\n",
        "TL seems particularly adapted as class learning as already been done behind the scenes. I \"just\" need to specialize this base model (trained already) to the specific classes I have from the VOC dataset. It appears quite appealing.\n",
        "\n",
        "<u>Plan summary: </u>\n",
        "1. get training and validation sets\n",
        "2. built a network -- I go for transfer learning.\n",
        "3. number of output class = 20\n",
        "4. output activation = 'softmax'\n",
        "5. loss function = categorical cross-entropy\n",
        "6. metric = categorical accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo3BJWhUWIni",
        "colab_type": "text"
      },
      "source": [
        "####Data input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ccRUKNTnTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "First step: from the dataframes used for the generation we keep only the items with one label\n",
        "'''\n",
        "# sp_df_class_train= get_dataframe_from_classes(df_class_train, )\n",
        "# sp_df_class_val = get_dataframe_from_classes(df_class_val, ('cat','dog'))\n",
        "\n",
        "# training\n",
        "sp_df_class_train_to_generate = df_class_train_to_generate.copy()\n",
        "sp_df_class_train_to_generate[\"nb_classes\"] = sp_df_class_train_to_generate[\"class\"].apply(len)\n",
        "sp_df_class_train_to_generate = sp_df_class_train_to_generate[sp_df_class_train_to_generate[\"nb_classes\"]<2]\n",
        "sp_df_class_train_to_generate = sp_df_class_train_to_generate.reset_index()\n",
        "\n",
        "# validation\n",
        "sp_df_class_val_to_generate = df_class_val_to_generate.copy()\n",
        "sp_df_class_val_to_generate[\"nb_classes\"] = sp_df_class_val_to_generate[\"class\"].apply(len)\n",
        "sp_df_class_val_to_generate = sp_df_class_val_to_generate[sp_df_class_val_to_generate[\"nb_classes\"]<2]\n",
        "sp_df_class_val_to_generate = sp_df_class_val_to_generate.reset_index()\n",
        "\n",
        "print(\" #items in training set: \" + str(len(sp_df_class_train_to_generate[\"class\"])))\n",
        "print(\" #items in validation set: \" + str(len(sp_df_class_val_to_generate[\"class\"])))\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Because the classes are unbalanced, I need extra steps to \n",
        "- randomly select items from the original set\n",
        "- with a weight inversely proportional to original class weight\n",
        "The goal is to have a as flat as possible distribution\n",
        "\n",
        "==> drawback: we throw away a lot\n",
        "'''\n",
        "sp_training_labels = multiLabelBinarizer.transform(sp_df_class_train_to_generate[\"class\"])\n",
        "sp_classes_weights = np.sum(sp_training_labels == 1, axis = 0) / sp_training_labels.shape[0]\n",
        "print(\"Weights of the different classes, in the Single Label context:\" + str(sp_classes_weights))\n",
        "\n",
        "# inverted weights, indicating the weights for sampling\n",
        "sp_inverted_classes_weights = (1/sp_classes_weights)/ np.sum(1/sp_classes_weights)\n",
        "print(sp_inverted_classes_weights)\n",
        "\n",
        "# add a column for this weight\n",
        "def _loc(df):\n",
        "    df = df.assign(sampling_rate=0)\n",
        "    for i in range(len(classes_names)):\n",
        "        df.loc[df['class']==(classes_names[i],), 'sampling_rate'] = sp_inverted_classes_weights[i]\n",
        "    return df\n",
        "sp_df_class_train_to_generate = _loc(sp_df_class_train_to_generate)\n",
        "sp_df_class_val_to_generate = _loc(sp_df_class_val_to_generate)\n",
        "\n",
        "\n",
        "#sample appropriately 1500 for training and for validation from the single_label inout dataframe\n",
        "sp_df_class_train_to_generate = sp_df_class_train_to_generate.sample(2200, weights = sp_df_class_train_to_generate['sampling_rate'], random_state=1000)\n",
        "print(\"\\nNew single-label dataframe for training (5 first elem):\")\n",
        "print(sp_df_class_train_to_generate.head(5))\n",
        "\n",
        "\n",
        "sp_df_class_val_to_generate = sp_df_class_val_to_generate.sample(500, weights = sp_df_class_val_to_generate['sampling_rate'], random_state=500)\n",
        "print(\"\\nNew single-label dataframe for validation (5 first elem):\")\n",
        "print(sp_df_class_val_to_generate.head(5))\n",
        "\n",
        "'''\n",
        "Check the distribution\n",
        "'''\n",
        "# count the number of items of each class\n",
        "sp_counts_training = np.zeros((num_classes,))\n",
        "sp_counts_validation = np.zeros((num_classes,))\n",
        "for i in range(len(classes_names)):\n",
        "    sp_counts_training[i] = len(sp_df_class_train_to_generate[sp_df_class_train_to_generate['class'] ==  (classes_names[i],)]) \n",
        "    sp_counts_validation[i] = len(sp_df_class_val_to_generate[sp_df_class_val_to_generate['class'] ==  (classes_names[i],)]) \n",
        "\n",
        "# get the classes' ratio\n",
        "sp_counts_training /= sum(sp_counts_training)\n",
        "sp_counts_training*=100\n",
        "sp_counts_validation /= sum(sp_counts_validation)\n",
        "sp_counts_validation*=100\n",
        "\n",
        "# add this count to the dataframe containing proportions\n",
        "local_df[\"sp_training\"] = list(sp_counts_training)\n",
        "local_df[\"sp_validation\"] = list(sp_counts_validation)\n",
        "\n",
        "# compare to original training/validation\n",
        "print(\"\\n\\nProportion of each class associated to a specific set\")\n",
        "print(local_df.to_string())\n",
        "\n",
        "# print(len(sp_df_class_train_to_generate[\"class\"]))\n",
        "# print(len(sp_df_class_val_to_generate[\"class\"]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43w4IsKHr2TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "based on the dataframe, create tf generator\n",
        "'''\n",
        "sp_train_set_class_tf_generator         = get_classification_generator(sp_df_class_train_to_generate, multiLabelBinarizer, to_augment = True)\n",
        "sp_val_set_class_tf_generator           = get_classification_generator(sp_df_class_val_to_generate, multiLabelBinarizer, to_augment = False)\n",
        "#Because Keras API seems to give better results at this point\n",
        "sp_train_class_keras_generator          = get_classification_keras_generator(sp_df_class_train_to_generate, 'training')\n",
        "sp_val_set_class_keras_generator        = get_classification_keras_generator(sp_df_class_val_to_generate, 'validation')\n",
        "\n",
        "'''\n",
        "Plot to see the check the inputs of the training models\n",
        "'''\n",
        "\n",
        "sp_img_local, sp_labels_local = next(iter(sp_train_class_keras_generator))\n",
        "plot_matrix(sp_img_local, multiLabelBinarizer.inverse_transform(np.array(sp_labels_local)), scale = 2)\n",
        "\n",
        "sp_img_local, sp_labels_local = next(iter(sp_val_set_class_keras_generator))\n",
        "# plot_matrix(sp_img_local, multiLabelBinarizer.inverse_transform(np.array(sp_labels_local)), scale = 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrSYQ4k2WF23",
        "colab_type": "text"
      },
      "source": [
        "### Creation of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyUMbmtsrwJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# Create the base model from the pre-trained model MobileNet V2, for single label\n",
        "case.\n",
        "credit: https://www.tensorflow.org/tutorials/images/transfer_learning\n",
        "\n",
        "'''\n",
        "print('('+str(height) + \",\" + str(width) +', ' + str(channel) + \")\")\n",
        "\n",
        "'''\n",
        "Inspect a batch of data\n",
        "'''\n",
        "for image_batch, label_batch in sp_train_set_class_tf_generator.take(1):\n",
        "   pass\n",
        "\n",
        "image_batch.shape\n",
        "\n",
        "'''\n",
        "Creation of the Pre-trained model => MobileNet\n",
        "'''\n",
        "sp_base_model = tf.keras.applications.MobileNetV2(input_shape=(height, width, channel),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "sp_base_model.trainable = False\n",
        "\n",
        "feature_batch = sp_base_model(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "'''\n",
        "Add the classification head => here we want softmax as 1 label only\n",
        "'''\n",
        "# output_base_model = sp_base_model.layers[-1].output\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)\n",
        "\n",
        "\n",
        "prediction_layer   = tf.keras.layers.Dense(num_classes,kernel_regularizer=tf.keras.regularizers.l2(0.001), activation='softmax')\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)\n",
        "\n",
        "'''\n",
        "build the model\n",
        "# note: we used another API than before, in order to get acquainted with this tk.keras library\n",
        "'''\n",
        "model_sp = tf.keras.Sequential([\n",
        "                                 sp_base_model,\n",
        "                                 global_average_layer,\n",
        "                                 prediction_layer])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FlsxEGFdeo9",
        "colab_type": "text"
      },
      "source": [
        "###Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3LljAQtZCVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Compile\n",
        "'''\n",
        "# Compile the model\n",
        "model_sp.compile(optimizer=  tf.keras.optimizers.Adam(0.0001), #get_optimizer(), #\n",
        "                                    loss=tf.keras.losses.categorical_crossentropy, # to explain\n",
        "                                    metrics=['accuracy']) #categorical accuracy chosen\n",
        "\n",
        "\n",
        "model_sp.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujYTs7Ehaagw",
        "colab_type": "text"
      },
      "source": [
        "Based on this model, we can evaluate directly the loss and accuracy, on several batches. We get something close to random => 1/20 = 5% accuracy. This is expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQMn0YQ1ZpQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss0,accuracy0 = model_sp.evaluate(sp_val_set_class_tf_generator.take(100), steps = 100)\n",
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2nPlbeqdogH",
        "colab_type": "text"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1SZKu3jZYNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_model = True\n",
        "#' + str(int(time.time())) + '\n",
        "if train_class_model_sp:\n",
        "    history_model_sp = model_sp.fit(   sp_train_class_keras_generator, #  sp_train_set_class_tf_generator\n",
        "                                                steps_per_epoch= len(sp_df_class_train_to_generate[\"filename\"]) // BS,\n",
        "                                                epochs=EPOCHS, \n",
        "                                                callbacks=[my_callbacks],\n",
        "                                                validation_data= sp_val_set_class_tf_generator, #val_img_gen, #\n",
        "                                                validation_steps = len(sp_df_class_val_to_generate[\"filename\"]) // BS,\n",
        "        )\n",
        "    model_sp.save_weights(single_model_save_filename)\n",
        "    histories['model_sp'] = history_model_sp.history\n",
        "    pickle.dump(histories[\"model_sp\"], open(single_model_hist_save_filename, 'wb'))\n",
        "else:\n",
        "    model_sp.load_weights(single_model_save_filename)\n",
        "    histories['model_sp'] = pickle.load(open(single_model_hist_save_filename, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeZEWcu0J_kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key_ in  [\"model_sp\"]: #histories.keys():\n",
        "    print(\"key = \" + str(key_))\n",
        "    try:\n",
        "        acc = histories[key_]['accuracy']\n",
        "        val_acc = histories[key_]['val_accuracy']\n",
        "\n",
        "        loss = histories[key_]['loss']\n",
        "        val_loss = histories[key_]['val_loss']\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.subplot(2, 1, 1)\n",
        "\n",
        "        plt.plot(acc, label='Training accuracy')\n",
        "        plt.plot(val_acc, label='Validation accuracy')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.ylim([0,1])\n",
        "        plt.title('Training and Validation accuracy')\n",
        "\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(loss, label='Training Loss')\n",
        "        plt.plot(val_loss, label='Validation Loss')\n",
        "        plt.legend(loc='upper right')\n",
        "        plt.ylabel('Cross Entropy')\n",
        "        # plt.ylim([0,1.0])\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.show()\n",
        "    except KeyError:\n",
        "        print(\"Key error -> pass\")\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEWXaJYObucK",
        "colab_type": "text"
      },
      "source": [
        "###Analysis\n",
        "With this model, the confusion matrix isnt' binary anymore but multiclass, of course"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM4py9-1buDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Get the validation data ready for prediction\n",
        "'''\n",
        "# retrieve the ids from the dataframe\n",
        "sp_val_ids = list(sp_df_class_val_to_generate[\"filename\"].apply(lambda x: x.split('.')[0]))\n",
        "\n",
        "# load the images in RAM\n",
        "sp_val_images = get_images(sp_val_ids, path_image_folder,width=sq_size, height=sq_size,)\n",
        "if np.max(np.max(sp_val_images)) > 1:\n",
        "    sp_val_images = np.divide(sp_val_images,255.0, dtype = np.float32)\n",
        "\n",
        "# retrieve the labels from the dataframe\n",
        "sp_val_labels_binarized = multiLabelBinarizer.transform(sp_df_class_val_to_generate[\"class\"])\n",
        "sp_val_labels_str = list(sp_df_class_val_to_generate[\"class\"])\n",
        "y_true = sp_val_labels_binarized\n",
        "\n",
        "\n",
        "'''\n",
        "Predict\n",
        "'''\n",
        "y_pred = model_sp.predict(sp_val_images)\n",
        "# y_pred_str = multiLabelBinarizer.inverse_transform(y_pred)\n",
        "\n",
        "'''\n",
        "Check on shapes\n",
        "'''\n",
        "print(\"y_true shape = \" + str(y_true.shape))\n",
        "print(\"y_pred shape = \" + str(y_pred.shape))\n",
        "\n",
        "'''\n",
        "convert one hot encoding to categorical using argmax\n",
        "'''\n",
        "y_true_categorical = [ np.argmax(t) for t in y_true ]\n",
        "y_pred_categorical = [ np.argmax(t) for t in y_pred ]\n",
        "'''\n",
        "Compute confusion matrix\n",
        "'''\n",
        "conf_mat_dict = sklearn.metrics.confusion_matrix(y_true = y_true_categorical, y_pred = y_pred_categorical)\n",
        "conf_mat_dict_norm = sklearn.metrics.confusion_matrix( y_true=y_true_categorical, y_pred = y_pred_categorical, normalize = 'true')\n",
        "\n",
        "\n",
        "'''\n",
        "sp_classes_names => no diningtable (item #10 in zero indexing)\n",
        "'''\n",
        "\n",
        "classes_names_wo_diningtable = tuple([name for name in classes_names if not(name == 'diningtable')])\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1,2,figsize = (25,10))\n",
        "\n",
        "# group_names = ['TN','FP','FN','TP']\n",
        "# local_labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\n",
        "group_counts = [str(int(value))  if value > 0.01 else \"<\" for value in conf_mat_dict.flatten()]\n",
        "# group_percentages = [\"{0:0.2f}\".format(value) if value > 0.05 else \"<\" for value in conf_mat_dict.flatten()/np.sum(conf_mat_dict)]\n",
        "\n",
        "if len(group_counts) == 361:\n",
        "    size_local_labels = 19\n",
        "    sp_classes_names = classes_names_wo_diningtable\n",
        "else:\n",
        "    size_local_labels = 20\n",
        "    sp_classes_names = classes_names\n",
        "\n",
        "local_labels = np.asarray(group_counts).reshape(size_local_labels,size_local_labels)\n",
        "\n",
        "\n",
        "sns.heatmap(conf_mat_dict, fmt='', annot=local_labels ,xticklabels=sp_classes_names, yticklabels=sp_classes_names, ax=axes[0])\n",
        "axes[0].set_title(\"Confusion Matrix\")\n",
        "\n",
        "group_counts = [\"{0:0.2f}\".format(value)  if value > 0.05 else \"<\" for value in conf_mat_dict_norm.flatten()]\n",
        "local_labels = np.asarray(group_counts).reshape(size_local_labels,size_local_labels)\n",
        "sns.heatmap(conf_mat_dict_norm, fmt='', annot=local_labels ,xticklabels=sp_classes_names, yticklabels=sp_classes_names, ax=axes[1])\n",
        "axes[1].set_title(\"Confusion Matrix normalized per True values\")\n",
        "\n",
        "'''\n",
        "Question: is the model capable of predicting a diningtable?\n",
        "'''\n",
        "y_pred = model_sp.predict(val_images)\n",
        "print(\"If the model is capable, all the index should have been predicted from the global validation set (containing all the classes):\")\n",
        "print(np.unique(np.argmax(y_pred, axis=-1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peFkiMwduUyA",
        "colab_type": "text"
      },
      "source": [
        "###Conclusion\n",
        "1.  From scratch models\n",
        "    * v1 -> lots of weights\n",
        "    * v2 -> attempt to solve overfitting - does not work always\n",
        "    * v3 -> deeper convolution: less weights, deeper -> better results\n",
        "2.  Transfer Learning - MobileNetv2\n",
        "    * Much Better - ~63% (sqsize = 128) to ~70% (sqsize = 224)\n",
        "    * Overfitting --> not adapted to fine tuning (although implemented)\n",
        "    * VGG16 -> worst results; Restnet -> slower\n",
        "\n",
        "3.  'Simpler' problem: Single-label multi-class classification\n",
        "    * Better results\n",
        "    * Lack of data overall\n",
        "    * Classes better represented perform better as well\n",
        "\n",
        "\n",
        "---\n",
        "* Overall lack of data. Data augmentation helps but is not miraculous at this point\n",
        "* Drop Out tested but not (always) successfull\n",
        "* Batch Normalization helps\n",
        "* Mean substraction does not help (at least, in the sq_size = 128 case)\n",
        "* Confusion Matrix is a nice tool to apprehend behaviour\n",
        "* Importance of image input pipeline (intuitive)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlO1cf8nd_cD",
        "colab_type": "text"
      },
      "source": [
        "##Clean Up RAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49BWEImceB8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    del training_set_class_tf_generator\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    del val_set_class_tf_generator\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    del sp_train_class_tf_generator\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    del sp_val_class_tf_generator\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    del train_img_gen\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    del val_img_gen\n",
        "except:\n",
        "    pass\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3xrsvWf8ikC",
        "colab_type": "text"
      },
      "source": [
        "# Segmentation Tasks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuEYqnxYERxp",
        "colab_type": "text"
      },
      "source": [
        "### Definition of the data pipeline\n",
        "In a very similar fashion to Classification Tasks, we define a pipeline (based on tf.Data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btl-0UiZuP10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "override parameters\n",
        "'''\n",
        "sq_size = 224\n",
        "height = sq_size\n",
        "width = sq_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pevuFHDz9KHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Segmentation\n",
        "'''\n",
        "print(\"--\" * 50)\n",
        "training_seg_ids = get_ids(\"training\", \"segmentation\")\n",
        "validation_seg_ids = get_ids(\"validation\", \"segmentation\")\n",
        "\n",
        "print(\"Segmentation task:\")\n",
        "print(\"training set,   #elements = \", len(training_seg_ids))\n",
        "print(\"validation set, #elements = \", len(validation_seg_ids))\n",
        "\n",
        "print(training_seg_ids[0:2])\n",
        "print(validation_seg_ids[0:2])\n",
        "\n",
        "'''\n",
        "get labels\n",
        "'''\n",
        "\n",
        "training_seg_labels_str = get_class_labels_str(training_seg_ids, classification_type = classification_type, n_samples = None )\n",
        "val_seg_labels_str = get_class_labels_str(validation_seg_ids, classification_type = classification_type, n_samples = None)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPZFUd4y-YP4",
        "colab_type": "text"
      },
      "source": [
        "####Create base dictionary\n",
        "\n",
        "At this point, we have the structures that contains all the info for the pipeline. The name of the variables is kept as explicit as possible\n",
        "\n",
        ">`name` | type | description\n",
        ">---|---|---\n",
        ">`d_seg_train`| dictionary | training dictionary for segmentation\n",
        ">`d_seg_val` | dictionary | validation dictionary for segmentation\n",
        ">`df_seg_train`| dataframe | training dataframe for segmentation\n",
        ">`df_seg_val` | dataframe | validation dataframe for segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVm9YKtgOPCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "build dictionary and dataframe\n",
        "'''\n",
        "d_seg_train = {'stem_filename': training_seg_ids , 'class': training_seg_labels_str}\n",
        "d_seg_val   = {'stem_filename': validation_seg_ids , 'class': val_seg_labels_str}\n",
        "\n",
        "df_seg_train = pd.DataFrame(data=d_seg_train)\n",
        "df_seg_val   = pd.DataFrame(data=d_seg_val)\n",
        "\n",
        "## Example of dataframe with horses only\n",
        "# df_seg_train_horse = get_dataframe_from_classes(df_seg_train, ('horse',))\n",
        "# df_seg_val_horse = get_dataframe_from_classes(df_seg_val, ('horse',))\n",
        "\n",
        "'''\n",
        "the dataframes that are used to generate data. \n",
        "It can be change with more specific dataframe, if needed \n",
        "(or a new generator can be created as well, see below)\n",
        "'''\n",
        "df_seg_train_to_generate = df_seg_train\n",
        "df_seg_val_to_generate   = df_seg_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUZPatYTEwuT",
        "colab_type": "text"
      },
      "source": [
        "Although there are other ways, the colormap is short enough to be hardcoded manually (pragmatic yet not production-ready solution)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcgqUpSz-WoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Segmentation part\n",
        "'''\n",
        "\n",
        "colormap = ((0,0,0),(128,0,0), (0,128,0),(128,128,0),(0,0,128),(128,0,128), (0,128,128),(128,128,128),\n",
        "                           (64,0,0),(192,0,0), (64,128,0), (192,128,0), (64,0,128), (192,0,128), (64,128,128),\n",
        "                           (192,128,128),(0,64,0), (128,64,0), (0,192,0),(128,192,0), (0,64,128),(224, 224, 192))\n",
        "# colormap = np.array(colormap_uint8, np.float32) \n",
        "# colormap = colormap/255.0\n",
        "# print(colormap)\n",
        "color_class = {\"color\": colormap,\n",
        "                 \"class_id\":(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,255),\n",
        "                 \"classes_names\" :( 'background', 'aeroplane','bicycle', 'bird','boat','bottle','bus','car',\n",
        "                'cat', 'chair','cow','diningtable','dog','horse','motorbike',\n",
        "                'person','pottedplant','sheep','sofa','train','tvmonitor', 'void') }\n",
        "df_color_class = pd.DataFrame(color_class)\n",
        "print(df_color_class.to_string())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p3XT2Djm-Zc",
        "colab_type": "text"
      },
      "source": [
        "####Creation of the generators\n",
        "\n",
        "similarly to classification task, tf.Data generators can be built up. \n",
        "In particular it:\n",
        "- loads an image\n",
        "- converts its mask to one-hot encoding representation\n",
        "- resize of the image\n",
        "- convert pix value to float, between [0,1]\n",
        "- performs (limited!) data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSJBidaVRJ6a",
        "colab_type": "text"
      },
      "source": [
        "######Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kkaSU3HHr0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Helper function to create generartors using tensorflow Data API\n",
        "'''\n",
        "\n",
        "# https://www.tensorflow.org/tutorials/images/segmentation\n",
        "\n",
        "def _one_hot_encode(mask):\n",
        "    \"\"\"\n",
        "    Converts mask to a one-hot encoding specified by the semantic map.\n",
        "    source: inspired by https://stackoverflow.com/questions/57518057/how-can-i-convert-an-image-from-pixels-to-one-hot-encodings\n",
        "    does not use directly tf.onehot\n",
        "    \"\"\"\n",
        "    # Create a \"color reference\" tensor from image_colors\n",
        "    color_reference = tf.cast(tf.constant(colormap[0:21]), dtype=tf.float32)\n",
        "    # Load the image and obtain tensor with one-hot values\n",
        "    comp = tf.equal(mask[..., None, :], color_reference)\n",
        "    one_hot_map = tf.cast(tf.reduce_all(comp, axis=-1), dtype=tf.float32)\n",
        "    # print(one_hot_map.shape)\n",
        "    return one_hot_map\n",
        "\n",
        "\n",
        "def segmentation_normalize(input_image, input_mask):\n",
        "    '''\n",
        "    Normalize an input image by:\n",
        "    - convert it to float32, within [0.0, 1.0]\n",
        "    - encode the input_mask\n",
        "    '''\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask = _one_hot_encode(input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "\n",
        "def parse_segmentation_function(stem_filename):\n",
        "    '''\n",
        "    @param stem_filename: id of the image files to read\n",
        "    '''\n",
        "    filename_input_image = voc_root_folder + r'/JPEGImages/' + stem_filename + \".jpg\"\n",
        "    filename_input_mask = voc_root_folder + r'/SegmentationClass/' + stem_filename + \".png\"\n",
        "\n",
        "    input_image_string = tf.io.read_file(filename_input_image)\n",
        "    input_image = tf.image.decode_jpeg(input_image_string, channels=3)\n",
        "\n",
        "    input_mask_string = tf.io.read_file(filename_input_mask)\n",
        "    input_mask = tf.image.decode_png(input_mask_string, channels=3)\n",
        "\n",
        "    input_image = tf.image.resize(input_image, [sq_size, sq_size])\n",
        "    input_mask = tf.image.resize(input_mask, [sq_size, sq_size])\n",
        "\n",
        "    input_image, input_mask = segmentation_normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "\n",
        "def train_segmentation_preprocess(input_image, input_mask):\n",
        "    '''\n",
        "    Segmentation pre-processing -- linked to data augmentation\n",
        "    Only perform a random flip of the input insofar\n",
        "    The benefits of such augmentation are yet not really clear on the augmentation\n",
        "    '''\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "    # if tf.random.uniform(()) > 0.5:\n",
        "    #     input_image = tf.image.central_crop(input_image, central_fraction=0.5)\n",
        "    #     input_mask = tf.image.central_crop(input_mask, central_fraction=0.5)\n",
        "    #     input_image = tf.image.resize(input_image, [sq_size, sq_size])\n",
        "    #     input_mask = tf.image.resize(input_mask, [sq_size, sq_size])\n",
        "\n",
        "    # input_image = tf.image.random_brightness(input_image, max_delta=0.3)\n",
        "    # input_image = tf.image.random_saturation(input_image, lower=0.8, upper=1.2)\n",
        "    # input_image = tf.image.random_contrast(input_image, 0.85, 1.15)\n",
        "    \n",
        "    # tf.print(tf.reduce_mean(input_image, axis=None))\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "# def train_segmentation_reduce(input_image, input_mask):\n",
        "#     '''\n",
        "#     convert a (sq_size, sq_size, 22) to a (sqsize, sqsize, 3)\n",
        "#     '''\n",
        "#     get_class_number = tf.argmax(input_mask, axis=-1)\n",
        "    \n",
        "#     t_ = tf.convert_to_tensor(arr)\n",
        "\n",
        "#     # print(get_class_number.numpy)\n",
        "#     tf.print(t_)\n",
        "#     # condition = tf.equal(get_class_number, tf.constant(0, dtype = tf.int64)) or \\\n",
        "#     #             tf.equal(get_class_number, tf.constant(1, dtype = tf.int64)) or \\\n",
        "#     #             tf.equal(get_class_number, tf.constant(13, dtype = tf.int64))\n",
        "#     # case_true = get_class_number #\n",
        "#     # case_false = 0\n",
        "#     # get_class_number = tf.where(condition, case_true, case_false)\n",
        "#     tf.print(get_class_number)\n",
        "#     # one_hot_map = tf.one_hot(indices =get_class_number, depth=3, on_value=1, off_value=0, axis=-1, dtype=None,)\n",
        "\n",
        "#     # condition2 = tf.equal(get_class_number, tf.constant(13, dtype = tf.int64))    \n",
        "    \n",
        "#     # local_colormap = ((0,0,0),(128,0,0), (192,0,128),)\n",
        "#     # local_color_reference = tf.cast(tf.constant(local_colormap), dtype=tf.int64)\n",
        "#     # # Load the image and obtain tensor with one-hot values\n",
        "#     # comp = tf.equal(get_class_number[..., None, :], local_color_reference)\n",
        "#     # one_hot_map = tf.cast(tf.reduce_all(comp, axis=-1), dtype=tf.float32)\n",
        "\n",
        "\n",
        "#     # print(get_class_number.numpy)\n",
        "#     # print(\"end\")\n",
        "\n",
        "#     return input_image, input_mask\n",
        "\n",
        "\n",
        "def get_segmentation_generator(dataframe, cache = True, to_augment = True, reduced = False):\n",
        "    '''\n",
        "    In the exact same fashion as get_classification_generator, it returns a \n",
        "    tf generator of image and label for segmentation task. \n",
        "    This generator allows caching\n",
        "    '''\n",
        "    stem_filenames = dataframe[\"stem_filename\"]\n",
        "    tf_generator = tf.data.Dataset.from_tensor_slices(stem_filenames)\n",
        "    \n",
        "    tf_generator = tf_generator.map(parse_segmentation_function, num_parallel_calls = AUTOTUNE)\n",
        "    \n",
        "    # if reduced:\n",
        "    #     tf_generator = tf_generator.map(train_segmentation_reduce, num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "    if isinstance(cache, str):      \n",
        "        tf_generator = tf_generator.cache(cache)\n",
        "    else:\n",
        "        tf_generator = tf_generator.cache()\n",
        "    \n",
        "    if to_augment:\n",
        "        tf_generator = tf_generator.map(train_segmentation_preprocess, num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "    tf_generator = tf_generator.shuffle(len(stem_filenames), seed = 426473)\n",
        "    tf_generator = tf_generator.repeat()\n",
        "    tf_generator = tf_generator.batch(BATCH_SIZE)\n",
        "    tf_generator = tf_generator.prefetch(buffer_size = AUTOTUNE)\n",
        "    return tf_generator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXahz-rFRCHh",
        "colab_type": "text"
      },
      "source": [
        "######Creation of the generators\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKywbSX4H6R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_seg_tf_generator   = get_segmentation_generator(df_seg_train_to_generate, to_augment = False)\n",
        "val_set_seg_tf_generator        = get_segmentation_generator(df_seg_val_to_generate, to_augment = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0pedJMWWdMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VAL_SUBSPLITS = 1\n",
        "BATCH_SIZE = 10 #10\n",
        "BS = BATCH_SIZE\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = len(df_seg_train_to_generate) // BATCH_SIZE  # TRAIN_LENGTH // BATCH_SIZE\n",
        "VALIDATION_STEPS = len(df_seg_val_to_generate) // BATCH_SIZE // VAL_SUBSPLITS #VAL_LENGTH//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "OUTPUT_CHANNELS = 20+1 #+1 # 20 classes + background + void (shoud not be, But I don't know how to tackle cleanly)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49Z1_QdsXY4M",
        "colab_type": "text"
      },
      "source": [
        "####Visualization\n",
        "Heper Function to get the colors and to visualize the mask created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGmAuFaeG4Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Creation of a palette, and visualisation of the mask\n",
        "source of the code snippet : https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/vis.py\n",
        "'''\n",
        "def make_palette(num_classes):\n",
        "    \"\"\"\n",
        "    NOT USED AS COLORS HARDCODED\n",
        "\n",
        "    Maps classes to colors in the style of PASCAL VOC.\n",
        "    Close values are mapped to far colors for segmentation visualization.\n",
        "    See http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#devkit\n",
        "    Takes:\n",
        "        num_classes: the number of classes\n",
        "    Gives:\n",
        "        palette: the colormap as a k x 3 array of RGB colors\n",
        "    \"\"\"\n",
        "    palette = np.zeros((num_classes, 3), dtype=np.uint8)\n",
        "    for k in range(0, num_classes):\n",
        "        label = k\n",
        "        i = 0\n",
        "        while label:\n",
        "            palette[k, 0] |= (((label >> 0) & 1) << (7 - i))\n",
        "            palette[k, 1] |= (((label >> 1) & 1) << (7 - i))\n",
        "            palette[k, 2] |= (((label >> 2) & 1) << (7 - i))\n",
        "            label >>= 3\n",
        "            i += 1\n",
        "    return palette\n",
        "\n",
        "def color_seg(seg, palette):\n",
        "    \"\"\"\n",
        "    Replace classes with their colors.\n",
        "    Takes:\n",
        "        seg: H x W segmentation image of class IDs\n",
        "    Gives:\n",
        "        H x W x 3 image of class colors\n",
        "    \"\"\"\n",
        "    res = palette[seg.flat].reshape(seg.shape + (3,))\n",
        "    return res\n",
        "\n",
        "def vis_seg(img, seg, palette, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Visualize segmentation as an overlay on the image.\n",
        "    Takes:\n",
        "        img: H x W x 3 image in [0, 255]\n",
        "        seg: H x W segmentation image of class IDs\n",
        "        palette: K x 3 colormap for all classes\n",
        "        alpha: opacity of the segmentation in [0, 1]\n",
        "    Gives:\n",
        "        H x W x 3 image with overlaid segmentation\n",
        "    \"\"\"\n",
        "    vis = np.array(img, dtype=np.float32)\n",
        "    mask = seg > 0\n",
        "    vis[mask] *= 1. - alpha\n",
        "    vis[mask] += alpha * palette[seg[mask].flat]\n",
        "    # vis = vis.astype(np.uint8)\n",
        "    return vis\n",
        "\n",
        "\n",
        "def display(display_list):\n",
        "    '''\n",
        "        Utils function from XXX\n",
        "        Allows plotting :\n",
        "        | input image | the True Mask | The predicted Mask |\n",
        "    '''\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def create_mask(pred_mask, ):\n",
        "    '''\n",
        "    transform a prediction to a an image\n",
        "    '''\n",
        "    if len(pred_mask.shape) == 4:\n",
        "        pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "        return color_seg(np.array(pred_mask[0]), np.array(colormap[0:21])/255.0)\n",
        "    elif len(pred_mask.shape) == 3:\n",
        "        pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "        return color_seg(np.array(pred_mask), np.array(colormap[0:21])/255.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhKbUCJmHBYR",
        "colab_type": "text"
      },
      "source": [
        "Sanity checks on the behavior of the previous functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeBLes3oHCdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "- load images using the generators, and show them using plot_matrix (as usual)\n",
        "- create corresponding mask from the one-hot encoding, and show them \n",
        "'''\n",
        "# palette=make_palette(21)\n",
        "# print(palette)\n",
        "# plot_matrix(np.array(color_seg(np.array(pred_mask), palette)).T, color=True)\n",
        "# display([color_seg(np.array(pred_mask),palette)])\n",
        "\n",
        "print(\"Segmentation Training Set\")\n",
        "image_batch, mask_batch = next(iter(training_set_seg_tf_generator))\n",
        "plot_matrix(image_batch, scale=2)\n",
        "tab_mask = np.empty((32,sq_size,sq_size,3), np.float32)\n",
        "i = 0\n",
        "for mask_ in mask_batch:\n",
        "    tab_mask[i,:] = create_mask(mask_)\n",
        "    i+=1\n",
        "plot_matrix(tab_mask, scale=2)\n",
        "# print(\"dtype of image = \" + str(image_val_batch[0].dtype))\n",
        "# print(\"dtype of mask  = \" + str(mask_val_batch[0].dtype))\n",
        "# print(\"max value mask = \" + str(np.max(mask_val_batch)))\n",
        "# print(\"min value mask = \" + str(np.min(mask_val_batch)))\n",
        "\n",
        "print(\"Segmentation Validation Set\")\n",
        "image_batch, mask_batch = next(iter(val_set_seg_tf_generator))\n",
        "plot_matrix(image_batch, scale=2)\n",
        "tab_mask = np.empty((32,sq_size,sq_size,3), np.float32)\n",
        "i = 0\n",
        "for mask_ in mask_batch:\n",
        "    tab_mask[i,:] = create_mask(mask_)\n",
        "    i+=1\n",
        "plot_matrix(tab_mask,scale=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiiElJe2bieq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekk-vRnaHU0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "viewing the numbers; just for ppt purpose\n",
        "'''\n",
        "\n",
        "# image_val_batch, mask_val_batch = next(iter(training_set_seg_tf_generator))\n",
        "# mask_ = mask_val_batch[0]\n",
        "# plot_matrix(np.array([image_val_batch[0]]), scale=3)\n",
        "# pred_mask = tf.argmax(mask_, axis=-1)\n",
        "# print(\"pred_mask.shape\", pred_mask.shape)\n",
        "# plot_matrix(np.array([pred_mask]), color = True, scale=3)\n",
        "# with np.printoptions(threshold=sys.maxsize, linewidth = 100):\n",
        "#     print(pred_mask[55:60,55:64].numpy())\n",
        "#     # print(mask_[55:60, 55:64, :].numpy())\n",
        "# plt.figure(figsize=(10,10))\n",
        "# sns.heatmap(pred_mask[55:64, 55:64], annot = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZL5zvSMrJiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "segmentation part: check of the pipeline\n",
        "'''\n",
        "stem_filename_ = \"2007_002400\" #2007_000129\n",
        "\n",
        "toy_filename_input_image = voc_root_folder + r'/JPEGImages/' + stem_filename_ + \".jpg\"\n",
        "toy_filename_input_mask = voc_root_folder + r'/SegmentationClass/' + stem_filename_ + \".png\"\n",
        "\n",
        "toy_input_image_string = tf.io.read_file(toy_filename_input_image)\n",
        "toy_input_image = tf.image.decode_jpeg(toy_input_image_string, channels=3)\n",
        "\n",
        "toy_input_mask_string = tf.io.read_file(toy_filename_input_mask)\n",
        "toy_input_mask = tf.image.decode_png(toy_input_mask_string, channels=3)\n",
        "\n",
        "toy_input_image = tf.image.resize(toy_input_image, [sq_size, sq_size])\n",
        "toy_input_mask = tf.image.resize(toy_input_mask, [sq_size, sq_size])\n",
        "img_source = tf.cast(toy_input_image, tf.float32) / 255.0 \n",
        "mask_source = tf.cast(toy_input_mask, tf.int32)\n",
        "\n",
        "display([img_source,mask_source])\n",
        "one_hot_ = _one_hot_encode(tf.cast(mask_source, tf.float32))\n",
        "print(\"one hot shape:\" + str(one_hot_.shape))\n",
        "\n",
        "# one_hot_tmp = tf.one_hot(mask_source, colormap)\n",
        "# print(\"TensorFlow one hot: \", one_hot_tmp.shape)\n",
        "# crop = one_hot_[80:87, 60:65]\n",
        "# display([mask_source[80:87, 60:65]])\n",
        "# print(crop)\n",
        "# print(\"==\"*30)\n",
        "\n",
        "pred_tmp = tf.argmax(one_hot_, axis=-1)\n",
        "display([img_source, mask_source, color_seg(np.array(pred_tmp), np.array(colormap[0:21]))])\n",
        "print(\"unique classes: \" + str(np.unique(pred_tmp)))\n",
        "\n",
        "# for i,j in zip(palette, colormap):\n",
        "# #     print(str(i)+ \" <-> \" + str(j))\n",
        "# print( ('bird',) in list(df_seg_val_to_generate[\"class\"]))\n",
        "# print( \"2007_002400\" in list(df_seg_val_to_generate[\"stem_filename\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWTnBiwy8kvd",
        "colab_type": "text"
      },
      "source": [
        "##Definition of loss and score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uPHcYr4WQm-",
        "colab_type": "text"
      },
      "source": [
        "The class MyScore gathers some metrics interessant in the context of image segmentation \n",
        "- dice score and loss\n",
        "- generalized dice score\n",
        "- twersky loss\n",
        "\n",
        "Not all are used, but are left in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YleDMUZU8pvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyScore():\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def iou_coef(y_true, y_pred):\n",
        "        '''\n",
        "        classical intersection over union idea\n",
        "        '''\n",
        "        # axis = 1,2,3 ---> per image\n",
        "        smooth = 1\n",
        "        intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis = [1,2,3])\n",
        "        union        = tf.keras.backend.sum(y_true, axis = [1,2,3]) + tf.keras.backend.sum(y_pred, axis = [1,2,3]) - intersection\n",
        "        iou = tf.keras.backend.mean((intersection + smooth)/ (union + smooth) , axis = 0)\n",
        "        return iou\n",
        "    \n",
        "    @staticmethod\n",
        "    def dice_loss(y_true, y_pred):\n",
        "        '''\n",
        "        As refered to in the litterature, as in \n",
        "        https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/\n",
        "\n",
        "        '''\n",
        "        return 1 - MyScore.dice_score(y_true, y_pred)\n",
        "    \n",
        "    @staticmethod\n",
        "    def dice_score(y_true, y_pred):\n",
        "        name_of_class = y_true.__class__.__name__\n",
        "        if not (\"Tensor\" in name_of_class):\n",
        "            y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
        "            y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
        "\n",
        "        eps = 1e-7\n",
        "        numerator = 2 * tf.reduce_sum(y_true * y_pred, axis = (0,1,2)) + eps\n",
        "        denominator = tf.reduce_sum(y_true + y_pred, axis = (0,1,2)) + eps\n",
        "        return (numerator / denominator)\n",
        "    \n",
        "    @staticmethod\n",
        "    def gen_dice(y_true, y_pred):\n",
        "        '''\n",
        "        both tensors are [b, h, w, classes] and y_pred is in logit form\n",
        "        '''\n",
        "        eps=1e-7\n",
        "\n",
        "        # [b, h, w, classes]\n",
        "        pred_tensor = tf.nn.softmax(y_pred)\n",
        "        y_true_shape = tf.shape(y_true)\n",
        "\n",
        "        # [b, h*w, classes]\n",
        "        y_true = tf.reshape(y_true, [-1, y_true_shape[0]*y_true_shape[1], y_true_shape[2]])\n",
        "        y_pred = tf.reshape(pred_tensor, [-1, y_true_shape[0]*y_true_shape[1], y_true_shape[2]])\n",
        "\n",
        "        # [b, classes]\n",
        "        # count how many of each class are present in \n",
        "        # each image, if there are zero, then assign\n",
        "        # them a fixed weight of eps\n",
        "        counts = tf.reduce_sum(y_true, axis=0)\n",
        "        weights = 1. / (counts ** 2)\n",
        "        weights = tf.where(tf.math.is_finite(weights), weights, eps)\n",
        "\n",
        "        multed = tf.reduce_sum(y_true * y_pred, axis=0)\n",
        "        summed = tf.reduce_sum(y_true + y_pred, axis=0)\n",
        "\n",
        "        # [b]\n",
        "        numerators = tf.reduce_sum(weights*multed, axis=-1)\n",
        "        denom = tf.reduce_sum(weights*summed, axis=-1)\n",
        "        dices = 1. - 2. * numerators / denom\n",
        "        dices = tf.where(tf.math.is_finite(dices), dices, tf.zeros_like(dices))\n",
        "        return tf.reduce_mean(dices)\n",
        "\n",
        "\n",
        "    # Ref: salehi17, \"Twersky loss function for image segmentation using 3D FCDN\"\n",
        "    # -> the score is computed for each class separately and then summed\n",
        "    # alpha=beta=0.5 : dice coefficient\n",
        "    # alpha=beta=1   : tanimoto coefficient (also known as jaccard)\n",
        "    # alpha+beta=1   : produces set of F*-scores\n",
        "    # implemented by E. Moebel, 06/04/18\n",
        "    @staticmethod\n",
        "    def tversky_loss(y_true, y_pred):\n",
        "        name_of_class = y_true.__class__.__name__\n",
        "        print(name_of_class)\n",
        "        if not (\"Tensor\" in name_of_class):\n",
        "            y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
        "            y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
        "\n",
        "        alpha = 0.5\n",
        "        beta  = 0.5\n",
        "        \n",
        "        ones = tf.keras.backend.ones(tf.keras.backend.shape(y_true))\n",
        "        p0 = y_pred      # proba that voxels are class i\n",
        "        p1 = ones-y_pred # proba that voxels are not class i\n",
        "        g0 = y_true\n",
        "        g1 = ones-y_true\n",
        "        \n",
        "        num = tf.keras.backend.sum(p0*g0, (0,1,2))\n",
        "        den = num + alpha*tf.keras.backend.sum(p0*g1,(0,1,2)) + beta*tf.keras.backend.sum(p1*g0,(0,1,2))\n",
        "        T = tf.keras.backend.sum(num/den) # when summing over classes, T has dynamic range [0 Ncl]\n",
        "        \n",
        "        Ncl = tf.keras.backend.cast(tf.keras.backend.shape(y_true)[-1], 'float32')\n",
        "        return Ncl-T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjV9lefUEf-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "https://github.com/tensorflow/tensorflow/issues/32875 \n",
        "'''\n",
        "class MyMeanIoU(tf.keras.metrics.MeanIoU):\n",
        "    '''\n",
        "    Attempt to use built-in MeanIoU, but seeting the weight of the VOID class to 0\n",
        "    '''\n",
        "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
        "        # y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        weights_ = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0])\n",
        "        return super().__call__(y_true, y_pred, sample_weight=weights_)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOyRH_Qdguvt",
        "colab_type": "text"
      },
      "source": [
        "Additional Loss function\n",
        "Attempt to have a loss weighted per class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSF_TtERgtxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CategoricalCrossentropyWeightedPerClass(tf.keras.losses.CategoricalCrossentropy):\n",
        "    def __init__(self, weights):\n",
        "        super(CategoricalCrossentropyWeightedPerClass, self).__init__()\n",
        "        self._weights = weights # tf.convert_to_tensor(np.array([BS, 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0]))\n",
        "    \n",
        "    def __call__(self, y_true, y_pred, sample_weight):\n",
        "        # tf.print(y_true)\n",
        "        # tf.print(\"y_true shape = \" + str(y_true.shape))\n",
        "        # tf.print(\"y_pred shape = \" + str(y_pred.shape))\n",
        "\n",
        "        return super().__call__(y_true, y_pred, sample_weight = self._weights)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQLxHfr3NmkR",
        "colab_type": "text"
      },
      "source": [
        "####Computing (inverse) weight of class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drm_H2CkXxfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "class weights\n",
        "'''\n",
        "# totalPixels = 0\n",
        "# counts = np.zeros((21,))\n",
        "# generator = training_set_seg_tf_generator\n",
        "# batches_per_epoch = len(df_seg_train_to_generate) // BS\n",
        "\n",
        "# for i in range(batches_per_epoch):\n",
        "#     x, y = next(iter(generator))\n",
        "#     # plot_matrix(x)\n",
        "#     shp = y.shape\n",
        "#     totalPixels += shp[0] * shp[1] * shp[2] \n",
        "#     counts = counts + np.sum(y, axis=(0,1,2))\n",
        "\n",
        "# print(\"total number of pixels: \" + str(totalPixels))\n",
        "# print(\"counts: \" + str(counts))\n",
        "\n",
        "# weights = totalPixels / (counts + 1e-8)\n",
        "# print(\"weights before normalization: \" + str(weights))\n",
        "\n",
        "# weights = weights / np.sum(weights)\n",
        "# print(\"weights after normalization: \" + str(weights))\n",
        "\n",
        "\n",
        "weights_before_normalization = np.array([  1.37158705, 125.5154789,  346.32864165,  97.87471169, 188.29581472,\n",
        " 129.08625047,  63.33267949,  66.69344206,  78.27472078, 117.4650739,\n",
        " 175.19801069,  76.89171447, 216.99631816, 134.38962242,  70.32948383,\n",
        "  25.88651142, 154.05779723, 123.93974291, 125.51081184,  83.77931862,\n",
        "  95.39310543])\n",
        "weights_after_normalization = np.array([0.00054938, 0.05027435, 0.13871951, 0.03920303, 0.07542057, 0.05170459,\n",
        " 0.02536746, 0.02671359, 0.03135239, 0.04704981, 0.07017434, 0.03079844,\n",
        " 0.08691636, 0.05382882, 0.02816998, 0.01036866, 0.06170677, 0.0496432,\n",
        " 0.05027248, 0.03355722, 0.03820904])\n",
        "weights = weights_after_normalization.reshape((1,1,1,21))\n",
        "kWeights = tf.keras.backend.constant(weights)\n",
        "\n",
        "'''\n",
        "Attempt of weighted categorical cross entropy\n",
        "'''\n",
        "def weighted_cce(y_true, y_pred):\n",
        "    yWeights = kWeights * y_pred         #shape (batch, 128, 128, 4)\n",
        "    yWeights = tf.keras.backend.sum(yWeights, axis=-1)  #shape (batch, 128, 128)  \n",
        "\n",
        "    yWeights = yWeights / tf.keras.backend.sum(yWeights)\n",
        "\n",
        "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred) #shape (batch, 128, 128)\n",
        "    wLoss = yWeights * loss\n",
        "\n",
        "    return tf.keras.backend.sum(wLoss, axis=(1,2))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mftXU19inBem",
        "colab_type": "text"
      },
      "source": [
        "####Toy Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhv1CSHkOv4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "toy example\n",
        "3 1 1 3\n",
        "1 2 2 1\n",
        "1 2 2 1\n",
        "3 1 1 3 \n",
        "'''\n",
        "channel1 = np.array([[0,1,1,0],[1,0,0,1],[1,0,0,1],[0,1,1,0]], dtype = np.float32)\n",
        "channel1pred = np.array([[0.2,0.6,0.6,0.2],[0.6,0.2,0.2,0.6],[0.6,0.2,0.2,0.6],[0.2,0.6,0.6,0.2]], dtype = np.float32)\n",
        "\n",
        "channel2 = np.array([[0,0,0,0],[0,1,1,0],[0,1,1,0],[0,0,0,0]], dtype = np.float32)\n",
        "channel2pred = np.array([[0.2,0.2,0.2,0.2],[0.2,0.6,0.6,0.2],[0.2,0.6,0.6,0.2],[0.2,0.2,0.2,0.2]], dtype = np.float32)\n",
        "\n",
        "channel3 = np.array([[1,0,0,1],[0,0,0,0],[0,0,0,0],[1,0,0,1]], dtype = np.float32)\n",
        "channel3pred = np.array([[0.6,0.2,0.2,0.6],[0.2,0.2,0.2,0.2],[0.2,0.2,0.2,0.2],[0.6,0.2,0.2,0.6]], dtype = np.float32)\n",
        "t_ = np.stack([channel1[0:2,0:2], channel2[0:2,0:2], channel3[0:2,0:2]], axis = -1)\n",
        "pred_ = np.stack([channel1pred[0:2,0:2], channel2pred[0:2,0:2], channel3pred[0:2,0:2]], axis = -1)\n",
        "mask_input = t_.copy()\n",
        "# print(\"Mask input shape\", mask_input.shape)\n",
        " \n",
        "mask_pred1 = mask_input.copy()\n",
        "# print(\"mask_pred1 shape\", mask_pred1.shape)\n",
        "print(\"Keras binary cross entropy (same input): \", tf.keras.losses.binary_crossentropy(mask_input, mask_pred1))\n",
        "mask_pred2 = pred_.copy()\n",
        "print(\"Keras binary cross entropy (pred):\\n\", tf.keras.losses.binary_crossentropy(mask_input, mask_pred2))\n",
        "print(tf.keras.backend.sum(tf.keras.losses.binary_crossentropy(mask_input, mask_pred2)))\n",
        "print(\"Keras categorical cross entropy (pred):\\n \", tf.keras.losses.categorical_crossentropy(mask_input, mask_pred2))\n",
        "print(tf.keras.backend.sum(tf.keras.losses.categorical_crossentropy(mask_input, mask_pred2)))\n",
        "\n",
        "print(\"MyScore Dice loss(same input):\\n\", MyScore.dice_loss(mask_input, mask_pred1))\n",
        "print(\"MyScore Dice loss(pred):\\n\", MyScore.dice_loss(mask_input, mask_pred2))\n",
        "print(\"MyScore Gen Dice (same input):\\n\", MyScore.gen_dice(mask_input, mask_pred1))\n",
        "print(\"MyScore Gen Dice (pred):\\n\", MyScore.gen_dice(mask_input, mask_pred2))\n",
        "\n",
        "# print(\"MyScore tversky_loss:\\n\", MyScore.tversky_loss(mask_input, mask_pred2))\n",
        "\n",
        "\n",
        "# cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "# loss = cce(mask_input,mask_pred2)\n",
        "# print('CCE Loss: ', loss.numpy())  # Loss: 0.5108256\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql9k6RckfFST",
        "colab_type": "text"
      },
      "source": [
        "##Additional Callbacks\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kn3FxAdh0Pg",
        "colab_type": "text"
      },
      "source": [
        "Function to see prediction (can be used in other context than callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kLlZwUfKifz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_predictions(model, dataset=None):\n",
        "    '''\n",
        "    Used the model given to predict the segmentation of the image taken from the dataset given, if any. \n",
        "    Else, the image is taken from the validation set (using tf.Data API generators created)\n",
        "\n",
        "    It uses the display function to plot [ original | target_mask | predicted_mask ]\n",
        "    '''\n",
        "    if not(dataset is None):\n",
        "        # print(next(iter(dataset)))\n",
        "        image_batch, mask_batch = next(iter(dataset))\n",
        "        image=image_batch[0]\n",
        "        mask = color_seg(np.array(tf.argmax(mask_batch[0], axis = -1)),np.array(colormap))\n",
        "        pred_mask = model.predict(image[tf.newaxis, ...])\n",
        "        display([image, mask, create_mask(pred_mask)])\n",
        "    else:\n",
        "        image_train_batch, mask_train_batch = next(iter(val_set_seg_tf_generator))\n",
        "        sample_image = image_train_batch[0]\n",
        "        # print(mask_train_batch[0].shape)\n",
        "        sample_mask = color_seg(np.array(tf.argmax(mask_train_batch[0], axis = -1)),np.array(colormap))\n",
        "        pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
        "        display([sample_image, sample_mask, create_mask(pred_mask)])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I3RS12VNAYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, model_t):\n",
        "        super(DisplayCallback, self).__init__()\n",
        "        self.model_t = model_t\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # clear_output(wait=True)\n",
        "        show_predictions(model = self.model_t)\n",
        "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VznV1wXuU9aq",
        "colab_type": "text"
      },
      "source": [
        "##Segmentation using TL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-trioTVmT1ge",
        "colab_type": "text"
      },
      "source": [
        "#####Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DWQ4ZdYT7s4",
        "colab_type": "text"
      },
      "source": [
        "First, get the base model, and select a few layers\n",
        "-> they will be used for skip connections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agy1dF-iA5Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Get Backbone - MobileNetv2\n",
        "'''\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[sq_size, sq_size, 3], include_top=False)\n",
        "\n",
        "'''\n",
        "Create the encoding part model thanks to MobileNetv2\n",
        "'''\n",
        "\n",
        "\n",
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "layers_list = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "'''\n",
        "create a model based on those activations, and make in Not Trainable\n",
        "'''\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers_list)\n",
        "\n",
        "'''\n",
        "make it not trainable!\n",
        "'''\n",
        "down_stack.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1fgW-JLUSzl",
        "colab_type": "text"
      },
      "source": [
        "#####Upsampling part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Gc5CjpVR2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Helper function from \n",
        "https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py \n",
        "'''\n",
        "\n",
        "def upsample(filters, size, norm_type='batchnorm', apply_dropout=False):\n",
        "  \"\"\"Upsamples an input.\n",
        "  Conv2DTranspose => Batchnorm => Dropout => Relu\n",
        "  Args:\n",
        "    filters: number of filters\n",
        "    size: filter size\n",
        "    norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
        "    apply_dropout: If True, adds the dropout layer\n",
        "  Returns:\n",
        "    Upsample Sequential Model\n",
        "  \"\"\"\n",
        "\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                      padding='same',\n",
        "                                      kernel_initializer=initializer,\n",
        "                                      use_bias=False))\n",
        "\n",
        "  if norm_type.lower() == 'batchnorm':\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "  elif norm_type.lower() == 'instancenorm':\n",
        "    result.add(InstanceNormalization())\n",
        "\n",
        "  if apply_dropout:\n",
        "    result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3JVa3OyVh5e",
        "colab_type": "text"
      },
      "source": [
        "establishing the upsampling stack (no skip at this point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-GfBpsaBPW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Defining the layers for the decoding part (upsampling)\n",
        "'''\n",
        "up_stack = [\n",
        "            upsample(512, 3),  # 4x4 -> 8x8\n",
        "            upsample(256, 3),  # 8x8 -> 16x16\n",
        "            upsample(128, 3),  # 16x16 -> 32x32\n",
        "            upsample(64, 3),   # 32x32 -> 64x64\n",
        "            ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmKl2AoGVo3f",
        "colab_type": "text"
      },
      "source": [
        "####U-Net\n",
        "(using skip connections)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpK4uAvPVnVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Definition of U-Net model, with skip connections\n",
        "'''\n",
        "def unet_model(output_channels):\n",
        "    inputs = tf.keras.layers.Input(shape=[sq_size, sq_size, 3])\n",
        "    x = inputs\n",
        "\n",
        "    # Downsampling through the model\n",
        "    skips = down_stack(x)\n",
        "    x = skips[-1]\n",
        "\n",
        "    # create a generator of the layers in skips ==> in downstack, in the reverse order, until last-but-one\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        concat = tf.keras.layers.Concatenate()\n",
        "        x = concat([x, skip])\n",
        "\n",
        "    # This is the last layer of the model\n",
        "    last = tf.keras.layers.Conv2DTranspose(\n",
        "        output_channels, 3, strides=2,\n",
        "        padding='same',\n",
        "        activation=\"softmax\")  #64x64 -> 128x128\n",
        "\n",
        "    x = last(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "    # model.trainable = False\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anTWeJN8qFcc",
        "colab_type": "text"
      },
      "source": [
        "####Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnY2rXWMAnT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Build the model\n",
        "'''\n",
        "model_seg_tl = unet_model(OUTPUT_CHANNELS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxM1qV-ZLic2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Compilation \n",
        "'''\n",
        "\n",
        "# meanIoU = tf.keras.metrics.MeanIoU(num_classes = 22)\n",
        "# my_meanIoU = MyMeanIoU(num_classes = 22)\n",
        "model_seg_tl.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss= tf.keras.losses.categorical_crossentropy,#MyScore.dice_loss, \n",
        "              metrics= [MyScore.iou_coef, MyScore.dice_score] ) #MyScore.dice_score\n",
        "\n",
        "'''\n",
        "Plot the model\n",
        "'''\n",
        "tf.keras.utils.plot_model(model_seg_tl, show_shapes=True)\n",
        "model_seg_tl.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHjgHVPHiuLV",
        "colab_type": "text"
      },
      "source": [
        "We know have the U-Net model (with skip connections).\n",
        "We can plot a prediction on a image from the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPtceNmhHDJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Using show_predictions BEFORE training\n",
        "'''\n",
        "show_predictions(model_seg_tl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ClHpFqCLHIM",
        "colab_type": "text"
      },
      "source": [
        "####Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cTCmtghNFtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EPOCHS = 100\n",
        "if train_seg_model_tl:\n",
        "    history_model_seg_tl = model_seg_tl.fit(training_set_seg_tf_generator, \n",
        "                            epochs=EPOCHS,\n",
        "                            steps_per_epoch= len(df_seg_train_to_generate)//BS, #STEPS_PER_EPOCH,\n",
        "                            validation_steps= len(df_seg_val_to_generate)//BS, #VALIDATION_STEPS,\n",
        "                            validation_data=val_set_seg_tf_generator,\n",
        "                            callbacks=[my_callbacks] #DisplayCallback(model_seg_tl), \n",
        "                            )\n",
        "    model_seg_tl.save_weights(model_seg_tl_save_filename)\n",
        "    histories['model_seg_tl'] = history_model_seg_tl.history\n",
        "    pickle.dump(histories[\"model_seg_tl\"], open(model_seg_tl_hist_save_filename, 'wb'))\n",
        "else:\n",
        "    model_seg_tl.load_weights(model_seg_tl_save_filename)\n",
        "    histories['model_seg_tl'] = pickle.load(open(model_seg_tl_hist_save_filename, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU6wh9tDNjVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    fig, axes = plt.subplots(2,1,figsize=(8,8))\n",
        "    axes[0].plot(histories[\"model_seg_tl\"]['iou_coef'], label='IoU')\n",
        "    axes[0].plot(histories[\"model_seg_tl\"]['val_iou_coef'], label = 'val_IoU')\n",
        "    axes[0].plot(histories[\"model_seg_tl\"]['dice_score'], label='Dice')\n",
        "    axes[0].plot(histories[\"model_seg_tl\"]['val_dice_score'], label = 'val_Dice')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Metric')\n",
        "    axes[0].set_ylim([0.0, 1])\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[1].plot(histories[\"model_seg_tl\"]['loss'], label='loss')\n",
        "    axes[1].plot(histories[\"model_seg_tl\"]['val_loss'], label = 'val_loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Categorical Cross-entropy')\n",
        "    # axes[1].set_ylim([0.0, 1])\n",
        "    axes[1].legend(loc='upper right')\n",
        "    fig.suptitle('Model Sementation TL')\n",
        "except:\n",
        "    print(\"There was an error during the plot\")\n",
        "finally:\n",
        "    scores = model_seg_tl.evaluate(val_set_seg_tf_generator, steps=2*len(df_seg_train_to_generate[\"stem_filename\"])//BS )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ2GmM-9t3jc",
        "colab_type": "text"
      },
      "source": [
        "####Results\n",
        "Example of results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR34VtNvNODC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# next(iter(val_set_seg_tf_generator))\n",
        "'''\n",
        "using show_predictions\n",
        "'''\n",
        "print(\"Using show_predictions:\")\n",
        "show_predictions(model = model_seg_tl, dataset = val_set_seg_tf_generator)\n",
        "\n",
        "\n",
        "print(\"Manually:\")\n",
        "image_train_batch, mask_train_batch = next(iter(val_set_seg_tf_generator))\n",
        "sample_image = image_train_batch[3]\n",
        "sample_mask = color_seg(np.array(tf.argmax(mask_train_batch[3], axis = -1)),np.array(colormap[0:21]))\n",
        "pred_mask = model_seg_tl.predict(sample_image[tf.newaxis, ...])\n",
        "display([sample_image, sample_mask, create_mask(pred_mask)])\n",
        "\n",
        "\n",
        "\n",
        "# print(len(pred_mask[0,...]))\n",
        "# first_layer = pred_mask[0,...]\n",
        "# print(first_layer.shape)\n",
        "# print(np.round(first_layer[50:60, 50:60, 0],1))\n",
        "# print(np.round(first_layer[50:60, 50:60, 3],1))\n",
        "# print(np.round(first_layer[64,64,0:22],1))\n",
        "\n",
        "\n",
        "# print(len(np.where(np.round(pred_mask[0,:,:,0]) == 1)))\n",
        "# print(len(np.where(np.round(pred_mask[0,:,:,1]) == 1)))\n",
        "# print(len(np.where(np.round(pred_mask[0,:,:,2]) == 1)))\n",
        "# print(len(np.where(np.round(pred_mask[0,:,:,3]) == 1)))\n",
        "# print(len(np.where(np.round(pred_mask[0,:,:,4]) == 1)))\n",
        "# print(len(np.where(np.round(pred_mask[0,:,:,5]) == 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPJ28GLaupIh",
        "colab_type": "text"
      },
      "source": [
        "####Sandbox metrics and losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4YL0cAOUmwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_train_batch, mask_train_batch = next(iter(val_set_seg_tf_generator))\n",
        "# sample_image = image_train_batch[5]\n",
        "# # print(mask_train_batch[0].shape)\n",
        "# sample_mask = color_seg(np.array(tf.argmax(mask_train_batch[5], axis = -1)),np.array(colormap))\n",
        "# pred_mask = model_seg_tl.predict(sample_image[tf.newaxis, ...])\n",
        "# display([sample_image, sample_mask, create_mask(pred_mask)])\n",
        "# print(tf.shape(mask_train_batch[5]))\n",
        "# metric_0 = tf.reduce_mean(tf.keras.metrics.categorical_crossentropy(mask_train_batch[5][tf.newaxis, ...], pred_mask))\n",
        "# print(metric_0)\n",
        "# loss_0 = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(mask_train_batch[5][tf.newaxis, ...], pred_mask))\n",
        "# print(loss_0)\n",
        "\n",
        "# metric_1 = tf.reduce_mean(MyScore.dice_score(mask_train_batch[5][tf.newaxis, ...], pred_mask))\n",
        "# print(metric_1)\n",
        "# metric_2 = Trial.dice_coe(mask_train_batch[5][tf.newaxis, ...], pred_mask)\n",
        "# print(metric_2)\n",
        "# metric_3 = Trial.dice_hard_coe(mask_train_batch[5][tf.newaxis, ...], pred_mask)\n",
        "# print(metric_3)\n",
        "\n",
        "# reference_mask = mask_train_batch[5][tf.newaxis, ...]\n",
        "# predicted_mask = reference_mask\n",
        "# metric_1 = tf.reduce_mean(MyScore.dice_score(reference_mask, predicted_mask))\n",
        "# print(metric_1)\n",
        "# metric_2 = Trial.dice_coe(reference_mask, predicted_mask)\n",
        "# print(metric_2)\n",
        "# metric_3 = Trial.dice_hard_coe(reference_mask, predicted_mask)\n",
        "# print(metric_3)\n",
        "# '''\n",
        "# BUG\n",
        "# '''\n",
        "# # reference_mask = tf.convert_to_tensor(mask_input)\n",
        "# # predicted_mask = tf.convert_to_tensor(mask_pred1)\n",
        "# # metric_1 = tf.reduce_mean(MyScore.dice_score(reference_mask, predicted_mask))\n",
        "# # print(metric_1)\n",
        "# # metric_2 = Trial.dice_coe(reference_mask, predicted_mask)\n",
        "# # print(metric_2)\n",
        "# # metric_3 = Trial.dice_hard_coe(reference_mask, predicted_mask)\n",
        "# # print(metric_3)\n",
        "\n",
        "\n",
        "# # reference_mask = tf.convert_to_tensor(mask_input)\n",
        "# # predicted_mask = tf.convert_to_tensor(mask_pred2)\n",
        "# # metric_1 = tf.reduce_mean(MyScore.dice_score(reference_mask, predicted_mask))\n",
        "# # print(metric_1)\n",
        "# # metric_2 = Trial.dice_coe(reference_mask, predicted_mask)\n",
        "# # print(metric_2)\n",
        "# # metric_3 = Trial.dice_hard_coe(reference_mask, predicted_mask)\n",
        "# # print(metric_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh4D8po2o4ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.python.framework import ops\n",
        "# from tensorflow.python.ops import array_ops, math_ops, nn_ops, standard_ops\n",
        "\n",
        "# # from tensorlayer import logging\n",
        "\n",
        "# class Trial():\n",
        "\n",
        "#     @staticmethod\n",
        "#     def cross_entropy(output, target, name=None):\n",
        "#         \"\"\"\n",
        "#         Softmax cross-entropy operation, returns the TensorFlow expression of cross-entropy for two distributions,\n",
        "#         it implements softmax internally. See ``tf.nn.sparse_softmax_cross_entropy_with_logits``.\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         output : Tensor\n",
        "#             A batch of distribution with shape: [batch_size, num of classes].\n",
        "#         target : Tensor\n",
        "#             A batch of index with shape: [batch_size, ].\n",
        "#         name : string\n",
        "#             Name of this loss.\n",
        "\n",
        "#         Examples\n",
        "#         --------\n",
        "#         >>> import tensorlayer as tl\n",
        "#         >>> ce = tl.cost.cross_entropy(y_logits, y_target_logits, 'my_loss')    \n",
        "#         References\n",
        "#         -----------\n",
        "#         - About cross-entropy: `<https://en.wikipedia.org/wiki/Cross_entropy>`__.\n",
        "#         - The code is borrowed from: `<https://en.wikipedia.org/wiki/Cross_entropy>`__.\n",
        "#         \"\"\"\n",
        "#         return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=target, logits=output), name=name)\n",
        "\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def sigmoid_cross_entropy(output, target, name=None):\n",
        "#         \"\"\"Sigmoid cross-entropy operation, see ``tf.nn.sigmoid_cross_entropy_with_logits``.\n",
        "\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         output : Tensor\n",
        "#             A batch of distribution with shape: [batch_size, num of classes].\n",
        "#         target : Tensor\n",
        "#             A batch of index with shape: [batch_size, ].\n",
        "#         name : string\n",
        "#             Name of this loss.\n",
        "\n",
        "#         \"\"\"\n",
        "#         return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output), name=name)\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def binary_cross_entropy(output, target, epsilon=1e-8, name='bce_loss'):\n",
        "#         \"\"\"Binary cross entropy operation.\n",
        "\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         output : Tensor\n",
        "#             Tensor with type of `float32` or `float64`.\n",
        "#         target : Tensor\n",
        "#             The target distribution, format the same with `output`.\n",
        "#         epsilon : float\n",
        "#             A small value to avoid output to be zero.\n",
        "#         name : str\n",
        "#             An optional name to attach to this function.\n",
        "\n",
        "#         References\n",
        "#         -----------\n",
        "#         - `ericjang-DRAW <https://github.com/ericjang/draw/blob/master/draw.py#L73>`__\n",
        "\n",
        "#         \"\"\"\n",
        "#         #     with ops.op_scope([output, target], name, \"bce_loss\") as name:\n",
        "#         #         output = ops.convert_to_tensor(output, name=\"preds\")\n",
        "#         #         target = ops.convert_to_tensor(targets, name=\"target\")\n",
        "\n",
        "#         # with tf.name_scope(name):\n",
        "#         return tf.reduce_mean(\n",
        "#             tf.reduce_sum(\n",
        "#                 -(target * tf.math.log(output + epsilon) + (1. - target) * tf.math.log(1. - output + epsilon)), axis=1\n",
        "#             ), name=name\n",
        "#         )\n",
        "\n",
        "\n",
        "#     # For brevity, let `x = output`, `z = target`.  The binary cross entropy loss is\n",
        "#     #\n",
        "#     #     loss(x, z) = - sum_i (x[i] * log(z[i]) + (1 - x[i]) * log(1 - z[i]))\n",
        "\n",
        "#     @staticmethod\n",
        "#     def mean_squared_error(output, target, is_mean=False, axis=-1, name=\"mean_squared_error\"):\n",
        "#         \"\"\"Return the TensorFlow expression of mean-square-error (L2) of two batch of data.\n",
        "\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         output : Tensor\n",
        "#             2D, 3D or 4D tensor i.e. [batch_size, n_feature], [batch_size, height, width] or [batch_size, height, width, channel].\n",
        "#         target : Tensor\n",
        "#             The target distribution, format the same with `output`.\n",
        "#         is_mean : boolean\n",
        "#             Whether compute the mean or sum for each example.\n",
        "#                 - If True, use ``tf.reduce_mean`` to compute the loss between one target and predict data.\n",
        "#                 - If False, use ``tf.reduce_sum`` (default).\n",
        "#         axis : int or list of int\n",
        "#             The dimensions to reduce.\n",
        "#         name : str\n",
        "#             An optional name to attach to this function.\n",
        "\n",
        "#         References\n",
        "#         ------------\n",
        "#         - `Wiki Mean Squared Error <https://en.wikipedia.org/wiki/Mean_squared_error>`__\n",
        "\n",
        "#         \"\"\"\n",
        "#         # with tf.name_scope(name):\n",
        "#         # if len(output.shape) == 2:  # [batch_size, n_feature]\n",
        "#         #     axis = 1\n",
        "#         # elif len(output.shape) == 3:  # [batch_size, w, h]\n",
        "#         #     axis = [1, 2]\n",
        "#         # elif len(output.shape) == 4:  # [batch_size, w, h, c]\n",
        "#         #     axis = [1, 2, 3]\n",
        "#         # else:\n",
        "#         #     raise Exception(\"Unknow dimension\")\n",
        "\n",
        "#         if is_mean:\n",
        "#             mse = tf.reduce_mean(tf.reduce_mean(tf.math.squared_difference(output, target), axis), name=name)\n",
        "#         else:\n",
        "#             mse = tf.reduce_mean(tf.reduce_sum(tf.math.squared_difference(output, target), axis), name=name)\n",
        "#         return mse\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def normalized_mean_square_error(output, target, axis=-1, name=\"normalized_mean_squared_error_loss\"):\n",
        "#         \"\"\"Return the TensorFlow expression of normalized mean-square-error of two distributions.\n",
        "\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         output : Tensor\n",
        "#             2D, 3D or 4D tensor i.e. [batch_size, n_feature], [batch_size, height, width] or [batch_size, height, width, channel].\n",
        "#         target : Tensor\n",
        "#             The target distribution, format the same with `output`.\n",
        "#         axis : int or list of int\n",
        "#             The dimensions to reduce.\n",
        "#         name : str\n",
        "#             An optional name to attach to this function.\n",
        "\n",
        "#         \"\"\"\n",
        "#         with tf.name_scope(\"normalized_mean_squared_error_loss\"):\n",
        "#             # if len(output.shape) == 2:  # [batch_size, n_feature]\n",
        "#             #     axis = 1\n",
        "#             # elif len(output.shape) == 3:  # [batch_size, w, h]\n",
        "#             #     axis = [1, 2]\n",
        "#             # elif len(output.shape) == 4:  # [batch_size, w, h, c]\n",
        "#             #     axis = [1, 2, 3]\n",
        "#             nmse_a = tf.sqrt(tf.reduce_sum(tf.math.squared_difference(output, target), axis=axis))\n",
        "#             nmse_b = tf.sqrt(tf.reduce_sum(tf.square(target), axis=axis))\n",
        "#             nmse = tf.reduce_mean(nmse_a / nmse_b, name=name)\n",
        "#         return nmse\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def absolute_difference_error(output, target, is_mean=False, axis=-1, name=\"absolute_difference_error_loss\"):\n",
        "#         \"\"\"Return the TensorFlow expression of absolute difference error (L1) of two batch of data.\n",
        "\n",
        "#         Parameters\n",
        "#         ----------\n",
        "#         output : Tensor\n",
        "#             2D, 3D or 4D tensor i.e. [batch_size, n_feature], [batch_size, height, width] or [batch_size, height, width, channel].\n",
        "#         target : Tensor\n",
        "#             The target distribution, format the same with `output`.\n",
        "#         is_mean : boolean\n",
        "#             Whether compute the mean or sum for each example.\n",
        "#                 - If True, use ``tf.reduce_mean`` to compute the loss between one target and predict data.\n",
        "#                 - If False, use ``tf.reduce_sum`` (default).\n",
        "#         axis : int or list of int\n",
        "#             The dimensions to reduce.\n",
        "#         name : str\n",
        "#             An optional name to attach to this function.\n",
        "\n",
        "#         \"\"\"\n",
        "#         # # with tf.name_scope(\"absolute_difference_error_loss\"):\n",
        "#         # if len(output.shape) == 2:  # [batch_size, n_feature]\n",
        "#         #     axis = 1\n",
        "#         # elif len(output.shape) == 3:  # [batch_size, w, h]\n",
        "#         #     axis = [1, 2]\n",
        "#         # elif len(output.shape) == 4:  # [batch_size, w, h, c]\n",
        "#         #     axis = [1, 2, 3]\n",
        "#         # else:\n",
        "#         #     raise Exception(\"Unknow dimension\")\n",
        "#         if is_mean:\n",
        "#             loss = tf.reduce_mean(tf.reduce_mean(tf.abs(output - target), axis), name=name)\n",
        "#         else:\n",
        "#             loss = tf.reduce_mean(tf.reduce_sum(tf.abs(output - target), axis), name=name)\n",
        "#         return loss\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def dice_coe(output, target, loss_type='jaccard', axis=(1, 2, 3), smooth=1e-5):\n",
        "#         \"\"\"Soft dice (Sørensen or Jaccard) coefficient for comparing the similarity\n",
        "#         of two batch of data, usually be used for binary image segmentation\n",
        "#         i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n",
        "\n",
        "#         Parameters\n",
        "#         -----------\n",
        "#         output : Tensor\n",
        "#             A distribution with shape: [batch_size, ....], (any dimensions).\n",
        "#         target : Tensor\n",
        "#             The target distribution, format the same with `output`.\n",
        "#         loss_type : str\n",
        "#             ``jaccard`` or ``sorensen``, default is ``jaccard``.\n",
        "#         axis : tuple of int\n",
        "#             All dimensions are reduced, default ``[1,2,3]``.\n",
        "#         smooth : float\n",
        "#             This small value will be added to the numerator and denominator.\n",
        "#                 - If both output and target are empty, it makes sure dice is 1.\n",
        "#                 - If either output or target are empty (all pixels are background), dice = ```smooth/(small_value + smooth)``, then if smooth is very small, dice close to 0 (even the image values lower than the threshold), so in this case, higher smooth can have a higher dice.\n",
        "\n",
        "#         Examples\n",
        "#         ---------\n",
        "#         >>> import tensorlayer as tl\n",
        "#         >>> outputs = tl.act.pixel_wise_softmax(outputs)\n",
        "#         >>> dice_loss = 1 - tl.cost.dice_coe(outputs, y_)\n",
        "\n",
        "#         References\n",
        "#         -----------\n",
        "#         - `Wiki-Dice <https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient>`__\n",
        "\n",
        "#         \"\"\"\n",
        "#         name_of_class = target.__class__.__name__\n",
        "#         if not (\"Tensor\" in name_of_class):\n",
        "#             target = tf.convert_to_tensor(target, dtype=tf.float32)\n",
        "#             output = tf.convert_to_tensor(output, dtype=tf.float32)\n",
        "\n",
        "\n",
        "#         inse = tf.reduce_sum(output * target, axis=axis)\n",
        "#         if loss_type == 'jaccard':\n",
        "#             l = tf.reduce_sum(output * output, axis=axis)\n",
        "#             r = tf.reduce_sum(target * target, axis=axis)\n",
        "#         elif loss_type == 'sorensen':\n",
        "#             l = tf.reduce_sum(output, axis=axis)\n",
        "#             r = tf.reduce_sum(target, axis=axis)\n",
        "#         else:\n",
        "#             raise Exception(\"Unknow loss_type\")\n",
        "#         # old axis=[0,1,2,3]\n",
        "#         # dice = 2 * (inse) / (l + r)\n",
        "#         # epsilon = 1e-5\n",
        "#         # dice = tf.clip_by_value(dice, 0, 1.0-epsilon) # if all empty, dice = 1\n",
        "#         # new haodong\n",
        "#         dice = (2. * inse + smooth) / (l + r + smooth)\n",
        "#         ##\n",
        "#         dice = tf.reduce_mean(dice, name='dice_coe')\n",
        "#         return dice\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def dice_hard_coe(output, target, threshold=0.5, axis=(1, 2, 3), smooth=1e-5):\n",
        "#         \"\"\"Non-differentiable Sørensen–Dice coefficient for comparing the similarity\n",
        "#         of two batch of data, usually be used for binary image segmentation i.e. labels are binary.\n",
        "#         The coefficient between 0 to 1, 1 if totally match.\n",
        "\n",
        "#         Parameters\n",
        "#         -----------\n",
        "#         output : tensor\n",
        "#             A distribution with shape: [batch_size, ....], (any dimensions).\n",
        "#         target : tensor\n",
        "#             The target distribution, format the same with `output`.\n",
        "#         threshold : float\n",
        "#             The threshold value to be true.\n",
        "#         axis : tuple of integer\n",
        "#             All dimensions are reduced, default ``(1,2,3)``.\n",
        "#         smooth : float\n",
        "#             This small value will be added to the numerator and denominator, see ``dice_coe``.\n",
        "\n",
        "#         References\n",
        "#         -----------\n",
        "#         - `Wiki-Dice <https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient>`__\n",
        "\n",
        "#         \"\"\"\n",
        "#         name_of_class = target.__class__.__name__\n",
        "#         if not (\"Tensor\" in name_of_class):\n",
        "#             target = tf.convert_to_tensor(target, dtype=tf.float32)\n",
        "#             output = tf.convert_to_tensor(output, dtype=tf.float32)\n",
        "            \n",
        "#         output = tf.cast(output > threshold, dtype=tf.float32)\n",
        "#         target = tf.cast(target > threshold, dtype=tf.float32)\n",
        "#         inse = tf.reduce_sum(tf.multiply(output, target), axis=axis)\n",
        "#         l = tf.reduce_sum(output, axis=axis)\n",
        "#         r = tf.reduce_sum(target, axis=axis)\n",
        "#         # old axis=[0,1,2,3]\n",
        "#         # hard_dice = 2 * (inse) / (l + r)\n",
        "#         # epsilon = 1e-5\n",
        "#         # hard_dice = tf.clip_by_value(hard_dice, 0, 1.0-epsilon)\n",
        "#         # new haodong\n",
        "#         hard_dice = (2. * inse + smooth) / (l + r + smooth)\n",
        "#         ##\n",
        "#         hard_dice = tf.reduce_mean(hard_dice, name='hard_dice')\n",
        "#         return hard_dice\n",
        "\n",
        "\n",
        "#     @staticmethod\n",
        "#     def iou_coe(output, target, threshold=0.5, axis=(1, 2, 3), smooth=1e-5):\n",
        "#         \"\"\"Non-differentiable Intersection over Union (IoU) for comparing the\n",
        "#         similarity of two batch of data, usually be used for evaluating binary image segmentation.\n",
        "#         The coefficient between 0 to 1, and 1 means totally match.\n",
        "\n",
        "#         Parameters\n",
        "#         -----------\n",
        "#         output : tensor\n",
        "#             A batch of distribution with shape: [batch_size, ....], (any dimensions).\n",
        "#         target : tensor\n",
        "#             The target distribution, format the same with `output`.\n",
        "#         threshold : float\n",
        "#             The threshold value to be true.\n",
        "#         axis : tuple of integer\n",
        "#             All dimensions are reduced, default ``(1,2,3)``.\n",
        "#         smooth : float\n",
        "#             This small value will be added to the numerator and denominator, see ``dice_coe``.\n",
        "\n",
        "#         Notes\n",
        "#         ------\n",
        "#         - IoU cannot be used as training loss, people usually use dice coefficient for training, IoU and hard-dice for evaluating.\n",
        "\n",
        "#         \"\"\"\n",
        "#         pre = tf.cast(output > threshold, dtype=tf.float32)\n",
        "#         truth = tf.cast(target > threshold, dtype=tf.float32)\n",
        "#         inse = tf.reduce_sum(tf.multiply(pre, truth), axis=axis)  # AND\n",
        "#         union = tf.reduce_sum(tf.cast(tf.add(pre, truth) >= 1, dtype=tf.float32), axis=axis)  # OR\n",
        "#         # old axis=[0,1,2,3]\n",
        "#         # epsilon = 1e-5\n",
        "#         # batch_iou = inse / (union + epsilon)\n",
        "#         # new haodong\n",
        "#         batch_iou = (inse + smooth) / (union + smooth)\n",
        "#         iou = tf.reduce_mean(batch_iou, name='iou_coe')\n",
        "#         return iou  # , pre, truth, inse, union\n",
        "\n",
        "\n",
        "\n",
        "# ## test soft/hard dice and iou\n",
        "# # import numpy as np\n",
        "# y = np.zeros((1,10,10,1))\n",
        "# # y[0,0:5,0:5]=1.0\n",
        "# o = np.zeros((1,10,10,1))\n",
        "# # o[:,:,:,:] = 0            # what we want: dice=0   iou=0  OK\n",
        "# # o[0,0:2,0:2]=0.3          # what we want: dice larger iou=0  OK\n",
        "# # o[0,0:2,0:2]=0.6          # what we want: dice larger  iou small  OK\n",
        "# # o[0,0:3,0:3]=0.6          # what we want: dice larger iou larger OK\n",
        "# # o[0,0:3,0:3]=1            # what we want: dice larger iou same OK\n",
        "# # o[0,0:5,0:5]=1            # what we want: dice=1 iou=1  OK\n",
        "# # o[0,0:5,0:5]=0.3          # what we want: dice smaller  iou=0  OK\n",
        "# # o[0,0:5,0:5]=1e-2           # what we want: dice≈0 iou=0  OK\n",
        "# # o[0,8:10,8:10]=1.0        # what we want: dice=0 iou=0  OK\n",
        "# # o[0,8:10,8:10]=1e-10        # what we want: dice=0 iou=0  OK\n",
        "# # y[:,:,:,:] = o[:,:,:,:] = 0 # what we want: dice=1 iou=1  OK\n",
        "# ## why in u-net, dice=1 hard-dice=1 iou=1 exist?? print bug?\n",
        "\n",
        "# d = Trial.dice_coe(o, y, 'jaccard', smooth=1.)\n",
        "# hd = Trial.dice_hard_coe(o, y, smooth=1e-5)\n",
        "# i = Trial.iou_coe(o, y, smooth=1e-5)\n",
        "# # sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
        "# # sess.run(tf.local_variables_initializer())\n",
        "# # print(sess.run([d,hd,i]))\n",
        "# # p, t, i, u = sess.run([pre, truth, inse, union])\n",
        "# # import pprint\n",
        "# # pprint.pprint(((y>0.5)*(o>0.5)).astype(int).tolist())\n",
        "# # pprint.pprint(p.tolist())\n",
        "# # pprint.pprint(t.tolist())\n",
        "# # pprint.pprint(i)\n",
        "# # pprint.pprint(u)\n",
        "# # exit()\n",
        "# print(d)\n",
        "# print(hd)\n",
        "# print(i)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlDpkT1sSxM5",
        "colab_type": "text"
      },
      "source": [
        "##Segmentation from scratch\n",
        "here, we build a complete network from scratch. \n",
        "The code is based on [this tutorial](https://github.com/tensorflow/examples/blob/master/community/en/ImageSegmentation_ModelSubclassing.ipynb) \n",
        "\n",
        "First we define encoding block and decoding block. Then, we build the encoding-decoding version, using those base blocks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9RdEXedYKrf",
        "colab_type": "text"
      },
      "source": [
        "####Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPnHmWZ-TB_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderBlock(tf.keras.Model):\n",
        "    def __init__(self, filter_size):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.filter_size = filter_size\n",
        "\n",
        "        self.layer_1 = tf.keras.layers.Activation('relu')\n",
        "        self.layer_2 = tf.keras.layers.SeparableConv2D(self.filter_size, 3, padding = 'same' ,\n",
        "                                                       kernel_regularizer=tf.keras.regularizers.l2(0),\n",
        "                                                       bias_regularizer = tf.keras.regularizers.l2(0))\n",
        "        self.layer_3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.layer_4 = tf.keras.layers.Activation('relu')\n",
        "        self.layer_5 = tf.keras.layers.SeparableConv2D(self.filter_size, 3, padding = 'same',\n",
        "                                                       kernel_regularizer=tf.keras.regularizers.l2(0),\n",
        "                                                       bias_regularizer = tf.keras.regularizers.l2(0))\n",
        "        self.layer_6 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.layer_7 = tf.keras.layers.MaxPooling2D(3, strides = 2, padding = 'same') #3,2\n",
        "        self.residual_layer = tf.keras.layers.Conv2D(self.filter_size, 1, strides = 2, padding = 'same')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.layer_1(inputs)\n",
        "        x = self.layer_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        x = self.layer_4(x)\n",
        "        x = self.layer_5(x)\n",
        "        x = self.layer_6(x)\n",
        "        x = self.layer_7(x)\n",
        "        residual = self.residual_layer(inputs)\n",
        "        x = tf.keras.layers.add([x, residual])\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBZWnnWBYNhT",
        "colab_type": "text"
      },
      "source": [
        "####Decoder Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx23ePHpVQp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Decoder class - Upsampling\n",
        "'''\n",
        "class DecoderBlock(tf.keras.Model):\n",
        "    def __init__(self, filter_size):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "\n",
        "        self.filter_size = filter_size\n",
        "    \n",
        "        self.layer_1 = tf.keras.layers.Activation('relu')\n",
        "        self.layer_2 = tf.keras.layers.Conv2DTranspose(self.filter_size, 3, padding = 'same')\n",
        "        self.layer_3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.layer_4 = tf.keras.layers.Activation('relu')\n",
        "        self.layer_5 = tf.keras.layers.Conv2DTranspose(self.filter_size, 3, padding = 'same')\n",
        "        self.layer_6 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.layer_7 = tf.keras.layers.UpSampling2D(2)\n",
        "\n",
        "        self.residual_layer_1 = tf.keras.layers.UpSampling2D(2)\n",
        "        self.residual_layer_2 = tf.keras.layers.Conv2D(filter_size, 1, padding = 'same')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.layer_1(inputs)\n",
        "        x = self.layer_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        x = self.layer_4(x)\n",
        "        x = self.layer_5(x)\n",
        "        x = self.layer_6(x)\n",
        "        x = self.layer_7(x)\n",
        "        residual = self.residual_layer_1(inputs)\n",
        "        residual = self.residual_layer_2(residual)\n",
        "\n",
        "        x = tf.keras.layers.add([x, residual])\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6af4ASjYQFp",
        "colab_type": "text"
      },
      "source": [
        "####Image Segmentation Model From Scratch\n",
        "Concatenating the two parts: encoding and decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA7DgQirWlHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageSegmentationModel(tf.keras.Model):\n",
        "    def __init__(self, output_channels, dynamic = True):\n",
        "        super(ImageSegmentationModel, self).__init__()\n",
        "        self.output_channels = output_channels\n",
        "\n",
        "        self.entry_block_1 = tf.keras.layers.Conv2D(32, 3, strides = 2, padding='same')\n",
        "        self.entry_block_2 = tf.keras.layers.BatchNormalization()\n",
        "        self.entry_block_3 = tf.keras.layers.Activation('relu')\n",
        "\n",
        "        self.encoder_block_1 = EncoderBlock(64)\n",
        "        self.encoder_block_2 = EncoderBlock(128)\n",
        "        self.encoder_block_3 = EncoderBlock(256)\n",
        "        self.decoder_block_1 = DecoderBlock(256)\n",
        "        self.decoder_block_2 = DecoderBlock(128)\n",
        "        self.decoder_block_3 = DecoderBlock(64)\n",
        "        self.decoder_block_4 = DecoderBlock(32)\n",
        "\n",
        "        self.output_layer = tf.keras.layers.Conv2D(output_channels, (3,3), activation='softmax', padding = 'same')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.entry_block_1(inputs)\n",
        "        x = self.entry_block_2(x)\n",
        "        x = self.entry_block_3(x)\n",
        "        x = self.encoder_block_1(x)\n",
        "        x = self.encoder_block_2(x)\n",
        "        x = self.encoder_block_3(x)\n",
        "        x = self.decoder_block_1(x)\n",
        "        x = self.decoder_block_2(x)\n",
        "        x = self.decoder_block_3(x)\n",
        "        x = self.decoder_block_4(x)\n",
        "        x = self.output_layer(x)\n",
        "        # tf.print(x.shape)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NrjC8ekYZu_",
        "colab_type": "text"
      },
      "source": [
        "####Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBrdwh4NgaVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gki-0aJYb5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS_ = 21\n",
        "model_seg_fs = ImageSegmentationModel(OUTPUT_CHANNELS_)\n",
        "model_seg_fs.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                     loss = tf.keras.losses.categorical_crossentropy, #loss_weighted, #\n",
        "                     metrics = [  MyScore.iou_coef, MyScore.dice_score ]) #meanIoU,\n",
        "\n",
        "model_seg_fs.build(input_shape = (BS, sq_size, sq_size, 3))\n",
        "model_seg_fs.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WNx5YBYaVV_",
        "colab_type": "text"
      },
      "source": [
        "####Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krwqgkulaXkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if train_seg_model_fs:\n",
        "    model_seg_fs_history = model_seg_fs.fit(training_set_seg_tf_generator, \n",
        "                                            epochs=EPOCHS,\n",
        "                                            steps_per_epoch= len(df_seg_train_to_generate)//BS,\n",
        "                                            validation_steps= len(df_seg_val_to_generate)//BS, #VALIDATION_STEPS,\n",
        "                                            validation_data=val_set_seg_tf_generator,\n",
        "                                            callbacks=[my_callbacks] #DisplayCallback(model_t = model_seg_fs), \n",
        "                                            )\n",
        "    model_seg_fs.save_weights(model_seg_fs_save_filename)\n",
        "    histories['model_seg_fs'] = model_seg_fs_history.history\n",
        "    pickle.dump(histories[\"model_seg_fs\"], open(model_seg_fs_hist_save_filename, 'wb'))\n",
        "else:\n",
        "    model_seg_fs.load_weights(model_seg_fs_save_filename)\n",
        "    histories['model_seg_fs'] = pickle.load(open(model_seg_fs_hist_save_filename, 'rb'))\n",
        "\n",
        "model_seg_fs.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGF0Y5keUAXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    fig, axes = plt.subplots(2,1,figsize=(8,8))\n",
        "    axes[0].plot(histories[\"model_seg_fs\"]['iou_coef'], label='IoU')\n",
        "    axes[0].plot(histories[\"model_seg_fs\"]['val_iou_coef'], label = 'val_IoU')\n",
        "    axes[0].plot(histories[\"model_seg_fs\"]['dice_score'], label='Dice')\n",
        "    axes[0].plot(histories[\"model_seg_fs\"]['val_dice_score'], label = 'val_Dice')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Metric')\n",
        "    axes[0].set_ylim([0.0, 1])\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[1].plot(histories[\"model_seg_fs\"]['loss'], label='loss')\n",
        "    axes[1].plot(histories[\"model_seg_fs\"]['val_loss'], label = 'val_loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Categorical Cross-entropy')\n",
        "    # axes[1].set_ylim([0.0, 1])\n",
        "    axes[1].legend(loc='upper right')\n",
        "    fig.suptitle('Model Sementation FS')\n",
        "except:\n",
        "    print(\"There was an error during the plot\")\n",
        "finally:\n",
        "    scores = model_seg_fs.evaluate(val_set_seg_tf_generator, steps=2*len(df_seg_val_to_generate[\"stem_filename\"])//BS )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8agqgIdBLfm",
        "colab_type": "text"
      },
      "source": [
        "###Results (Comparison with Transfer Learning)\n",
        "\n",
        "Similarly we can show the results of from-scratch modeling.\n",
        "Those results are pretty bad => The network hasn't learned useful things, much."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe8wWrZYj25Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Comparison between prediction from TL model, and from FS (From Scratch) model\n",
        "'''\n",
        "show_predictions(model = model_seg_tl, dataset=val_set_seg_tf_generator)\n",
        "show_predictions(model = model_seg_fs, dataset=val_set_seg_tf_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8gTBPjBOlnY",
        "colab_type": "text"
      },
      "source": [
        "##Segmentation From Scratch - Cat & Dog\n",
        "\n",
        "Tackling the full problem is hard, and there are not a lot of data available. In order to learn better, I decide to implement a simpler model in two steps:\n",
        "1. From scratch, binary classifier between cats and dogs\n",
        "    - Get more data from another dataset (available in tensorflow)\n",
        "    - Build a simpler CNN classifier\n",
        "        * 1 output (either cat or dog)\n",
        "        * Loss = binary cross entropy (2 classes)\n",
        "        * Metric = accuracy\n",
        "        * Output activation Function: sigmoid\n",
        "    - Verify performance on validation VOC set (cat & dogs only)\n",
        "    - save the model\n",
        "2. Reuse this model as the encoding part for segmentation\n",
        "    - create a training and a validation dataframe for segmentation containing only aeroplane and horses\n",
        "    - transform the mask so that they only contains background, cats and dogs\n",
        "    - Build the full network, reusing the feature extraction (= encoding) part of previous network\n",
        "    - train this as a segmentation problem, with 3 classes: background, cat, dog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gObWo9No2xxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Variable updates\n",
        "'''\n",
        "sq_size = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEJGOfEvQlCa",
        "colab_type": "text"
      },
      "source": [
        "#####Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vz_OEB8QYb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "create label binarizer\n",
        "'''\n",
        "classes_names_ah = [\"cat\", \"dog\"]\n",
        "multiLabelBinarizer_ah = preprocessing.MultiLabelBinarizer(classes=classes_names_ah)\n",
        "multiLabelBinarizer_ah.fit(classes_names_ah)\n",
        "\n",
        "\n",
        "'''\n",
        "obtain the classification dataframes\n",
        "'''\n",
        "df_class_train_ah= get_dataframe_from_classes(df_class_train, ('cat','dog'))\n",
        "df_class_val_ah  = get_dataframe_from_classes(df_class_val, ('cat','dog'))\n",
        "\n",
        "df1 = df_class_val_ah.iloc[:125,:]\n",
        "df_class_val_ah = df_class_val_ah.iloc[125:,:]\n",
        "\n",
        "frames = [df_class_train_ah, df1]\n",
        "\n",
        "df_class_train_ah = pd.concat(frames)\n",
        "\n",
        "print(df_class_train_ah.head(5))\n",
        "print(df_class_val_ah.head(5))\n",
        "\n",
        "nb_elm_train_ah = len(df_class_train_ah[\"class\"])\n",
        "print(\"Number total of element in training set: \" + str(nb_elm_train_ah))\n",
        "print(\"Number of 'cat' in training set: \" + str(len([ x for x in df_class_train_ah[\"class\"] if x == ('cat',)  ])))\n",
        "print(\"Number of 'dog' in training set: \" + str(len([ x for x in df_class_train_ah[\"class\"] if x == ('dog',)  ]) ))\n",
        "print(\"--\"*30)\n",
        "print(\"Number of 'cat' in validation set: \" + str(len([ x for x in df_class_val_ah[\"class\"] if x == ('cat',)  ]) ))\n",
        "print(\"Number of 'dog' in validation set: \" + str(len([ x for x in df_class_val_ah[\"class\"] if x == ('dog',)  ]) ))\n",
        "print(\"Number total of element in validation set: \" + str(len(df_class_val_ah[\"class\"])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5tbOkUe_Mvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Because the classes are unbalanced, I need extra steps to \n",
        "- randomly select items from the original set\n",
        "- with a weight inversely proportional to original class weight\n",
        "The goal is to have a as flat as possible distribution\n",
        "\n",
        "==> Wrong side: we throw away a lot\n",
        "'''\n",
        "equalize_distribution = False\n",
        "if equalize_distribution:\n",
        "    ah_training_labels = multiLabelBinarizer_ah.transform(df_class_train_ah[\"class\"])\n",
        "    print(ah_training_labels)\n",
        "    ah_classes_weights = np.sum(ah_training_labels == 1, axis = 0) / ah_training_labels.shape[0]\n",
        "    print(\"Weights of the different classes, in the Single Label context:\" + str(ah_classes_weights))\n",
        "\n",
        "    # inverted weights, indicating the weights for sampling\n",
        "    ah_inverted_classes_weights = (1/ah_classes_weights)/ (np.sum(1/ah_classes_weights)+1e-16)\n",
        "    print(ah_inverted_classes_weights)\n",
        "\n",
        "    # add a column for this weight\n",
        "    def _loc(df):\n",
        "        df = df.assign(sampling_rate=0)\n",
        "        for i in range(len(classes_names_ah)):\n",
        "            df.loc[df['class']==(classes_names_ah[i],), 'sampling_rate'] = ah_inverted_classes_weights[i]\n",
        "        return df\n",
        "    ah_df_class_train_to_generate = _loc(df_class_train_ah)\n",
        "    ah_df_class_val_to_generate = _loc(df_class_val_ah)\n",
        "\n",
        "\n",
        "    print(ah_df_class_train_to_generate.head(10))\n",
        "\n",
        "    #sample appropriately 1500 for training and for validation from the single_label inout dataframe\n",
        "    ah_df_class_train_to_generate = ah_df_class_train_to_generate.sample(600, weights = ah_df_class_train_to_generate['sampling_rate'], random_state=1000)\n",
        "    print(\"\\nNew single-label dataframe for training (5 first elem):\")\n",
        "    print(ah_df_class_train_to_generate.head(5))\n",
        "\n",
        "\n",
        "    ah_df_class_val_to_generate = ah_df_class_val_to_generate.sample(85, weights = ah_df_class_val_to_generate['sampling_rate'], random_state=0)\n",
        "    print(\"\\nNew single-label dataframe for validation (5 first elem):\")\n",
        "    print(ah_df_class_val_to_generate.head(5))\n",
        "else:\n",
        "    ah_df_class_train_to_generate = df_class_train_ah\n",
        "    ah_df_class_val_to_generate = df_class_val_ah\n",
        "'''\n",
        "Check the distribution\n",
        "'''\n",
        "# count the number of items of each class\n",
        "ah_counts_training = np.zeros((2,))\n",
        "ah_counts_validation = np.zeros((2,))\n",
        "for i in range(len(classes_names_ah)):\n",
        "    ah_counts_training[i] = len(ah_df_class_train_to_generate[ah_df_class_train_to_generate['class'] ==  (classes_names_ah[i],)]) \n",
        "    ah_counts_validation[i] = len(ah_df_class_val_to_generate[ah_df_class_val_to_generate['class'] ==  (classes_names_ah[i],)]) \n",
        "\n",
        "# get the classes' ratio\n",
        "ah_counts_training /= sum(ah_counts_training)\n",
        "ah_counts_training*=100\n",
        "ah_counts_validation /= sum(ah_counts_validation)\n",
        "ah_counts_validation*=100\n",
        "\n",
        "print(ah_counts_training)\n",
        "print(ah_counts_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57PyvcX1Qsmx",
        "colab_type": "text"
      },
      "source": [
        "#####Generators\n",
        "Create generators for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx5QqDF2T58S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "construct generators for classification training\n",
        "'''\n",
        "train_class_gen_ah   = get_classification_keras_generator(ah_df_class_train_to_generate, mode = 'training', BS = 32,  seed = 50)\n",
        "val_class_gen_ah     = get_classification_keras_generator(ah_df_class_val_to_generate, mode = 'validation', BS = 32, seed = 500)\n",
        "\n",
        "img, lbls = next(train_class_gen_ah)\n",
        "plot_matrix(img, multiLabelBinarizer_ah.inverse_transform(lbls))\n",
        "\n",
        "img, lbls = next(val_class_gen_ah)\n",
        "plot_matrix(img, multiLabelBinarizer_ah.inverse_transform(lbls))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfMmO0N-P6Dl",
        "colab_type": "text"
      },
      "source": [
        "### Classifier (encoder) with new Data\n",
        "After many trials, it appears this is not easy to get a good classifier conidering the limited number of pictures available\n",
        "-> a solution is to try and get another dataset - hopefully from similar images\n",
        "\n",
        "the next few snippets are inspired by [tensorflow tutorial](https://www.tensorflow.org/tutorials/images/classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdnmEBxLO2Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmoB4Al8O8k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc1eVIKiPMK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7KkaCzKPAT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83PdVLeXP_cR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = BS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HUJs9kUQBJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                                        width_shift_range=.1,\n",
        "                                                                        height_shift_range=.1,\n",
        "                                                                        horizontal_flip=True) # Generator for our training data\n",
        "validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfnfnD3JQjpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed = 0,\n",
        "                                                           target_size=(sq_size, sq_size),\n",
        "                                                           class_mode='binary')\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              seed = 0,\n",
        "                                                              target_size=(sq_size, sq_size),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFLEv36BQrHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, labels_sampes= next(train_data_gen)\n",
        "plot_matrix(sample_training_images, labels_sampes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYuURejTUQ26",
        "colab_type": "text"
      },
      "source": [
        "#####Build Classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyQ27IEvrBjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    \n",
        "    model.add(tf.keras.layers.SeparableConv2D( 32, (3, 3), kernel_initializer='he_uniform', padding='same', input_shape=(sq_size, sq_size, 3),name = 'conv0', ))\n",
        "    model.add(tf.keras.layers.Activation('relu', name = 'relu0'))\n",
        "    # model.add(tf.keras.layers.SeparableConv2D( 32, (3, 3), kernel_initializer='he_uniform', padding='same', input_shape=(sq_size, sq_size, 3),name = 'conv02', ))\n",
        "    # model.add(tf.keras.layers.Activation('relu', name = 'relu02'))\n",
        "    \n",
        "    model.add(tf.keras.layers.MaxPooling2D(2,2)),\n",
        "    \n",
        "    model.add(tf.keras.layers.SeparableConv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv1', ))\n",
        "    model.add(tf.keras.layers.Activation('relu', name = 'relu1'))\n",
        "    # model.add(tf.keras.layers.SeparableConv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv12', ))\n",
        "    # model.add(tf.keras.layers.Activation('relu', name = 'relu12'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    \n",
        "    model.add(tf.keras.layers.SeparableConv2D( 128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv2',))\n",
        "    model.add(tf.keras.layers.Activation('relu', name = 'relu2'))\n",
        "    # model.add(tf.keras.layers.SeparableConv2D( 128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv22',))\n",
        "    # model.add(tf.keras.layers.Activation('relu', name = 'relu22'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    \n",
        "    model.add(tf.keras.layers.SeparableConv2D( 256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv3',))\n",
        "    model.add(tf.keras.layers.Activation('relu', name = 'relu3'))\n",
        "    # model.add(tf.keras.layers.SeparableConv2D( 256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv32',))\n",
        "    # model.add(tf.keras.layers.Activation('relu', name = 'relu32'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    \n",
        "    # model.add(tf.keras.layers.Conv2D( 256, (1, 1), strides=1, activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv4',))\n",
        "    # model.add(tf.keras.layers.Activation('relu', name = 'relu4'))\n",
        "\n",
        "    # model.add(tf.keras.layers.SeparableConv2D( 384, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv4',))\n",
        "    # model.add(tf.keras.layers.Activation('relu', name = 'relu4'))\n",
        "    # model.add(tf.keras.layers.SeparableConv2D( 256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', name = 'conv32',))\n",
        "    # model.add(tf.keras.layers.Activation('relu', name = 'relu32'))\n",
        "    # model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    # model.add(tf.keras.layers.Dropout(0.5))\n",
        "    # model.add(tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "    # model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USy53CAzWQED",
        "colab_type": "text"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q774kXAIWSWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Compilation\n",
        "'''\n",
        "loss_ah = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
        "# loss_ah = tf.keras.losses.CategoricalCrossentropy()\n",
        "# model_ah = get_model_ah()\n",
        "# model_ah = ImageClassificationModel(2)\n",
        "model_ah = define_model()\n",
        "model_ah.compile(   optimizer = tf.keras.optimizers.Adam(1e-4),\n",
        "                    loss = loss_ah, #loss_weighted, #\n",
        "                    metrics = [ 'accuracy' ]) \n",
        "model_ah.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-KFtedzWk-K",
        "colab_type": "text"
      },
      "source": [
        "#####Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lliGg8pbWnj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Model Fitting\n",
        "'''\n",
        "BS_AH = 32\n",
        "if train_class_ah:\n",
        "    history_model_ah = model_ah.fit(train_data_gen, #train_class_gen_ah, #\n",
        "                                    epochs=EPOCHS,\n",
        "                                    # shuffle = True,\n",
        "                                    steps_per_epoch=  total_train // BS_AH, #len(df_class_train_ah)//BS_AH, # \n",
        "                                    validation_steps= total_val // BS_AH, # #VALIDATION_STEPS, len(df_class_val_ah)//BS_AH, # \n",
        "                                    validation_data=val_data_gen, #val_class_gen_ah, # \n",
        "                                     ) #callbacks=[my_callbacks]\n",
        "    model_ah.save_weights(model_ah_save_filename)\n",
        "    histories['model_ah'] = history_model_ah.history\n",
        "    pickle.dump(histories[\"model_ah\"], open(model_ah_hist_save_filename, 'wb'))\n",
        "else:\n",
        "    model_ah.load_weights(model_ah_save_filename)\n",
        "    histories['model_ah'] = pickle.load(open(model_ah_hist_save_filename, 'rb'))\n",
        "\n",
        "\n",
        "model_ah.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HztO_IdSZNfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    fig, axes = plt.subplots(2,1,figsize=(8,8))\n",
        "    axes[0].plot(histories['model_ah']['accuracy'], label='accuracy')\n",
        "    axes[0].plot(histories['model_ah']['val_accuracy'], label = 'val_accuracy')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Metric')\n",
        "    axes[0].set_ylim([0.5, 1])\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[1].plot(histories['model_ah']['loss'], label='loss')\n",
        "    axes[1].plot(histories['model_ah']['val_loss'], label = 'val_loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Binary Cross-entropy')\n",
        "    axes[1].set_ylim([0.0, 1])\n",
        "    axes[1].legend(loc='upper right')\n",
        "    fig.suptitle('Model AH ')\n",
        "except:\n",
        "    print(\"There was an error during the plot\")\n",
        "finally:\n",
        "    model_ah.summary()\n",
        "\n",
        "pred = model_ah.predict(val_class_gen_ah)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqvkzGCXrPM-",
        "colab_type": "text"
      },
      "source": [
        "####Check performance on VOC val set\n",
        "This CAt&Dog was trained using another dataset. We can verify the performances on the validation set defined. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LraRWR_kAk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Get the validation data ready for prediction\n",
        "'''\n",
        "# retrieve the ids from the dataframe\n",
        "ah_val_ids = list(ah_df_class_val_to_generate[\"filename\"].apply(lambda x: x.split('.')[0]))\n",
        "\n",
        "# load the images in RAM\n",
        "ah_val_images = get_images(ah_val_ids, path_image_folder,width=sq_size, height=sq_size,)\n",
        "if np.max(np.max(ah_val_images)) > 1:\n",
        "    ah_val_images = np.divide(ah_val_images,255.0, dtype = np.float32)\n",
        "\n",
        "# retrieve the labels from the dataframe\n",
        "ah_val_labels_binarized = multiLabelBinarizer_ah.transform(ah_df_class_val_to_generate[\"class\"])\n",
        "ah_val_labels_str = list(ah_df_class_val_to_generate[\"class\"])\n",
        "y_true = ah_val_labels_binarized\n",
        "\n",
        "\n",
        "'''\n",
        "Predict\n",
        "'''\n",
        "y_pred_binary = model_ah.predict(ah_val_images)\n",
        "\n",
        "# reshape the binary so that it gets one-hot encoded\n",
        "y_pred = [[1,0] if x[0] < 0.5 else [0,1] for x in y_pred_binary]\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# y_pred_str = multiLabelBinarizer.inverse_transform(y_pred)\n",
        "\n",
        "'''\n",
        "Check on shapes\n",
        "'''\n",
        "print(\"y_true shape = \" + str(y_true.shape))\n",
        "print(\"y_pred shape = \" + str(y_pred.shape))\n",
        "\n",
        "'''\n",
        "convert one hot encoding to categorical using argmax\n",
        "'''\n",
        "y_true_categorical = [ np.argmax(t) for t in y_true ]\n",
        "y_pred_categorical = [ np.argmax(t) for t in y_pred ]\n",
        "'''\n",
        "Compute confusion matrix\n",
        "'''\n",
        "conf_mat_dict = sklearn.metrics.confusion_matrix(y_true = y_true_categorical, y_pred = y_pred_categorical)\n",
        "conf_mat_dict_norm = sklearn.metrics.confusion_matrix( y_true=y_true_categorical, y_pred = y_pred_categorical, normalize = 'true')\n",
        "\n",
        "print(conf_mat_dict_norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtYE30pe7Gu-",
        "colab_type": "text"
      },
      "source": [
        "###Segmentation network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnzSmItc4gIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Extract layers of the classifier\n",
        "'''\n",
        "\n",
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    'relu0',   # 64x64\n",
        "    'relu1',   # 32x32\n",
        "    'relu2',   # 16x16\n",
        "    'relu3', \n",
        "]\n",
        "layers_list = [model_ah.get_layer(name).output for name in layer_names]\n",
        "\n",
        "\n",
        "'''\n",
        "create a model based on those activation, and make in Not Trainable\n",
        "'''\n",
        "# Create the feature extraction model\n",
        "down_stack_ah = tf.keras.Model(inputs=model_ah.input, outputs=layers_list)\n",
        "\n",
        "'''\n",
        "copy weights\n",
        "'''\n",
        "for name_ in layer_names:\n",
        "    down_stack_ah.get_layer(name = name_).set_weights(model_ah.get_layer(name = name_).get_weights())\n",
        "\n",
        "'''\n",
        "make it not trainable!\n",
        "'''\n",
        "down_stack_ah.trainable = False\n",
        "\n",
        "print(len(down_stack_ah.layers))\n",
        "print(len(model_ah.layers))\n",
        "\n",
        "print(down_stack_ah.get_layer(name = 'conv2'))\n",
        "print(model_ah.get_layer(name = 'conv2'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmW4zl9S5HYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "upstack\n",
        "'''\n",
        "up_stack_ah = [\n",
        "            upsample(128, 3),  # 16x16 -> 32x32\n",
        "            upsample(64, 3),   # 32x32 -> 64x64\n",
        "            upsample(32, 3)\n",
        "            ]\n",
        "\n",
        "def my_unet_ah(output_channels = 3):\n",
        "    inputs = tf.keras.layers.Input(shape=[sq_size, sq_size, 3])\n",
        "    x = inputs\n",
        "    # Downsampling through the model\n",
        "    skips = down_stack_ah(x)\n",
        "    x = skips[-1]\n",
        "\n",
        "    # create a generator of the layers in skips ==> in downstack, in the reverse order, until last-but-one\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack_ah, skips):\n",
        "        x = up(x)\n",
        "        concat = tf.keras.layers.Concatenate()\n",
        "        x = concat([x, skip])\n",
        "\n",
        "    # This is the last layer of the model\n",
        "    last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=1,  padding='same',   activation=\"softmax\")  #64x64 -> 128x128\n",
        "    x = last(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "    # model.trainable = False\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWVKxmV654YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_seg_fs_ah = my_unet_ah(3)\n",
        "model_seg_fs_ah.summary()\n",
        "tf.keras.utils.plot_model(model_seg_fs_ah, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jPKxBLpKtmP",
        "colab_type": "text"
      },
      "source": [
        "###Data for segmentation\n",
        "Build the generators for training and validation sets.\n",
        "\n",
        "Most of the code is a duplicate of previous cells, with tiny changes. This is bad code design.\n",
        "\n",
        "Those functions below replicate exactly the creation of the generators usinf tf.Data API, but change the way the mask is encoded to make sure only background, cats and dogs are present. All the other colors go to black"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZfT_WY7JjkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Those functions are only dedicated to the aerplane vs horse case: only 2 classes + background problem. \n",
        "The implementation is the exact same as above, instead of the one-hot encoding of the mask. \n",
        "\n",
        "It should be changed as it induces a lot of code redundancy (note the \"_reduced\" in the function names)\n",
        "'''\n",
        "\n",
        "def get_reduced_segmentation_generator(dataframe, cache = True, to_augment = True):\n",
        "    '''\n",
        "    In the exact same fashion as get_classification_generator, it returns a \n",
        "    tf generator of image and label for segmentation task. \n",
        "    This generator allows caching\n",
        "    '''\n",
        "    stem_filenames = dataframe[\"stem_filename\"]\n",
        "    tf_generator = tf.data.Dataset.from_tensor_slices(stem_filenames)\n",
        "    tf_generator = tf_generator.map(parse_reduced_segmentation_function, num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "\n",
        "    if isinstance(cache, str):      \n",
        "        tf_generator = tf_generator.cache(cache)\n",
        "    else:\n",
        "        tf_generator = tf_generator.cache()\n",
        "    \n",
        "    if to_augment:\n",
        "        tf_generator = tf_generator.map(train_segmentation_preprocess, num_parallel_calls = AUTOTUNE)\n",
        "    \n",
        "\n",
        "    tf_generator = tf_generator.shuffle(len(stem_filenames), seed = 426473)\n",
        "    tf_generator = tf_generator.repeat()\n",
        "    tf_generator = tf_generator.batch(BATCH_SIZE)\n",
        "    tf_generator = tf_generator.prefetch(buffer_size = AUTOTUNE)\n",
        "    return tf_generator\n",
        "\n",
        "def parse_reduced_segmentation_function(stem_filename):\n",
        "    '''\n",
        "    @param stem_filename: id of the image files to read\n",
        "    '''\n",
        "    filename_input_image = voc_root_folder + r'/JPEGImages/' + stem_filename + \".jpg\"\n",
        "    filename_input_mask = voc_root_folder + r'/SegmentationClass/' + stem_filename + \".png\"\n",
        "\n",
        "    input_image_string = tf.io.read_file(filename_input_image)\n",
        "    input_image = tf.image.decode_jpeg(input_image_string, channels=3)\n",
        "\n",
        "    input_mask_string = tf.io.read_file(filename_input_mask)\n",
        "    input_mask = tf.image.decode_png(input_mask_string, channels=3)\n",
        "\n",
        "    input_image = tf.image.resize(input_image, [sq_size, sq_size])\n",
        "    input_mask = tf.image.resize(input_mask, [sq_size, sq_size])\n",
        "\n",
        "    input_image, input_mask = segmentation_reduced_normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "\n",
        "def segmentation_reduced_normalize(input_image, input_mask):\n",
        "    '''\n",
        "    Normalize an input image by:\n",
        "    - convert it to float32, within [0.0, 1.0]\n",
        "    - encode the input_mask\n",
        "    '''\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask = __two_encode(input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "\n",
        "\n",
        "def __two_encode(mask):\n",
        "    '''\n",
        "    Trial helper function that maps a full mask of 22 colors into a mask of 3 colors. \n",
        "    '''\n",
        "    # colors = tf.map_fn(lambda x: map_colors(tf.cast(x, dtype=tf.float32)), mask)\n",
        "    # one_hot = tf.one_hot(colors, depth=3)\n",
        "    local_colormap = ([64,0,0], [64,0,128],) #\n",
        "    local_color_reference = tf.cast(tf.constant(local_colormap), dtype=tf.float32)\n",
        "    # Load the image and obtain tensor with one-hot values\n",
        "    comp = tf.equal(mask[..., None, :], local_color_reference)\n",
        "    one_hot_map = tf.cast(tf.reduce_all(comp, axis=-1), dtype=tf.float32)\n",
        "\n",
        "    map_elements = tf.reduce_sum(one_hot_map, axis=-1)\n",
        "    map_elements = tf.expand_dims(map_elements,2)\n",
        "    one_hot_opposite_map = tf.math.subtract(tf.ones((sq_size,sq_size,1)), map_elements)\n",
        "\n",
        "    output = tf.concat([one_hot_opposite_map, one_hot_map], axis = -1)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rvvtvi3dX7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "get dataframe for segmentation\n",
        "'''\n",
        "df_seg_train_ah = get_dataframe_from_classes(df_seg_train, ('cat','dog',))\n",
        "df_seg_val_ah = get_dataframe_from_classes(df_seg_val, ('cat','dog',))\n",
        "\n",
        "\n",
        "print(df_seg_val.head(5))\n",
        "print(df_seg_val_ah.head(5))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0INL1zBDgWiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "get generators from dataframe\n",
        "'''\n",
        "train_seg_tf_gen_ah   = get_reduced_segmentation_generator(df_seg_train_ah, to_augment = True)\n",
        "val_seg_tf_gen_ah     = get_reduced_segmentation_generator(df_seg_val_ah, to_augment = False)\n",
        "\n",
        "for img, mask in train_seg_tf_gen_ah.take(2):\n",
        "    tf.print(mask.shape)\n",
        "\n",
        "plot_matrix(img, scale =2)\n",
        "plot_matrix(mask, scale = 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1eAXTb-8ba6",
        "colab_type": "text"
      },
      "source": [
        "###Segmentation Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_wqqVdrfKPE",
        "colab_type": "text"
      },
      "source": [
        "Now we are ready to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iOu6SySizK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_after_normalization = np.array([0.6, 0.25, 0.15])\n",
        "weights = weights_after_normalization.reshape((1,1,1,3))\n",
        "kWeights = tf.keras.backend.constant(weights)\n",
        "\n",
        "'''\n",
        "Attempt of weighted categorical cross entropy\n",
        "'''\n",
        "def weighted_cce_ah(y_true, y_pred):\n",
        "    yWeights = kWeights * y_pred         #shape (batch, 128, 128, 4)\n",
        "    yWeights = tf.keras.backend.sum(yWeights, axis=-1)  #shape (batch, 128, 128)  \n",
        "\n",
        "    yWeights = yWeights / tf.keras.backend.sum(yWeights)\n",
        "\n",
        "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred) #shape (batch, 128, 128)\n",
        "    wLoss = yWeights * loss\n",
        "    return tf.keras.backend.sum(wLoss, axis=(1,2))\n",
        "\n",
        "\n",
        "\n",
        "mean_iou_ah = tf.keras.metrics.MeanIoU(num_classes=3)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Compilation\n",
        "'''\n",
        "\n",
        "\n",
        "model_seg_fs_ah.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                        loss = tf.keras.losses.categorical_crossentropy, #loss_weighted, #weighted_cce_ah, #\n",
        "                        metrics = [MyScore.iou_coef, MyScore.dice_score ]) #meanIoU,\n",
        "\n",
        "if train_seg_fs_ah:\n",
        "    history_model_seg_fs_ah = model_seg_fs_ah.fit(train_seg_tf_gen_ah, \n",
        "                                                epochs=EPOCHS,\n",
        "                                                steps_per_epoch= len(df_seg_train_ah),\n",
        "                                                validation_steps= len(df_seg_val_ah), #VALIDATION_STEPS,\n",
        "                                                validation_data=val_seg_tf_gen_ah,\n",
        "                                                callbacks= [my_callbacks], \n",
        "                                                )\n",
        "\n",
        "    model_seg_fs_ah.save_weights(model_seg_fs_ah_save_filename)\n",
        "    histories['model_seg_fs_ah'] = history_model_seg_fs_ah.history\n",
        "    pickle.dump(histories[\"model_seg_fs_ah\"], open(model_seg_fs_ah_hist_save_filename, 'wb'))\n",
        "else:\n",
        "    model_seg_fs_ah.load_weights(model_seg_fs_ah_save_filename)\n",
        "    histories['model_seg_fs_ah'] = pickle.load(open(model_seg_fs_ah_hist_save_filename, 'rb'))\n",
        "\n",
        "\n",
        "\n",
        "model_seg_fs_ah.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybk33yzDzWwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    fig, axes = plt.subplots(2,1,figsize=(8,8))\n",
        "    axes[0].plot(histories[\"model_seg_fs_ah\"]['iou_coef'], label='IoU')\n",
        "    axes[0].plot(histories[\"model_seg_fs_ah\"]['val_iou_coef'], label = 'val_IoU')\n",
        "    axes[0].plot(histories[\"model_seg_fs_ah\"]['dice_score'], label='Dice')\n",
        "    axes[0].plot(histories[\"model_seg_fs_ah\"]['val_dice_score'], label = 'val_Dice')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Metric')\n",
        "    axes[0].set_ylim([0.0, 1])\n",
        "    axes[0].legend(loc='upper right')\n",
        "    axes[1].plot(histories[\"model_seg_fs_ah\"]['loss'], label='loss')\n",
        "    axes[1].plot(histories[\"model_seg_fs_ah\"]['val_loss'], label = 'val_loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Categorical Cross-entropy')\n",
        "    # axes[1].set_ylim([0.0, 1])\n",
        "    axes[1].legend(loc='upper right')\n",
        "    fig.suptitle('Model Sementation FS Cats and Dogs')\n",
        "except:\n",
        "    print(\"There was an error during the plot\")\n",
        "finally:\n",
        "    scores = model_seg_fs_ah.evaluate(val_seg_tf_gen_ah, steps=2*len(df_seg_val_ah[\"stem_filename\"])//BS )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp4kJuhHTfDU",
        "colab_type": "text"
      },
      "source": [
        "###Predictions results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXees6_9hPl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show_predictions(model = model_seg_fs_ah, dataset=val_seg_tf_gen_ah)\n",
        "# show_predictions(model = model_seg_fs_ah, dataset=val_seg_tf_gen_ah)\n",
        "# show_predictions(model = model_seg_fs_ah, dataset=val_seg_tf_gen_ah)\n",
        "\n",
        "for img_batch, mask_batch in val_seg_tf_gen_ah.take(10):\n",
        "    for i in range(10):\n",
        "        sample_image = img_batch[i]\n",
        "        sample_mask = color_seg(np.array(tf.argmax(mask_batch[i], axis = -1)),np.array(colormap[0:21]))\n",
        "        pred_mask = model_seg_fs_ah.predict(sample_image[tf.newaxis, ...])\n",
        "        display([sample_image, sample_mask, create_mask(pred_mask)])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5hcjN3BIKJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}